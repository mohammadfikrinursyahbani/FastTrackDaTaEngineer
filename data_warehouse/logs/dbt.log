[0m11:31:05.223469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7800055f2720>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x780003d870e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x780003d864b0>]}


============================== 11:31:05.231523 | 40679cca-d2b0-4c74-b351-1c6fbf2f1f56 ==============================
[0m11:31:05.231523 [info ] [MainThread]: Running with dbt=1.8.5
[0m11:31:05.234045 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:31:05.264692 [info ] [MainThread]: dbt version: 1.8.5
[0m11:31:05.268269 [info ] [MainThread]: python version: 3.12.3
[0m11:31:05.273062 [info ] [MainThread]: python path: /home/fikri/Documents/ftde-digitalskola/project 2/venv/bin/python3
[0m11:31:05.275441 [info ] [MainThread]: os info: Linux-6.8.0-39-generic-x86_64-with-glibc2.39
[0m11:31:05.580403 [info ] [MainThread]: Using profiles dir at /home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse
[0m11:31:05.582091 [info ] [MainThread]: Using profiles.yml file at /home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse/profiles.yml
[0m11:31:05.584049 [info ] [MainThread]: Using dbt_project.yml file at /home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse/dbt_project.yml
[0m11:31:05.586149 [info ] [MainThread]: adapter type: postgres
[0m11:31:05.587914 [info ] [MainThread]: adapter version: 1.8.2
[0m11:31:05.983546 [info ] [MainThread]: Configuration:
[0m11:31:05.986537 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m11:31:05.988779 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m11:31:05.990024 [info ] [MainThread]: Required dependencies:
[0m11:31:05.991766 [debug] [MainThread]: Executing "git --help"
[0m11:31:05.998317 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m11:31:06.000623 [debug] [MainThread]: STDERR: "b''"
[0m11:31:06.001962 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m11:31:06.003595 [info ] [MainThread]: Connection:
[0m11:31:06.005079 [info ] [MainThread]:   host: localhost
[0m11:31:06.006159 [info ] [MainThread]:   port: 5433
[0m11:31:06.006987 [info ] [MainThread]:   user: admin
[0m11:31:06.008541 [info ] [MainThread]:   database: data_warehouse
[0m11:31:06.009874 [info ] [MainThread]:   schema: dbt_dev
[0m11:31:06.010783 [info ] [MainThread]:   connect_timeout: 10
[0m11:31:06.011828 [info ] [MainThread]:   role: None
[0m11:31:06.013176 [info ] [MainThread]:   search_path: None
[0m11:31:06.014474 [info ] [MainThread]:   keepalives_idle: 0
[0m11:31:06.018010 [info ] [MainThread]:   sslmode: None
[0m11:31:06.019537 [info ] [MainThread]:   sslcert: None
[0m11:31:06.021162 [info ] [MainThread]:   sslkey: None
[0m11:31:06.022795 [info ] [MainThread]:   sslrootcert: None
[0m11:31:06.027428 [info ] [MainThread]:   application_name: dbt
[0m11:31:06.030989 [info ] [MainThread]:   retries: 1
[0m11:31:06.037405 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m11:31:06.040751 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m11:31:06.155694 [debug] [MainThread]: Using postgres connection "debug"
[0m11:31:06.157008 [debug] [MainThread]: On debug: select 1 as id
[0m11:31:06.157928 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:31:06.159554 [debug] [MainThread]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "localhost" (127.0.0.1), port 5433 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

[0m11:31:06.161131 [debug] [MainThread]: Postgres adapter: Error running SQL: select 1 as id
[0m11:31:06.161966 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
[0m11:31:06.163074 [debug] [MainThread]: On debug: No close available on handle
[0m11:31:06.163927 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m11:31:06.165391 [info ] [MainThread]: [31m1 check failed:[0m
[0m11:31:06.166923 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  connection to server at "localhost" (127.0.0.1), port 5433 failed: Connection refused
  	Is the server running on that host and accepting TCP/IP connections?
  

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m11:31:06.169307 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_wall_clock_time": 1.0926036, "process_user_time": 3.620012, "process_kernel_time": 0.2174, "process_mem_max_rss": "97476", "process_out_blocks": "24", "command_success": false, "process_in_blocks": "0"}
[0m11:31:06.171167 [debug] [MainThread]: Command `dbt debug` failed at 11:31:06.170838 after 1.09 seconds
[0m11:31:06.172543 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m11:31:06.173945 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x780004cdcc80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7800037f89e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78000397a630>]}
[0m11:31:06.175325 [debug] [MainThread]: Flushing usage events
[0m11:31:32.149394 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d6001a63260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d600215bc20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d6001b1d580>]}


============================== 11:31:32.155692 | 5e08f64e-00b3-41db-b849-a2f2e0a7e25d ==============================
[0m11:31:32.155692 [info ] [MainThread]: Running with dbt=1.8.5
[0m11:31:32.157668 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse', 'debug': 'False', 'version_check': 'True', 'log_path': '/home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m11:31:32.177799 [info ] [MainThread]: dbt version: 1.8.5
[0m11:31:32.179494 [info ] [MainThread]: python version: 3.12.3
[0m11:31:32.180890 [info ] [MainThread]: python path: /home/fikri/Documents/ftde-digitalskola/project 2/venv/bin/python3
[0m11:31:32.182265 [info ] [MainThread]: os info: Linux-6.8.0-39-generic-x86_64-with-glibc2.39
[0m11:31:32.403224 [info ] [MainThread]: Using profiles dir at /home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse
[0m11:31:32.404649 [info ] [MainThread]: Using profiles.yml file at /home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse/profiles.yml
[0m11:31:32.405815 [info ] [MainThread]: Using dbt_project.yml file at /home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse/dbt_project.yml
[0m11:31:32.407748 [info ] [MainThread]: adapter type: postgres
[0m11:31:32.409329 [info ] [MainThread]: adapter version: 1.8.2
[0m11:31:32.663308 [info ] [MainThread]: Configuration:
[0m11:31:32.664414 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m11:31:32.665495 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m11:31:32.666734 [info ] [MainThread]: Required dependencies:
[0m11:31:32.669334 [debug] [MainThread]: Executing "git --help"
[0m11:31:32.674556 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m11:31:32.676742 [debug] [MainThread]: STDERR: "b''"
[0m11:31:32.678169 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m11:31:32.679358 [info ] [MainThread]: Connection:
[0m11:31:32.680606 [info ] [MainThread]:   host: localhost
[0m11:31:32.682112 [info ] [MainThread]:   port: 5432
[0m11:31:32.683423 [info ] [MainThread]:   user: admin
[0m11:31:32.684813 [info ] [MainThread]:   database: data_warehouse
[0m11:31:32.686135 [info ] [MainThread]:   schema: dbt_dev
[0m11:31:32.688036 [info ] [MainThread]:   connect_timeout: 10
[0m11:31:32.689364 [info ] [MainThread]:   role: None
[0m11:31:32.690605 [info ] [MainThread]:   search_path: None
[0m11:31:32.691998 [info ] [MainThread]:   keepalives_idle: 0
[0m11:31:32.693643 [info ] [MainThread]:   sslmode: None
[0m11:31:32.695752 [info ] [MainThread]:   sslcert: None
[0m11:31:32.697222 [info ] [MainThread]:   sslkey: None
[0m11:31:32.698876 [info ] [MainThread]:   sslrootcert: None
[0m11:31:32.700289 [info ] [MainThread]:   application_name: dbt
[0m11:31:32.701773 [info ] [MainThread]:   retries: 1
[0m11:31:32.703616 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m11:31:32.707585 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m11:31:32.807039 [debug] [MainThread]: Using postgres connection "debug"
[0m11:31:32.807923 [debug] [MainThread]: On debug: select 1 as id
[0m11:31:32.808825 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:31:32.832146 [debug] [MainThread]: SQL status: SELECT 1 in 0.023 seconds
[0m11:31:32.834614 [debug] [MainThread]: On debug: Close
[0m11:31:32.835825 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m11:31:32.837667 [info ] [MainThread]: [32mAll checks passed![0m
[0m11:31:32.839499 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 0.81695485, "process_user_time": 3.602691, "process_kernel_time": 0.195657, "process_mem_max_rss": "100360", "process_out_blocks": "8", "process_in_blocks": "0"}
[0m11:31:32.840923 [debug] [MainThread]: Command `dbt debug` succeeded at 11:31:32.840647 after 0.82 seconds
[0m11:31:32.841683 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m11:31:32.842937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d600231a150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d6000ece270>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d600169d970>]}
[0m11:31:32.844311 [debug] [MainThread]: Flushing usage events
[0m11:39:27.831537 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d3bba2c17f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d3bba77d5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d3bba66d160>]}


============================== 11:39:27.837257 | ef78f95f-3608-40fc-b6e1-9edea04dbf96 ==============================
[0m11:39:27.837257 [info ] [MainThread]: Running with dbt=1.8.5
[0m11:39:27.838543 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse', 'debug': 'False', 'warn_error': 'None', 'log_path': '/home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run -s payment', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:39:28.237482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ef78f95f-3608-40fc-b6e1-9edea04dbf96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d3bba2c18b0>]}
[0m11:39:28.404622 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ef78f95f-3608-40fc-b6e1-9edea04dbf96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d3bbb251640>]}
[0m11:39:28.406497 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m11:39:28.436530 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m11:39:28.440636 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:39:28.442224 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ef78f95f-3608-40fc-b6e1-9edea04dbf96', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d3bba4e9fa0>]}
[0m11:39:31.466925 [error] [MainThread]: Encountered an error:
Parsing Error
  Invalid sources config given in models/raw/sources.yml @ sources: {'name': 'public', 'database': 'data_warehouse', 'schema': 'public', 'tables': [{'name': 'payment'}, 'payment', {'name': 'rental'}, {'name': 'staff'}, {'name': 'customer'}, {'name': 'address'}, {'name': 'inventory'}, {'name': 'film'}, {'name': 'film_actor'}, {'name': 'actor'}]} - at path ['tables'][1]: 'payment' is not of type 'object'
[0m11:39:31.469218 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 3.748629, "process_user_time": 6.521657, "process_kernel_time": 0.264929, "process_mem_max_rss": "98224", "process_in_blocks": "32", "process_out_blocks": "16", "command_success": false}
[0m11:39:31.470979 [debug] [MainThread]: Command `dbt run` failed at 11:39:31.470716 after 3.75 seconds
[0m11:39:31.472079 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d3bbae6f4a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d3bb99333b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d3bb8b458b0>]}
[0m11:39:31.473143 [debug] [MainThread]: Flushing usage events
[0m11:40:14.814239 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748afb01c140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748afa52c5f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748afa055730>]}


============================== 11:40:14.822428 | 691119df-9e0d-459a-b0b0-3e8bda47f326 ==============================
[0m11:40:14.822428 [info ] [MainThread]: Running with dbt=1.8.5
[0m11:40:14.824659 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse', 'debug': 'False', 'warn_error': 'None', 'log_path': '/home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run -s payment', 'send_anonymous_usage_stats': 'True'}
[0m11:40:15.328041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '691119df-9e0d-459a-b0b0-3e8bda47f326', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748afa057410>]}
[0m11:40:15.510914 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '691119df-9e0d-459a-b0b0-3e8bda47f326', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748afb62ffe0>]}
[0m11:40:15.512704 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m11:40:15.543720 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m11:40:15.545979 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:40:15.547391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '691119df-9e0d-459a-b0b0-3e8bda47f326', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748afa94a420>]}
[0m11:40:19.056919 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '691119df-9e0d-459a-b0b0-3e8bda47f326', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748af9092540>]}
[0m11:40:19.320831 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '691119df-9e0d-459a-b0b0-3e8bda47f326', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748af8f603e0>]}
[0m11:40:19.321943 [info ] [MainThread]: Found 3 models, 4 data tests, 9 sources, 417 macros
[0m11:40:19.322928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '691119df-9e0d-459a-b0b0-3e8bda47f326', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748afb350e90>]}
[0m11:40:19.326420 [info ] [MainThread]: 
[0m11:40:19.327881 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:40:19.330263 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m11:40:19.447938 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m11:40:19.449446 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m11:40:19.451709 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:40:19.482013 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.030 seconds
[0m11:40:19.486513 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m11:40:19.488951 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse, now create_data_warehouse_dbt_dev_raw)
[0m11:40:19.490691 [debug] [ThreadPool]: Creating schema "database: "data_warehouse"
schema: "dbt_dev_raw"
"
[0m11:40:19.504173 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_raw"
[0m11:40:19.505465 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_raw: BEGIN
[0m11:40:19.506175 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:40:19.525102 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m11:40:19.525848 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_raw"
[0m11:40:19.526481 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "create_data_warehouse_dbt_dev_raw"} */
create schema if not exists "dbt_dev_raw"
[0m11:40:19.527922 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m11:40:19.530136 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_raw: COMMIT
[0m11:40:19.530865 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_raw"
[0m11:40:19.531482 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_raw: COMMIT
[0m11:40:19.533286 [debug] [ThreadPool]: SQL status: COMMIT in 0.001 seconds
[0m11:40:19.534167 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_raw: Close
[0m11:40:19.543055 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_data_warehouse_dbt_dev_raw, now list_data_warehouse_dbt_dev)
[0m11:40:19.559287 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m11:40:19.560292 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m11:40:19.561427 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:40:19.582710 [debug] [ThreadPool]: SQL status: BEGIN in 0.021 seconds
[0m11:40:19.584014 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m11:40:19.585288 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m11:40:19.591649 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m11:40:19.594443 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m11:40:19.595532 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m11:40:19.597237 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_raw)
[0m11:40:19.604548 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m11:40:19.605900 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m11:40:19.606591 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:40:19.631788 [debug] [ThreadPool]: SQL status: BEGIN in 0.025 seconds
[0m11:40:19.633320 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m11:40:19.635516 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m11:40:19.643036 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m11:40:19.647235 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m11:40:19.648868 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m11:40:19.663344 [debug] [MainThread]: Using postgres connection "master"
[0m11:40:19.664243 [debug] [MainThread]: On master: BEGIN
[0m11:40:19.665728 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:40:19.696391 [debug] [MainThread]: SQL status: BEGIN in 0.031 seconds
[0m11:40:19.698024 [debug] [MainThread]: Using postgres connection "master"
[0m11:40:19.699841 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:40:19.731548 [debug] [MainThread]: SQL status: SELECT 37 in 0.028 seconds
[0m11:40:19.739446 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '691119df-9e0d-459a-b0b0-3e8bda47f326', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748afb48f2f0>]}
[0m11:40:19.741374 [debug] [MainThread]: On master: ROLLBACK
[0m11:40:19.743138 [debug] [MainThread]: Using postgres connection "master"
[0m11:40:19.744494 [debug] [MainThread]: On master: BEGIN
[0m11:40:19.746110 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m11:40:19.747313 [debug] [MainThread]: On master: COMMIT
[0m11:40:19.748358 [debug] [MainThread]: Using postgres connection "master"
[0m11:40:19.749488 [debug] [MainThread]: On master: COMMIT
[0m11:40:19.751436 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:40:19.753007 [debug] [MainThread]: On master: Close
[0m11:40:19.756107 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:40:19.757536 [info ] [MainThread]: 
[0m11:40:19.763504 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m11:40:19.765348 [info ] [Thread-1 (]: 1 of 1 START sql table model dbt_dev_raw.payment ............................... [RUN]
[0m11:40:19.766644 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_raw, now model.data_warehouse.payment)
[0m11:40:19.769066 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m11:40:19.798307 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m11:40:19.801433 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m11:40:20.037527 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.payment"
[0m11:40:20.039847 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m11:40:20.041308 [debug] [Thread-1 (]: On model.data_warehouse.payment: BEGIN
[0m11:40:20.042340 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:40:20.071408 [debug] [Thread-1 (]: SQL status: BEGIN in 0.029 seconds
[0m11:40:20.072841 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m11:40:20.074181 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."payment"
  );
  
[0m11:40:20.095178 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.020 seconds
[0m11:40:20.107865 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m11:40:20.108859 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m11:40:20.110774 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:40:20.162161 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m11:40:20.163613 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m11:40:20.164639 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m11:40:20.170693 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m11:40:20.187332 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m11:40:20.210953 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m11:40:20.213447 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m11:40:20.216115 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m11:40:20.223920 [debug] [Thread-1 (]: On model.data_warehouse.payment: Close
[0m11:40:20.231112 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '691119df-9e0d-459a-b0b0-3e8bda47f326', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748af8f46570>]}
[0m11:40:20.233110 [info ] [Thread-1 (]: 1 of 1 OK created sql table model dbt_dev_raw.payment .......................... [[32mSELECT 14596[0m in 0.46s]
[0m11:40:20.235476 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m11:40:20.237764 [debug] [MainThread]: Using postgres connection "master"
[0m11:40:20.239165 [debug] [MainThread]: On master: BEGIN
[0m11:40:20.240508 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:40:20.266708 [debug] [MainThread]: SQL status: BEGIN in 0.026 seconds
[0m11:40:20.268497 [debug] [MainThread]: On master: COMMIT
[0m11:40:20.270368 [debug] [MainThread]: Using postgres connection "master"
[0m11:40:20.271469 [debug] [MainThread]: On master: COMMIT
[0m11:40:20.273102 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:40:20.274287 [debug] [MainThread]: On master: Close
[0m11:40:20.276007 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:40:20.276808 [debug] [MainThread]: Connection 'model.data_warehouse.payment' was properly closed.
[0m11:40:20.277760 [info ] [MainThread]: 
[0m11:40:20.279054 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 0.95 seconds (0.95s).
[0m11:40:20.280738 [debug] [MainThread]: Command end result
[0m11:40:20.367582 [info ] [MainThread]: 
[0m11:40:20.368768 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:40:20.369929 [info ] [MainThread]: 
[0m11:40:20.371135 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m11:40:20.372798 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.7002554, "process_user_time": 8.697939, "process_kernel_time": 0.305681, "process_mem_max_rss": "113032", "process_in_blocks": "128", "process_out_blocks": "2576"}
[0m11:40:20.374228 [debug] [MainThread]: Command `dbt run` succeeded at 11:40:20.373920 after 5.70 seconds
[0m11:40:20.375716 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748afa34bda0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748afdcc7a40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x748af8ac3a70>]}
[0m11:40:20.376808 [debug] [MainThread]: Flushing usage events
[0m11:45:11.551802 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76557b9155b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x765578d29c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x765579573290>]}


============================== 11:45:11.560953 | 2430004d-7c16-448f-a2f7-2a885eb95cb2 ==============================
[0m11:45:11.560953 [info ] [MainThread]: Running with dbt=1.8.5
[0m11:45:11.563413 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m11:45:11.990562 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2430004d-7c16-448f-a2f7-2a885eb95cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x765578ab0830>]}
[0m11:45:12.129409 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2430004d-7c16-448f-a2f7-2a885eb95cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x765579ac9f70>]}
[0m11:45:12.131149 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m11:45:12.162250 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m11:45:12.514555 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 8 files added, 0 files changed.
[0m11:45:12.515840 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models/raw/inventory.sql
[0m11:45:12.516819 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models/raw/staff.sql
[0m11:45:12.517769 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models/raw/rental.sql
[0m11:45:12.518562 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models/raw/film_actor.sql
[0m11:45:12.519367 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models/raw/customer.sql
[0m11:45:12.520152 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models/raw/address.sql
[0m11:45:12.521353 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models/raw/actor.sql
[0m11:45:12.522329 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models/raw/film.sql
[0m11:45:13.284640 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2430004d-7c16-448f-a2f7-2a885eb95cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x765577da5a30>]}
[0m11:45:13.638925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2430004d-7c16-448f-a2f7-2a885eb95cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x765577c30830>]}
[0m11:45:13.640724 [info ] [MainThread]: Found 11 models, 4 data tests, 9 sources, 417 macros
[0m11:45:13.642325 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2430004d-7c16-448f-a2f7-2a885eb95cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x765577c76d80>]}
[0m11:45:13.649580 [info ] [MainThread]: 
[0m11:45:13.651497 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:45:13.668564 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m11:45:13.802420 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m11:45:13.803767 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m11:45:13.805126 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:45:13.835945 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.031 seconds
[0m11:45:13.839447 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m11:45:13.847176 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m11:45:13.849344 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m11:45:13.850210 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:45:13.875831 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.026 seconds
[0m11:45:13.878672 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m11:45:13.880454 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse, now create_data_warehouse_dbt_dev)
[0m11:45:13.882450 [debug] [ThreadPool]: Creating schema "database: "data_warehouse"
schema: "dbt_dev"
"
[0m11:45:13.895717 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev"
[0m11:45:13.897174 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev: BEGIN
[0m11:45:13.898602 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:45:13.920572 [debug] [ThreadPool]: SQL status: BEGIN in 0.022 seconds
[0m11:45:13.921412 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev"
[0m11:45:13.922322 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "create_data_warehouse_dbt_dev"} */
create schema if not exists "dbt_dev"
[0m11:45:13.924488 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m11:45:13.928252 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev: COMMIT
[0m11:45:13.929739 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev"
[0m11:45:13.931159 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev: COMMIT
[0m11:45:13.934264 [debug] [ThreadPool]: SQL status: COMMIT in 0.002 seconds
[0m11:45:13.935644 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev: Close
[0m11:45:13.942367 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_raw)
[0m11:45:13.956920 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m11:45:13.958063 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m11:45:13.959028 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:45:13.982692 [debug] [ThreadPool]: SQL status: BEGIN in 0.024 seconds
[0m11:45:13.983876 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m11:45:13.984852 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m11:45:13.991860 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.006 seconds
[0m11:45:13.996359 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m11:45:13.998687 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m11:45:14.000488 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_raw, now list_data_warehouse_dbt_dev)
[0m11:45:14.009680 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m11:45:14.011229 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m11:45:14.012410 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:45:14.036357 [debug] [ThreadPool]: SQL status: BEGIN in 0.024 seconds
[0m11:45:14.037156 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m11:45:14.037982 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m11:45:14.047133 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.008 seconds
[0m11:45:14.049529 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m11:45:14.050537 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m11:45:14.063251 [debug] [MainThread]: Using postgres connection "master"
[0m11:45:14.064453 [debug] [MainThread]: On master: BEGIN
[0m11:45:14.065134 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:45:14.085743 [debug] [MainThread]: SQL status: BEGIN in 0.021 seconds
[0m11:45:14.086484 [debug] [MainThread]: Using postgres connection "master"
[0m11:45:14.087455 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:45:14.118153 [debug] [MainThread]: SQL status: SELECT 37 in 0.030 seconds
[0m11:45:14.122949 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2430004d-7c16-448f-a2f7-2a885eb95cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x765577c7a1e0>]}
[0m11:45:14.124452 [debug] [MainThread]: On master: ROLLBACK
[0m11:45:14.125662 [debug] [MainThread]: Using postgres connection "master"
[0m11:45:14.126868 [debug] [MainThread]: On master: BEGIN
[0m11:45:14.128211 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m11:45:14.129204 [debug] [MainThread]: On master: COMMIT
[0m11:45:14.129935 [debug] [MainThread]: Using postgres connection "master"
[0m11:45:14.130570 [debug] [MainThread]: On master: COMMIT
[0m11:45:14.131478 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:45:14.132376 [debug] [MainThread]: On master: Close
[0m11:45:14.133888 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:45:14.135029 [info ] [MainThread]: 
[0m11:45:14.139736 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m11:45:14.141527 [info ] [Thread-1 (]: 1 of 11 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m11:45:14.143789 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now model.data_warehouse.actor)
[0m11:45:14.145156 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m11:45:14.174250 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m11:45:14.177807 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m11:45:14.304049 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.actor"
[0m11:45:14.305459 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m11:45:14.307271 [debug] [Thread-1 (]: On model.data_warehouse.actor: BEGIN
[0m11:45:14.308786 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:45:14.331555 [debug] [Thread-1 (]: SQL status: BEGIN in 0.023 seconds
[0m11:45:14.332603 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m11:45:14.333336 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."actor"
  );
  
[0m11:45:14.336754 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.003 seconds
[0m11:45:14.349047 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m11:45:14.350267 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m11:45:14.351686 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:45:14.411870 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m11:45:14.414726 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m11:45:14.416614 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m11:45:14.420743 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m11:45:14.455991 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m11:45:14.478527 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m11:45:14.480707 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m11:45:14.483288 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m11:45:14.493106 [debug] [Thread-1 (]: On model.data_warehouse.actor: Close
[0m11:45:14.499622 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2430004d-7c16-448f-a2f7-2a885eb95cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76557a283110>]}
[0m11:45:14.502632 [info ] [Thread-1 (]: 1 of 11 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.35s]
[0m11:45:14.505444 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m11:45:14.507666 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m11:45:14.510538 [info ] [Thread-1 (]: 2 of 11 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m11:45:14.513064 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m11:45:14.515295 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m11:45:14.529902 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m11:45:14.532457 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m11:45:14.548904 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.address"
[0m11:45:14.551616 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m11:45:14.553587 [debug] [Thread-1 (]: On model.data_warehouse.address: BEGIN
[0m11:45:14.555495 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:45:14.607708 [debug] [Thread-1 (]: SQL status: BEGIN in 0.052 seconds
[0m11:45:14.609895 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m11:45:14.614037 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."address"
  );
  
[0m11:45:14.624617 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.008 seconds
[0m11:45:14.636448 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m11:45:14.639027 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m11:45:14.642684 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:45:14.654037 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m11:45:14.656551 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m11:45:14.658236 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m11:45:14.665846 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m11:45:14.686151 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."address__dbt_backup"
[0m11:45:14.692802 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m11:45:14.700006 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m11:45:14.707051 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m11:45:14.716481 [debug] [Thread-1 (]: On model.data_warehouse.address: Close
[0m11:45:14.724839 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2430004d-7c16-448f-a2f7-2a885eb95cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x765576f276e0>]}
[0m11:45:14.729640 [info ] [Thread-1 (]: 2 of 11 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.21s]
[0m11:45:14.735136 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m11:45:14.739669 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m11:45:14.742236 [info ] [Thread-1 (]: 3 of 11 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m11:45:14.745268 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m11:45:14.747614 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m11:45:14.762612 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m11:45:14.765245 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m11:45:14.793461 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.customer"
[0m11:45:14.796210 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m11:45:14.798274 [debug] [Thread-1 (]: On model.data_warehouse.customer: BEGIN
[0m11:45:14.800427 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:45:14.855743 [debug] [Thread-1 (]: SQL status: BEGIN in 0.055 seconds
[0m11:45:14.858045 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m11:45:14.862324 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."customer"
  );
  
[0m11:45:14.871692 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.007 seconds
[0m11:45:14.885096 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m11:45:14.886718 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m11:45:14.891422 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:45:14.901945 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m11:45:14.904327 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m11:45:14.906270 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m11:45:14.909698 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m11:45:14.922026 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m11:45:14.927099 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m11:45:14.928902 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m11:45:14.931978 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m11:45:14.940146 [debug] [Thread-1 (]: On model.data_warehouse.customer: Close
[0m11:45:14.943643 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2430004d-7c16-448f-a2f7-2a885eb95cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x765576f46c00>]}
[0m11:45:14.947528 [info ] [Thread-1 (]: 3 of 11 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.20s]
[0m11:45:14.950838 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m11:45:14.952148 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m11:45:14.953961 [info ] [Thread-1 (]: 4 of 11 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m11:45:14.955482 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m11:45:14.957828 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m11:45:14.969360 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m11:45:14.971365 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m11:45:14.990458 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film"
[0m11:45:14.993329 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m11:45:14.996296 [debug] [Thread-1 (]: On model.data_warehouse.film: BEGIN
[0m11:45:14.998030 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:45:15.031327 [debug] [Thread-1 (]: SQL status: BEGIN in 0.033 seconds
[0m11:45:15.032956 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m11:45:15.034580 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."film"
  );
  
[0m11:45:15.046080 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.010 seconds
[0m11:45:15.052824 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m11:45:15.054515 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m11:45:15.057710 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:45:15.063164 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m11:45:15.065065 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m11:45:15.066469 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m11:45:15.073348 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m11:45:15.082953 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film__dbt_backup"
[0m11:45:15.086951 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m11:45:15.088615 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m11:45:15.091773 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m11:45:15.097147 [debug] [Thread-1 (]: On model.data_warehouse.film: Close
[0m11:45:15.099754 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2430004d-7c16-448f-a2f7-2a885eb95cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x765576f46cf0>]}
[0m11:45:15.105166 [info ] [Thread-1 (]: 4 of 11 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.14s]
[0m11:45:15.109030 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m11:45:15.111340 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m11:45:15.113455 [info ] [Thread-1 (]: 5 of 11 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m11:45:15.116110 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m11:45:15.119858 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m11:45:15.135334 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m11:45:15.137900 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m11:45:15.154862 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film_actor"
[0m11:45:15.159772 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m11:45:15.162503 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: BEGIN
[0m11:45:15.167244 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:45:15.206743 [debug] [Thread-1 (]: SQL status: BEGIN in 0.040 seconds
[0m11:45:15.209292 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m11:45:15.211083 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."film_actor"
  );
  
[0m11:45:15.225903 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.013 seconds
[0m11:45:15.237338 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m11:45:15.239362 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m11:45:15.242522 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:45:15.249093 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m11:45:15.250927 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m11:45:15.252833 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m11:45:15.257719 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m11:45:15.268599 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m11:45:15.271690 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m11:45:15.273646 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m11:45:15.276125 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m11:45:15.282740 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: Close
[0m11:45:15.286162 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2430004d-7c16-448f-a2f7-2a885eb95cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76557709dd00>]}
[0m11:45:15.288516 [info ] [Thread-1 (]: 5 of 11 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.17s]
[0m11:45:15.293008 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m11:45:15.296042 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m11:45:15.300703 [info ] [Thread-1 (]: 6 of 11 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m11:45:15.303011 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m11:45:15.304648 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m11:45:15.318411 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m11:45:15.321559 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m11:45:15.345172 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.inventory"
[0m11:45:15.347815 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m11:45:15.349577 [debug] [Thread-1 (]: On model.data_warehouse.inventory: BEGIN
[0m11:45:15.351320 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:45:15.396273 [debug] [Thread-1 (]: SQL status: BEGIN in 0.045 seconds
[0m11:45:15.398520 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m11:45:15.400669 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."inventory"
  );
  
[0m11:45:15.418592 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.016 seconds
[0m11:45:15.432805 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m11:45:15.434505 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m11:45:15.437376 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:45:15.443086 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m11:45:15.444454 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m11:45:15.445731 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m11:45:15.449269 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m11:45:15.454357 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m11:45:15.457572 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m11:45:15.459586 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m11:45:15.460961 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m11:45:15.463932 [debug] [Thread-1 (]: On model.data_warehouse.inventory: Close
[0m11:45:15.465478 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2430004d-7c16-448f-a2f7-2a885eb95cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x765576f61cd0>]}
[0m11:45:15.467255 [info ] [Thread-1 (]: 6 of 11 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.16s]
[0m11:45:15.468980 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m11:45:15.470731 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m11:45:15.472657 [info ] [Thread-1 (]: 7 of 11 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m11:45:15.474617 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m11:45:15.476382 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m11:45:15.485319 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m11:45:15.487158 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m11:45:15.501082 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_first_dbt_model"
[0m11:45:15.503675 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m11:45:15.505676 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: BEGIN
[0m11:45:15.507783 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:45:15.554317 [debug] [Thread-1 (]: SQL status: BEGIN in 0.046 seconds
[0m11:45:15.557727 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m11:45:15.559982 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */

  
    

  create  table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m11:45:15.566504 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.004 seconds
[0m11:45:15.574947 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m11:45:15.576913 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m11:45:15.579648 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:45:15.583737 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m11:45:15.585078 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m11:45:15.586020 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m11:45:15.589526 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m11:45:15.595701 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m11:45:15.599120 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m11:45:15.600864 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
drop table if exists "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m11:45:15.603101 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m11:45:15.610508 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: Close
[0m11:45:15.613075 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2430004d-7c16-448f-a2f7-2a885eb95cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x76557718ea50>]}
[0m11:45:15.615245 [info ] [Thread-1 (]: 7 of 11 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.14s]
[0m11:45:15.617458 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m11:45:15.619817 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m11:45:15.623414 [info ] [Thread-1 (]: 8 of 11 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m11:45:15.625807 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m11:45:15.628510 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m11:45:15.642317 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m11:45:15.645081 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m11:45:15.671342 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.payment"
[0m11:45:15.676878 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m11:45:15.679455 [debug] [Thread-1 (]: On model.data_warehouse.payment: BEGIN
[0m11:45:15.681945 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:45:15.715739 [debug] [Thread-1 (]: SQL status: BEGIN in 0.034 seconds
[0m11:45:15.717145 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m11:45:15.719052 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."payment"
  );
  
[0m11:45:15.750078 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.030 seconds
[0m11:45:15.759875 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m11:45:15.761045 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m11:45:15.762943 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:45:15.778585 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m11:45:15.780133 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m11:45:15.781985 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:45:15.797398 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m11:45:15.798613 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m11:45:15.799923 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m11:45:15.804413 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m11:45:15.816237 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m11:45:15.818379 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m11:45:15.819448 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m11:45:15.824594 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m11:45:15.829630 [debug] [Thread-1 (]: On model.data_warehouse.payment: Close
[0m11:45:15.832040 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2430004d-7c16-448f-a2f7-2a885eb95cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x765576f0aab0>]}
[0m11:45:15.835296 [info ] [Thread-1 (]: 8 of 11 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.21s]
[0m11:45:15.838061 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m11:45:15.839996 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m11:45:15.842089 [info ] [Thread-1 (]: 9 of 11 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m11:45:15.843981 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m11:45:15.846702 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m11:45:15.858844 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m11:45:15.860871 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m11:45:15.879296 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.rental"
[0m11:45:15.881444 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m11:45:15.883880 [debug] [Thread-1 (]: On model.data_warehouse.rental: BEGIN
[0m11:45:15.885957 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:45:15.930895 [debug] [Thread-1 (]: SQL status: BEGIN in 0.045 seconds
[0m11:45:15.933351 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m11:45:15.936992 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."rental"
  );
  
[0m11:45:15.982840 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.044 seconds
[0m11:45:15.993831 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m11:45:15.995320 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m11:45:15.997930 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:45:16.004527 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m11:45:16.006070 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m11:45:16.007539 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m11:45:16.016115 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m11:45:16.028403 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m11:45:16.033448 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m11:45:16.035552 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m11:45:16.037344 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m11:45:16.044335 [debug] [Thread-1 (]: On model.data_warehouse.rental: Close
[0m11:45:16.047127 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2430004d-7c16-448f-a2f7-2a885eb95cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x765576f09ee0>]}
[0m11:45:16.050738 [info ] [Thread-1 (]: 9 of 11 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.20s]
[0m11:45:16.053875 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m11:45:16.058669 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m11:45:16.061920 [info ] [Thread-1 (]: 10 of 11 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m11:45:16.065510 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m11:45:16.067634 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m11:45:16.081790 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m11:45:16.084012 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m11:45:16.099368 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.staff"
[0m11:45:16.103013 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m11:45:16.106267 [debug] [Thread-1 (]: On model.data_warehouse.staff: BEGIN
[0m11:45:16.108180 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:45:16.145647 [debug] [Thread-1 (]: SQL status: BEGIN in 0.037 seconds
[0m11:45:16.147316 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m11:45:16.149008 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."staff"
  );
  
[0m11:45:16.157734 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.007 seconds
[0m11:45:16.170331 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m11:45:16.175307 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m11:45:16.181820 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.005 seconds
[0m11:45:16.195605 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m11:45:16.198336 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m11:45:16.200073 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m11:45:16.208674 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m11:45:16.218718 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m11:45:16.222032 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m11:45:16.224364 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m11:45:16.227867 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m11:45:16.233808 [debug] [Thread-1 (]: On model.data_warehouse.staff: Close
[0m11:45:16.236048 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2430004d-7c16-448f-a2f7-2a885eb95cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7655770fc080>]}
[0m11:45:16.238618 [info ] [Thread-1 (]: 10 of 11 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.17s]
[0m11:45:16.242282 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m11:45:16.244767 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m11:45:16.248336 [info ] [Thread-1 (]: 11 of 11 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m11:45:16.252107 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.my_second_dbt_model)
[0m11:45:16.253838 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m11:45:16.266137 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m11:45:16.269216 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m11:45:16.390514 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_second_dbt_model"
[0m11:45:16.393039 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m11:45:16.395479 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: BEGIN
[0m11:45:16.398101 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:45:16.443020 [debug] [Thread-1 (]: SQL status: BEGIN in 0.045 seconds
[0m11:45:16.445111 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m11:45:16.447409 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */

  create view "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "data_warehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m11:45:16.453461 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.004 seconds
[0m11:45:16.464844 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m11:45:16.466698 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m11:45:16.476530 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:45:16.482851 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m11:45:16.484916 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m11:45:16.486911 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m11:45:16.491120 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m11:45:16.499911 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m11:45:16.513588 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m11:45:16.515442 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
drop view if exists "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m11:45:16.517683 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m11:45:16.523868 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: Close
[0m11:45:16.528747 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2430004d-7c16-448f-a2f7-2a885eb95cb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x765576f97c80>]}
[0m11:45:16.533363 [info ] [Thread-1 (]: 11 of 11 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.28s]
[0m11:45:16.538158 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m11:45:16.545728 [debug] [MainThread]: Using postgres connection "master"
[0m11:45:16.548808 [debug] [MainThread]: On master: BEGIN
[0m11:45:16.555147 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:45:16.618825 [debug] [MainThread]: SQL status: BEGIN in 0.064 seconds
[0m11:45:16.620303 [debug] [MainThread]: On master: COMMIT
[0m11:45:16.628466 [debug] [MainThread]: Using postgres connection "master"
[0m11:45:16.631607 [debug] [MainThread]: On master: COMMIT
[0m11:45:16.639304 [debug] [MainThread]: SQL status: COMMIT in 0.006 seconds
[0m11:45:16.642564 [debug] [MainThread]: On master: Close
[0m11:45:16.646760 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:45:16.650289 [debug] [MainThread]: Connection 'model.data_warehouse.my_second_dbt_model' was properly closed.
[0m11:45:16.652956 [info ] [MainThread]: 
[0m11:45:16.655782 [info ] [MainThread]: Finished running 10 table models, 1 view model in 0 hours 0 minutes and 3.00 seconds (3.00s).
[0m11:45:16.664297 [debug] [MainThread]: Command end result
[0m11:45:16.911926 [info ] [MainThread]: 
[0m11:45:16.913734 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:45:16.915555 [info ] [MainThread]: 
[0m11:45:16.916799 [info ] [MainThread]: Done. PASS=11 WARN=0 ERROR=0 SKIP=0 TOTAL=11
[0m11:45:16.919087 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.5971007, "process_user_time": 7.214352, "process_kernel_time": 0.340066, "process_mem_max_rss": "111472", "process_in_blocks": "32", "process_out_blocks": "2928"}
[0m11:45:16.921455 [debug] [MainThread]: Command `dbt run` succeeded at 11:45:16.921028 after 5.60 seconds
[0m11:45:16.923313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x765578c790a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7655795730b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7655775fb2c0>]}
[0m11:45:16.925005 [debug] [MainThread]: Flushing usage events
[0m20:37:20.404943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b56a74184d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b56a7591580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b56a752c140>]}


============================== 20:37:20.408656 | 553577ee-2da5-49b4-a20f-bc9e8b0a076e ==============================
[0m20:37:20.408656 [info ] [MainThread]: Running with dbt=1.8.5
[0m20:37:20.409928 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse/logs', 'debug': 'False', 'profiles_dir': '/home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt compile', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m20:37:20.636302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '553577ee-2da5-49b4-a20f-bc9e8b0a076e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b56a73df3b0>]}
[0m20:37:20.699328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '553577ee-2da5-49b4-a20f-bc9e8b0a076e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b56a85d9ac0>]}
[0m20:37:20.700674 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m20:37:20.712302 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m20:37:20.875376 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 12 files added, 0 files changed.
[0m20:37:20.876124 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models/intermediate/dim_film_actor.sql
[0m20:37:20.876648 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models/intermediate/dim_film.sql
[0m20:37:20.877090 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models/mart/total_revenue.sql
[0m20:37:20.877524 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models/intermediate/dim_rental.sql
[0m20:37:20.877967 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models/intermediate/dim_address.sql
[0m20:37:20.878392 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models/mart/best_selling.sql
[0m20:37:20.878888 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models/intermediate/dim_customer.sql
[0m20:37:20.879310 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models/intermediate/fact_payment.sql
[0m20:37:20.879747 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models/intermediate/dim_staff.sql
[0m20:37:20.880446 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models/mart/most_actor.sql
[0m20:37:20.880924 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models/intermediate/dim_inventory.sql
[0m20:37:20.881350 [debug] [MainThread]: Partial parsing: added file: data_warehouse://models/intermediate/dim_actor.sql
[0m20:37:21.190828 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '553577ee-2da5-49b4-a20f-bc9e8b0a076e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b56a73310d0>]}
[0m20:37:21.322990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '553577ee-2da5-49b4-a20f-bc9e8b0a076e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b56a6dc4290>]}
[0m20:37:21.323586 [info ] [MainThread]: Found 23 models, 4 data tests, 9 sources, 417 macros
[0m20:37:21.324125 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '553577ee-2da5-49b4-a20f-bc9e8b0a076e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b56a66a3ce0>]}
[0m20:37:21.327103 [info ] [MainThread]: 
[0m20:37:21.327936 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:37:21.334922 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse_dbt_dev'
[0m20:37:21.384381 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m20:37:21.384900 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m20:37:21.385296 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:37:21.418188 [debug] [ThreadPool]: SQL status: BEGIN in 0.033 seconds
[0m20:37:21.418708 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m20:37:21.419136 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m20:37:21.438625 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.019 seconds
[0m20:37:21.440291 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m20:37:21.440962 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m20:37:21.441751 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_mart)
[0m20:37:21.444451 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m20:37:21.444918 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: BEGIN
[0m20:37:21.445307 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:37:21.456000 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m20:37:21.456513 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m20:37:21.457023 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_mart"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m20:37:21.460082 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m20:37:21.461582 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: ROLLBACK
[0m20:37:21.462258 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: Close
[0m20:37:21.463041 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_mart, now list_data_warehouse_dbt_dev_intermediate)
[0m20:37:21.466612 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediate"
[0m20:37:21.467121 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: BEGIN
[0m20:37:21.467540 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:37:21.478310 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m20:37:21.478844 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediate"
[0m20:37:21.479365 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediate"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediate'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediate'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediate'
  
[0m20:37:21.482715 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m20:37:21.484176 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: ROLLBACK
[0m20:37:21.484817 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: Close
[0m20:37:21.485690 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_intermediate, now list_data_warehouse_dbt_dev_raw)
[0m20:37:21.487909 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m20:37:21.488394 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m20:37:21.488869 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:37:21.499672 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m20:37:21.500167 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m20:37:21.500655 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m20:37:21.503894 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m20:37:21.505750 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m20:37:21.506437 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m20:37:21.514838 [debug] [MainThread]: Using postgres connection "master"
[0m20:37:21.515298 [debug] [MainThread]: On master: BEGIN
[0m20:37:21.515804 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:37:21.526133 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m20:37:21.526624 [debug] [MainThread]: Using postgres connection "master"
[0m20:37:21.527130 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:37:21.545476 [debug] [MainThread]: SQL status: SELECT 38 in 0.018 seconds
[0m20:37:21.548467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '553577ee-2da5-49b4-a20f-bc9e8b0a076e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b56a895c0e0>]}
[0m20:37:21.548997 [debug] [MainThread]: On master: ROLLBACK
[0m20:37:21.549583 [debug] [MainThread]: On master: Close
[0m20:37:21.550357 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:37:21.551310 [info ] [MainThread]: 
[0m20:37:21.555018 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m20:37:21.555933 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_raw, now model.data_warehouse.actor)
[0m20:37:21.556749 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m20:37:21.568927 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m20:37:21.569957 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m20:37:21.571605 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m20:37:21.572302 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m20:37:21.573069 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m20:37:21.573625 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m20:37:21.576708 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m20:37:21.577586 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m20:37:21.580321 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m20:37:21.581466 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m20:37:21.582682 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m20:37:21.583803 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m20:37:21.587614 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m20:37:21.588328 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m20:37:21.589187 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m20:37:21.589704 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m20:37:21.590306 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m20:37:21.590773 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m20:37:21.593680 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m20:37:21.594669 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m20:37:21.597291 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m20:37:21.598371 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m20:37:21.599118 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m20:37:21.599909 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m20:37:21.603315 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m20:37:21.604051 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m20:37:21.604914 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m20:37:21.605420 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m20:37:21.606042 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m20:37:21.606590 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m20:37:21.609830 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m20:37:21.610653 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m20:37:21.611775 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m20:37:21.612340 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m20:37:21.612987 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m20:37:21.613559 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m20:37:21.616250 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m20:37:21.616974 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m20:37:21.617819 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m20:37:21.618331 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m20:37:21.619039 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m20:37:21.619491 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m20:37:21.624386 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m20:37:21.625506 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m20:37:21.627049 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m20:37:21.627980 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m20:37:21.628876 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m20:37:21.629533 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m20:37:21.633907 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m20:37:21.634780 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m20:37:21.635808 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m20:37:21.636437 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m20:37:21.637160 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m20:37:21.637712 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m20:37:21.640892 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m20:37:21.641772 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m20:37:21.644542 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m20:37:21.645182 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m20:37:21.645717 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m20:37:21.646210 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m20:37:21.648966 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m20:37:21.650033 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m20:37:21.650922 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m20:37:21.651461 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m20:37:21.651991 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m20:37:21.652527 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m20:37:21.655453 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m20:37:21.656245 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m20:37:21.657228 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m20:37:21.657760 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m20:37:21.658265 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m20:37:21.658766 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m20:37:21.661647 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m20:37:21.662389 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m20:37:21.663334 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m20:37:21.663959 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m20:37:21.664501 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m20:37:21.665017 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m20:37:21.667953 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m20:37:21.668724 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m20:37:21.669631 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m20:37:21.670164 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m20:37:21.670683 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m20:37:21.671179 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m20:37:21.674121 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m20:37:21.674928 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m20:37:21.675885 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m20:37:21.676421 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m20:37:21.676955 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.dim_inventory)
[0m20:37:21.677495 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m20:37:21.680439 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m20:37:21.681235 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m20:37:21.682168 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m20:37:21.682711 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m20:37:21.683230 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m20:37:21.683732 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m20:37:21.686431 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m20:37:21.687301 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m20:37:21.688277 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m20:37:21.688843 [debug] [Thread-1 (]: Began running node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m20:37:21.689361 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710)
[0m20:37:21.689872 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m20:37:21.702748 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710"
[0m20:37:21.703717 [debug] [Thread-1 (]: Began executing node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m20:37:21.704639 [debug] [Thread-1 (]: Finished running node test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710
[0m20:37:21.705176 [debug] [Thread-1 (]: Began running node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m20:37:21.705698 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.not_null_my_first_dbt_model_id.5fb22c2710, now test.data_warehouse.unique_my_first_dbt_model_id.16e066b321)
[0m20:37:21.706192 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m20:37:21.712785 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.unique_my_first_dbt_model_id.16e066b321"
[0m20:37:21.713545 [debug] [Thread-1 (]: Began executing node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m20:37:21.714536 [debug] [Thread-1 (]: Finished running node test.data_warehouse.unique_my_first_dbt_model_id.16e066b321
[0m20:37:21.715088 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m20:37:21.715615 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.unique_my_first_dbt_model_id.16e066b321, now model.data_warehouse.fact_payment)
[0m20:37:21.716159 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m20:37:21.719168 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m20:37:21.719948 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m20:37:21.721100 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m20:37:21.722064 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m20:37:21.722888 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.dim_rental)
[0m20:37:21.723748 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m20:37:21.727676 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m20:37:21.728337 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m20:37:21.729164 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m20:37:21.729693 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m20:37:21.730245 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m20:37:21.730894 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m20:37:21.734086 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m20:37:21.734851 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m20:37:21.736159 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m20:37:21.737058 [debug] [Thread-1 (]: Began running node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m20:37:21.738008 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_staff, now test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778)
[0m20:37:21.738866 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m20:37:21.748799 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778"
[0m20:37:21.749834 [debug] [Thread-1 (]: Began executing node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m20:37:21.750924 [debug] [Thread-1 (]: Finished running node test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778
[0m20:37:21.751601 [debug] [Thread-1 (]: Began running node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m20:37:21.752178 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.not_null_my_second_dbt_model_id.151b76d778, now test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493)
[0m20:37:21.752661 [debug] [Thread-1 (]: Began compiling node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m20:37:21.757873 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493"
[0m20:37:21.758933 [debug] [Thread-1 (]: Began executing node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m20:37:21.760362 [debug] [Thread-1 (]: Finished running node test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493
[0m20:37:21.761409 [debug] [Thread-1 (]: Began running node model.data_warehouse.total_revenue
[0m20:37:21.762414 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.data_warehouse.unique_my_second_dbt_model_id.57a0f8c493, now model.data_warehouse.total_revenue)
[0m20:37:21.762971 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.total_revenue
[0m20:37:21.766139 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.total_revenue"
[0m20:37:21.766995 [debug] [Thread-1 (]: Began executing node model.data_warehouse.total_revenue
[0m20:37:21.767918 [debug] [Thread-1 (]: Finished running node model.data_warehouse.total_revenue
[0m20:37:21.769100 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:37:21.769800 [debug] [MainThread]: Connection 'model.data_warehouse.total_revenue' was properly closed.
[0m20:37:21.774648 [debug] [MainThread]: Command end result
[0m20:37:21.808777 [debug] [MainThread]: Resource report: {"command_name": "compile", "command_success": true, "command_wall_clock_time": 1.4586293, "process_user_time": 2.601023, "process_kernel_time": 0.205634, "process_mem_max_rss": "109536", "process_in_blocks": "60056", "process_out_blocks": "3088"}
[0m20:37:21.809984 [debug] [MainThread]: Command `dbt compile` succeeded at 20:37:21.809753 after 1.46 seconds
[0m20:37:21.810842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b56aa9b38f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b56a79d0440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7b56a6752780>]}
[0m20:37:21.811670 [debug] [MainThread]: Flushing usage events
[0m20:37:28.558238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d44a0320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d44a1820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d497a600>]}


============================== 20:37:28.561274 | a4b935bd-75d2-4579-b671-49631e3dd8f2 ==============================
[0m20:37:28.561274 [info ] [MainThread]: Running with dbt=1.8.5
[0m20:37:28.562167 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse/logs', 'fail_fast': 'False', 'profiles_dir': '/home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m20:37:28.792227 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d32dea50>]}
[0m20:37:28.856932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d49b61e0>]}
[0m20:37:28.857917 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m20:37:28.872182 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m20:37:29.006572 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:37:29.007054 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:37:29.056659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d31ed490>]}
[0m20:37:29.173388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d32df0b0>]}
[0m20:37:29.173991 [info ] [MainThread]: Found 23 models, 4 data tests, 9 sources, 417 macros
[0m20:37:29.174540 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d5fedd00>]}
[0m20:37:29.177522 [info ] [MainThread]: 
[0m20:37:29.178310 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:37:29.187284 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m20:37:29.237352 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m20:37:29.237880 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m20:37:29.238282 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:37:29.250844 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.012 seconds
[0m20:37:29.252516 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m20:37:29.255228 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m20:37:29.255965 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m20:37:29.256383 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:37:29.267897 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.011 seconds
[0m20:37:29.269457 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m20:37:29.272007 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m20:37:29.272742 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m20:37:29.273162 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:37:29.284591 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.011 seconds
[0m20:37:29.286064 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m20:37:29.288288 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m20:37:29.288885 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m20:37:29.289302 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:37:29.307065 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.018 seconds
[0m20:37:29.309688 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m20:37:29.316926 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse, now create_data_warehouse_dbt_dev_intermediate)
[0m20:37:29.318090 [debug] [ThreadPool]: Creating schema "database: "data_warehouse"
schema: "dbt_dev_intermediate"
"
[0m20:37:29.329878 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_intermediate"
[0m20:37:29.330732 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_intermediate: BEGIN
[0m20:37:29.331480 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:37:29.349763 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m20:37:29.350694 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_intermediate"
[0m20:37:29.351583 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_intermediate: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "create_data_warehouse_dbt_dev_intermediate"} */
create schema if not exists "dbt_dev_intermediate"
[0m20:37:29.354976 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.003 seconds
[0m20:37:29.356830 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_intermediate: COMMIT
[0m20:37:29.357763 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_intermediate"
[0m20:37:29.358514 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_intermediate: COMMIT
[0m20:37:29.360028 [debug] [ThreadPool]: SQL status: COMMIT in 0.001 seconds
[0m20:37:29.360527 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_intermediate: Close
[0m20:37:29.361338 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_data_warehouse_dbt_dev_intermediate, now create_data_warehouse_dbt_dev_mart)
[0m20:37:29.362060 [debug] [ThreadPool]: Creating schema "database: "data_warehouse"
schema: "dbt_dev_mart"
"
[0m20:37:29.364388 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_mart"
[0m20:37:29.364880 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_mart: BEGIN
[0m20:37:29.365302 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:37:29.376203 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m20:37:29.376725 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_mart"
[0m20:37:29.377177 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "create_data_warehouse_dbt_dev_mart"} */
create schema if not exists "dbt_dev_mart"
[0m20:37:29.378163 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m20:37:29.379285 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_mart: COMMIT
[0m20:37:29.379749 [debug] [ThreadPool]: Using postgres connection "create_data_warehouse_dbt_dev_mart"
[0m20:37:29.380167 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_mart: COMMIT
[0m20:37:29.381708 [debug] [ThreadPool]: SQL status: COMMIT in 0.001 seconds
[0m20:37:29.382206 [debug] [ThreadPool]: On create_data_warehouse_dbt_dev_mart: Close
[0m20:37:29.386455 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_data_warehouse_dbt_dev_mart, now list_data_warehouse_dbt_dev_intermediate)
[0m20:37:29.392764 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediate"
[0m20:37:29.393232 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: BEGIN
[0m20:37:29.393622 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:37:29.404379 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m20:37:29.404897 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediate"
[0m20:37:29.405381 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediate"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediate'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediate'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediate'
  
[0m20:37:29.408626 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m20:37:29.410067 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: ROLLBACK
[0m20:37:29.410755 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: Close
[0m20:37:29.411510 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_intermediate, now list_data_warehouse_dbt_dev_raw)
[0m20:37:29.413817 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m20:37:29.414303 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m20:37:29.414827 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:37:29.425692 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m20:37:29.426194 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m20:37:29.426686 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m20:37:29.429916 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m20:37:29.431571 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m20:37:29.432270 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m20:37:29.433062 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_raw, now list_data_warehouse_dbt_dev)
[0m20:37:29.437759 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m20:37:29.438220 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m20:37:29.438630 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:37:29.449606 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m20:37:29.450098 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m20:37:29.450532 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m20:37:29.453763 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m20:37:29.455246 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m20:37:29.455845 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m20:37:29.456635 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_mart)
[0m20:37:29.459228 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m20:37:29.459697 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: BEGIN
[0m20:37:29.460088 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:37:29.470916 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m20:37:29.471417 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m20:37:29.471960 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_mart"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m20:37:29.475184 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m20:37:29.476626 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: ROLLBACK
[0m20:37:29.477296 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: Close
[0m20:37:29.484447 [debug] [MainThread]: Using postgres connection "master"
[0m20:37:29.484926 [debug] [MainThread]: On master: BEGIN
[0m20:37:29.485318 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:37:29.495790 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m20:37:29.496266 [debug] [MainThread]: Using postgres connection "master"
[0m20:37:29.496880 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:37:29.511409 [debug] [MainThread]: SQL status: SELECT 38 in 0.014 seconds
[0m20:37:29.514065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d4fe7350>]}
[0m20:37:29.514636 [debug] [MainThread]: On master: ROLLBACK
[0m20:37:29.515304 [debug] [MainThread]: Using postgres connection "master"
[0m20:37:29.515774 [debug] [MainThread]: On master: BEGIN
[0m20:37:29.516602 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m20:37:29.517067 [debug] [MainThread]: On master: COMMIT
[0m20:37:29.517494 [debug] [MainThread]: Using postgres connection "master"
[0m20:37:29.517927 [debug] [MainThread]: On master: COMMIT
[0m20:37:29.518561 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:37:29.519029 [debug] [MainThread]: On master: Close
[0m20:37:29.519718 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:37:29.520338 [info ] [MainThread]: 
[0m20:37:29.523081 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m20:37:29.523791 [info ] [Thread-1 (]: 1 of 21 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m20:37:29.524480 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_mart, now model.data_warehouse.actor)
[0m20:37:29.525017 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m20:37:29.535627 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m20:37:29.536565 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m20:37:29.589534 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.actor"
[0m20:37:29.590450 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m20:37:29.591028 [debug] [Thread-1 (]: On model.data_warehouse.actor: BEGIN
[0m20:37:29.591445 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:37:29.602003 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m20:37:29.602530 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m20:37:29.602991 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."actor"
  );
  
[0m20:37:29.614438 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.011 seconds
[0m20:37:29.621163 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m20:37:29.621711 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m20:37:29.622840 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:37:29.625801 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m20:37:29.626284 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m20:37:29.627112 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:37:29.649203 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m20:37:29.649776 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m20:37:29.650243 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m20:37:29.652877 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:37:29.659897 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m20:37:29.666521 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m20:37:29.667070 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m20:37:29.670984 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m20:37:29.673568 [debug] [Thread-1 (]: On model.data_warehouse.actor: Close
[0m20:37:29.675379 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d44a1e50>]}
[0m20:37:29.676256 [info ] [Thread-1 (]: 1 of 21 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.15s]
[0m20:37:29.677128 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m20:37:29.677739 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m20:37:29.678665 [info ] [Thread-1 (]: 2 of 21 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m20:37:29.679300 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m20:37:29.679843 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m20:37:29.683343 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m20:37:29.684685 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m20:37:29.692395 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.address"
[0m20:37:29.693806 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m20:37:29.694840 [debug] [Thread-1 (]: On model.data_warehouse.address: BEGIN
[0m20:37:29.695775 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:37:29.712232 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m20:37:29.713230 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m20:37:29.714216 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."address"
  );
  
[0m20:37:29.719930 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.005 seconds
[0m20:37:29.726086 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m20:37:29.727125 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m20:37:29.728523 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:37:29.734651 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m20:37:29.735676 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m20:37:29.737183 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:37:29.741390 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m20:37:29.742396 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m20:37:29.743485 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m20:37:29.746468 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:37:29.753350 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."address__dbt_backup"
[0m20:37:29.754535 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m20:37:29.755029 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m20:37:29.758234 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m20:37:29.760791 [debug] [Thread-1 (]: On model.data_warehouse.address: Close
[0m20:37:29.763530 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d20045f0>]}
[0m20:37:29.764906 [info ] [Thread-1 (]: 2 of 21 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.08s]
[0m20:37:29.766647 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m20:37:29.767261 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m20:37:29.767858 [info ] [Thread-1 (]: 3 of 21 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m20:37:29.768703 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m20:37:29.769508 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m20:37:29.773481 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m20:37:29.774259 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m20:37:29.782118 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.customer"
[0m20:37:29.783561 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m20:37:29.784676 [debug] [Thread-1 (]: On model.data_warehouse.customer: BEGIN
[0m20:37:29.785656 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:37:29.800327 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m20:37:29.801110 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m20:37:29.801840 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."customer"
  );
  
[0m20:37:29.809715 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.007 seconds
[0m20:37:29.817758 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m20:37:29.818716 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m20:37:29.819870 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:37:29.825190 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m20:37:29.825733 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m20:37:29.827775 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:37:29.831757 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m20:37:29.832324 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m20:37:29.832863 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m20:37:29.834887 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:37:29.837403 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m20:37:29.838321 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m20:37:29.838791 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m20:37:29.841850 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m20:37:29.843909 [debug] [Thread-1 (]: On model.data_warehouse.customer: Close
[0m20:37:29.846002 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d25afc50>]}
[0m20:37:29.847544 [info ] [Thread-1 (]: 3 of 21 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.08s]
[0m20:37:29.849661 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m20:37:29.850460 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m20:37:29.851789 [info ] [Thread-1 (]: 4 of 21 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m20:37:29.852621 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m20:37:29.853202 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m20:37:29.858711 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m20:37:29.860366 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m20:37:29.869548 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film"
[0m20:37:29.871177 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m20:37:29.872490 [debug] [Thread-1 (]: On model.data_warehouse.film: BEGIN
[0m20:37:29.873906 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:37:29.889856 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m20:37:29.890572 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m20:37:29.891240 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."film"
  );
  
[0m20:37:29.905284 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.013 seconds
[0m20:37:29.908816 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m20:37:29.909474 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m20:37:29.910752 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:37:29.916273 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m20:37:29.916910 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m20:37:29.917837 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:37:29.920935 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m20:37:29.921776 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m20:37:29.922458 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m20:37:29.924097 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m20:37:29.926659 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film__dbt_backup"
[0m20:37:29.927687 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m20:37:29.928237 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m20:37:29.931346 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m20:37:29.933005 [debug] [Thread-1 (]: On model.data_warehouse.film: Close
[0m20:37:29.933813 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d2003080>]}
[0m20:37:29.934690 [info ] [Thread-1 (]: 4 of 21 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.08s]
[0m20:37:29.935717 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m20:37:29.936402 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m20:37:29.937161 [info ] [Thread-1 (]: 5 of 21 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m20:37:29.938035 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m20:37:29.938890 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m20:37:29.944690 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m20:37:29.945693 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m20:37:29.955220 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film_actor"
[0m20:37:29.956797 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m20:37:29.957627 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: BEGIN
[0m20:37:29.958128 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:37:29.973498 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m20:37:29.974075 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m20:37:29.974832 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."film_actor"
  );
  
[0m20:37:29.983739 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.008 seconds
[0m20:37:29.988259 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m20:37:29.989182 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m20:37:29.990853 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:37:29.995120 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m20:37:29.995715 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m20:37:29.997106 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:37:29.999857 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m20:37:30.000397 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m20:37:30.000907 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m20:37:30.003931 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:37:30.006664 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m20:37:30.007929 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m20:37:30.008621 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m20:37:30.013450 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.004 seconds
[0m20:37:30.015420 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: Close
[0m20:37:30.016793 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d2040170>]}
[0m20:37:30.018151 [info ] [Thread-1 (]: 5 of 21 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.08s]
[0m20:37:30.019540 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m20:37:30.020577 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m20:37:30.021741 [info ] [Thread-1 (]: 6 of 21 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m20:37:30.022737 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m20:37:30.023524 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m20:37:30.028604 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m20:37:30.029775 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m20:37:30.036921 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.inventory"
[0m20:37:30.037809 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m20:37:30.038296 [debug] [Thread-1 (]: On model.data_warehouse.inventory: BEGIN
[0m20:37:30.038732 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:37:30.051895 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m20:37:30.052436 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m20:37:30.052962 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."inventory"
  );
  
[0m20:37:30.058532 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.005 seconds
[0m20:37:30.064465 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m20:37:30.065013 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m20:37:30.066144 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:37:30.069267 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m20:37:30.069770 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m20:37:30.070615 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:37:30.072798 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m20:37:30.073298 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m20:37:30.073762 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m20:37:30.077007 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:37:30.079590 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m20:37:30.080640 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m20:37:30.081109 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m20:37:30.083922 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:37:30.085600 [debug] [Thread-1 (]: On model.data_warehouse.inventory: Close
[0m20:37:30.086449 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d2195940>]}
[0m20:37:30.087903 [info ] [Thread-1 (]: 6 of 21 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.06s]
[0m20:37:30.089321 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m20:37:30.089911 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m20:37:30.090692 [info ] [Thread-1 (]: 7 of 21 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m20:37:30.091359 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m20:37:30.091910 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m20:37:30.094472 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m20:37:30.095624 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m20:37:30.103394 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_first_dbt_model"
[0m20:37:30.104964 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m20:37:30.105967 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: BEGIN
[0m20:37:30.107622 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:37:30.123378 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m20:37:30.123976 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m20:37:30.124607 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */

  
    

  create  table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m20:37:30.128156 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.002 seconds
[0m20:37:30.135856 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m20:37:30.136687 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m20:37:30.137917 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:37:30.141106 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m20:37:30.141601 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m20:37:30.142445 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:37:30.145172 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m20:37:30.145776 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m20:37:30.146561 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m20:37:30.148451 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m20:37:30.151005 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m20:37:30.152047 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m20:37:30.152609 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
drop table if exists "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m20:37:30.155709 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m20:37:30.157346 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: Close
[0m20:37:30.158116 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d21fda60>]}
[0m20:37:30.158930 [info ] [Thread-1 (]: 7 of 21 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.07s]
[0m20:37:30.159816 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m20:37:30.160514 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m20:37:30.161120 [info ] [Thread-1 (]: 8 of 21 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m20:37:30.161905 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m20:37:30.162844 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m20:37:30.167279 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m20:37:30.168231 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m20:37:30.174022 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.payment"
[0m20:37:30.174961 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m20:37:30.175566 [debug] [Thread-1 (]: On model.data_warehouse.payment: BEGIN
[0m20:37:30.176092 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:37:30.189453 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m20:37:30.190037 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m20:37:30.190743 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."payment"
  );
  
[0m20:37:30.204612 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.013 seconds
[0m20:37:30.207846 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m20:37:30.208392 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m20:37:30.209655 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:37:30.213392 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m20:37:30.214028 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m20:37:30.215164 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:37:30.220271 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m20:37:30.220969 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m20:37:30.221644 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m20:37:30.229157 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m20:37:30.232235 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m20:37:30.233873 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m20:37:30.234686 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m20:37:30.237163 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:37:30.239634 [debug] [Thread-1 (]: On model.data_warehouse.payment: Close
[0m20:37:30.240717 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d25afb60>]}
[0m20:37:30.242102 [info ] [Thread-1 (]: 8 of 21 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.08s]
[0m20:37:30.243658 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m20:37:30.244208 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m20:37:30.244774 [info ] [Thread-1 (]: 9 of 21 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m20:37:30.245612 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m20:37:30.246105 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m20:37:30.249159 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m20:37:30.250407 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m20:37:30.258280 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.rental"
[0m20:37:30.259838 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m20:37:30.262219 [debug] [Thread-1 (]: On model.data_warehouse.rental: BEGIN
[0m20:37:30.264012 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:37:30.275950 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m20:37:30.276636 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m20:37:30.277980 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."rental"
  );
  
[0m20:37:30.292136 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.013 seconds
[0m20:37:30.295704 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m20:37:30.296214 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m20:37:30.297193 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:37:30.300615 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m20:37:30.301201 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m20:37:30.302037 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:37:30.304378 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m20:37:30.304935 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m20:37:30.305453 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m20:37:30.311764 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m20:37:30.316999 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m20:37:30.318053 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m20:37:30.318687 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m20:37:30.321306 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:37:30.323892 [debug] [Thread-1 (]: On model.data_warehouse.rental: Close
[0m20:37:30.324858 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d2032060>]}
[0m20:37:30.325669 [info ] [Thread-1 (]: 9 of 21 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.08s]
[0m20:37:30.326797 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m20:37:30.327739 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m20:37:30.328633 [info ] [Thread-1 (]: 10 of 21 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m20:37:30.329339 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m20:37:30.330122 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m20:37:30.335270 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m20:37:30.336545 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m20:37:30.345782 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.staff"
[0m20:37:30.346967 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m20:37:30.348105 [debug] [Thread-1 (]: On model.data_warehouse.staff: BEGIN
[0m20:37:30.349024 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:37:30.361748 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m20:37:30.362752 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m20:37:30.363455 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."staff"
  );
  
[0m20:37:30.369157 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.005 seconds
[0m20:37:30.372311 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m20:37:30.372819 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m20:37:30.373654 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:37:30.376888 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m20:37:30.377403 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m20:37:30.378208 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:37:30.380285 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m20:37:30.380775 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m20:37:30.381201 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m20:37:30.382957 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m20:37:30.385996 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m20:37:30.387247 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m20:37:30.387775 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m20:37:30.390258 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:37:30.392634 [debug] [Thread-1 (]: On model.data_warehouse.staff: Close
[0m20:37:30.393448 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d2195af0>]}
[0m20:37:30.394663 [info ] [Thread-1 (]: 10 of 21 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.06s]
[0m20:37:30.395819 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m20:37:30.396575 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m20:37:30.397204 [info ] [Thread-1 (]: 11 of 21 START sql table model dbt_dev_intermediate.dim_actor .................. [RUN]
[0m20:37:30.397948 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m20:37:30.398540 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m20:37:30.403054 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m20:37:30.404437 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m20:37:30.411502 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_actor"
[0m20:37:30.412800 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m20:37:30.413868 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: BEGIN
[0m20:37:30.414894 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:37:30.429254 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m20:37:30.430121 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m20:37:30.430681 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."actor"
  );
  
[0m20:37:30.433203 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m20:37:30.436734 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m20:37:30.437275 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m20:37:30.438328 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:37:30.440444 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m20:37:30.441014 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m20:37:30.441461 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m20:37:30.443246 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m20:37:30.445936 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_backup"
[0m20:37:30.446909 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m20:37:30.447382 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_backup" cascade
[0m20:37:30.448569 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m20:37:30.450168 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: Close
[0m20:37:30.450915 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d33355e0>]}
[0m20:37:30.451875 [info ] [Thread-1 (]: 11 of 21 OK created sql table model dbt_dev_intermediate.dim_actor ............. [[32mSELECT 200[0m in 0.05s]
[0m20:37:30.452853 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m20:37:30.453524 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m20:37:30.454218 [info ] [Thread-1 (]: 12 of 21 START sql table model dbt_dev_intermediate.dim_address ................ [RUN]
[0m20:37:30.454866 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m20:37:30.455362 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m20:37:30.458853 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m20:37:30.459577 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m20:37:30.463918 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_address"
[0m20:37:30.464706 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m20:37:30.465717 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: BEGIN
[0m20:37:30.466580 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:37:30.480780 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m20:37:30.482017 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m20:37:30.482941 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."address"
  );
  
[0m20:37:30.485998 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m20:37:30.491624 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m20:37:30.492145 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_tmp" rename to "dim_address"
[0m20:37:30.493069 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:37:30.496713 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m20:37:30.497247 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m20:37:30.497723 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m20:37:30.500034 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:37:30.502480 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_backup"
[0m20:37:30.503391 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m20:37:30.503919 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_backup" cascade
[0m20:37:30.504764 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m20:37:30.506799 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: Close
[0m20:37:30.507677 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d20045c0>]}
[0m20:37:30.509187 [info ] [Thread-1 (]: 12 of 21 OK created sql table model dbt_dev_intermediate.dim_address ........... [[32mSELECT 603[0m in 0.05s]
[0m20:37:30.510743 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m20:37:30.511418 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m20:37:30.512123 [info ] [Thread-1 (]: 13 of 21 START sql table model dbt_dev_intermediate.dim_customer ............... [RUN]
[0m20:37:30.512774 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m20:37:30.513257 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m20:37:30.517630 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m20:37:30.518865 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m20:37:30.527217 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_customer"
[0m20:37:30.530133 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m20:37:30.531151 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: BEGIN
[0m20:37:30.531875 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:37:30.543033 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m20:37:30.544843 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m20:37:30.546066 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."customer"
  );
  
[0m20:37:30.549024 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.002 seconds
[0m20:37:30.552201 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m20:37:30.552703 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m20:37:30.553514 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:37:30.555669 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m20:37:30.556167 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m20:37:30.556611 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m20:37:30.558806 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:37:30.561549 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_backup"
[0m20:37:30.562571 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m20:37:30.563084 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_backup" cascade
[0m20:37:30.563889 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m20:37:30.565448 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: Close
[0m20:37:30.566203 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d25a3ef0>]}
[0m20:37:30.567243 [info ] [Thread-1 (]: 13 of 21 OK created sql table model dbt_dev_intermediate.dim_customer .......... [[32mSELECT 599[0m in 0.05s]
[0m20:37:30.568215 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m20:37:30.568909 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m20:37:30.569773 [info ] [Thread-1 (]: 14 of 21 START sql table model dbt_dev_intermediate.dim_film ................... [RUN]
[0m20:37:30.570568 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m20:37:30.571103 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m20:37:30.574388 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m20:37:30.575275 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m20:37:30.579882 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film"
[0m20:37:30.580743 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m20:37:30.581753 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: BEGIN
[0m20:37:30.582685 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:37:30.596483 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m20:37:30.597331 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m20:37:30.598270 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."film"
  );
  
[0m20:37:30.604690 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.006 seconds
[0m20:37:30.608501 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m20:37:30.609048 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_tmp" rename to "dim_film"
[0m20:37:30.611235 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:37:30.614272 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m20:37:30.614818 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m20:37:30.615266 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m20:37:30.618856 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m20:37:30.622249 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_backup"
[0m20:37:30.623478 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m20:37:30.623997 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_backup" cascade
[0m20:37:30.624845 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m20:37:30.627101 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: Close
[0m20:37:30.628058 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d21fb5c0>]}
[0m20:37:30.629493 [info ] [Thread-1 (]: 14 of 21 OK created sql table model dbt_dev_intermediate.dim_film .............. [[32mSELECT 1000[0m in 0.06s]
[0m20:37:30.631138 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m20:37:30.632131 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m20:37:30.633235 [info ] [Thread-1 (]: 15 of 21 START sql table model dbt_dev_intermediate.dim_film_actor ............. [RUN]
[0m20:37:30.634205 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m20:37:30.635050 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m20:37:30.640309 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m20:37:30.641395 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m20:37:30.650004 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film_actor"
[0m20:37:30.651924 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m20:37:30.652733 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: BEGIN
[0m20:37:30.653401 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:37:30.667564 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m20:37:30.668416 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m20:37:30.669251 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m20:37:30.674557 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.004 seconds
[0m20:37:30.725934 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m20:37:30.726635 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m20:37:30.727853 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:37:30.730686 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m20:37:30.731255 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m20:37:30.731756 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m20:37:30.733206 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m20:37:30.735722 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_backup"
[0m20:37:30.736730 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m20:37:30.737253 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_backup" cascade
[0m20:37:30.738072 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m20:37:30.739885 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: Close
[0m20:37:30.740664 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d207be90>]}
[0m20:37:30.741464 [info ] [Thread-1 (]: 15 of 21 OK created sql table model dbt_dev_intermediate.dim_film_actor ........ [[32mSELECT 5462[0m in 0.11s]
[0m20:37:30.742445 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m20:37:30.743203 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m20:37:30.744005 [info ] [Thread-1 (]: 16 of 21 START sql table model dbt_dev_intermediate.dim_inventory .............. [RUN]
[0m20:37:30.744694 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.dim_inventory)
[0m20:37:30.745188 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m20:37:30.748806 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m20:37:30.750077 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m20:37:30.757736 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_inventory"
[0m20:37:30.758646 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m20:37:30.759271 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: BEGIN
[0m20:37:30.761819 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:37:30.774579 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m20:37:30.775123 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m20:37:30.775584 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."inventory"
  );
  
[0m20:37:30.781792 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.006 seconds
[0m20:37:30.784799 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m20:37:30.785288 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m20:37:30.786083 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:37:30.788170 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m20:37:30.788681 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m20:37:30.789121 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m20:37:30.792063 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:37:30.794805 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_backup"
[0m20:37:30.795751 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m20:37:30.796218 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_backup" cascade
[0m20:37:30.796938 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m20:37:30.798510 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: Close
[0m20:37:30.799467 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d32dee70>]}
[0m20:37:30.801025 [info ] [Thread-1 (]: 16 of 21 OK created sql table model dbt_dev_intermediate.dim_inventory ......... [[32mSELECT 4581[0m in 0.05s]
[0m20:37:30.802657 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m20:37:30.803345 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m20:37:30.804047 [info ] [Thread-1 (]: 17 of 21 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m20:37:30.804796 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m20:37:30.805387 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m20:37:30.808326 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m20:37:30.809803 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m20:37:30.838873 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_second_dbt_model"
[0m20:37:30.839816 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m20:37:30.840668 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: BEGIN
[0m20:37:30.841529 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:37:30.856758 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m20:37:30.857282 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m20:37:30.857752 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */

  create view "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "data_warehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m20:37:30.860258 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.002 seconds
[0m20:37:30.863607 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m20:37:30.864215 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m20:37:30.865113 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:37:30.867103 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m20:37:30.867636 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m20:37:30.868097 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m20:37:30.870110 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:37:30.872485 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m20:37:30.876209 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m20:37:30.876753 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
drop view if exists "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m20:37:30.877579 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m20:37:30.879326 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: Close
[0m20:37:30.880090 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d203cef0>]}
[0m20:37:30.880898 [info ] [Thread-1 (]: 17 of 21 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.08s]
[0m20:37:30.881842 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m20:37:30.882433 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m20:37:30.883159 [info ] [Thread-1 (]: 18 of 21 START sql table model dbt_dev_intermediate.fact_payment ............... [RUN]
[0m20:37:30.883894 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now model.data_warehouse.fact_payment)
[0m20:37:30.884475 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m20:37:30.888030 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m20:37:30.888968 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m20:37:30.898090 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.fact_payment"
[0m20:37:30.898920 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m20:37:30.899538 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: BEGIN
[0m20:37:30.900399 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:37:30.914048 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m20:37:30.914610 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m20:37:30.915449 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."payment"
  );
  
[0m20:37:30.926294 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.010 seconds
[0m20:37:30.932142 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m20:37:30.932782 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m20:37:30.933982 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:37:30.936011 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m20:37:30.936607 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m20:37:30.937475 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m20:37:30.942777 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m20:37:30.946833 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_backup"
[0m20:37:30.947877 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m20:37:30.948745 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_backup" cascade
[0m20:37:30.949790 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m20:37:30.951744 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: Close
[0m20:37:30.952881 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d2186600>]}
[0m20:37:30.953930 [info ] [Thread-1 (]: 18 of 21 OK created sql table model dbt_dev_intermediate.fact_payment .......... [[32mSELECT 14596[0m in 0.07s]
[0m20:37:30.955023 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m20:37:30.955685 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m20:37:30.956612 [info ] [Thread-1 (]: 19 of 21 START sql table model dbt_dev_intermediate.dim_rental ................. [RUN]
[0m20:37:30.957455 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.dim_rental)
[0m20:37:30.957970 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m20:37:30.962625 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m20:37:30.963911 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m20:37:30.970723 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_rental"
[0m20:37:30.971529 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m20:37:30.972007 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: BEGIN
[0m20:37:30.972435 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:37:30.985694 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m20:37:30.986226 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m20:37:30.986705 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."rental"
  );
  
[0m20:37:30.999302 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.012 seconds
[0m20:37:31.002507 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m20:37:31.003027 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m20:37:31.003878 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:37:31.005916 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m20:37:31.006405 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m20:37:31.006924 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m20:37:31.013132 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m20:37:31.015648 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_backup"
[0m20:37:31.016820 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m20:37:31.017324 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_backup" cascade
[0m20:37:31.018067 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m20:37:31.019636 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: Close
[0m20:37:31.020410 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d2002de0>]}
[0m20:37:31.021284 [info ] [Thread-1 (]: 19 of 21 OK created sql table model dbt_dev_intermediate.dim_rental ............ [[32mSELECT 16044[0m in 0.06s]
[0m20:37:31.022192 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m20:37:31.022810 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m20:37:31.023631 [info ] [Thread-1 (]: 20 of 21 START sql table model dbt_dev_intermediate.dim_staff .................. [RUN]
[0m20:37:31.024278 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m20:37:31.024821 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m20:37:31.028301 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m20:37:31.029290 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m20:37:31.033818 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_staff"
[0m20:37:31.035047 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m20:37:31.036165 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: BEGIN
[0m20:37:31.037050 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:37:31.050705 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m20:37:31.051529 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m20:37:31.052264 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."staff"
  );
  
[0m20:37:31.057657 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.005 seconds
[0m20:37:31.064571 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m20:37:31.065394 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m20:37:31.066691 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:37:31.069817 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m20:37:31.070572 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m20:37:31.071276 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m20:37:31.073074 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m20:37:31.077062 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_backup"
[0m20:37:31.078691 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m20:37:31.079509 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_backup" cascade
[0m20:37:31.080604 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m20:37:31.083040 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: Close
[0m20:37:31.084099 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d203d670>]}
[0m20:37:31.085284 [info ] [Thread-1 (]: 20 of 21 OK created sql table model dbt_dev_intermediate.dim_staff ............. [[32mSELECT 2[0m in 0.06s]
[0m20:37:31.086346 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m20:37:31.086965 [debug] [Thread-1 (]: Began running node model.data_warehouse.total_revenue
[0m20:37:31.087644 [info ] [Thread-1 (]: 21 of 21 START sql table model dbt_dev_mart.total_revenue ...................... [RUN]
[0m20:37:31.088273 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_staff, now model.data_warehouse.total_revenue)
[0m20:37:31.088777 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.total_revenue
[0m20:37:31.094327 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.total_revenue"
[0m20:37:31.095245 [debug] [Thread-1 (]: Began executing node model.data_warehouse.total_revenue
[0m20:37:31.100393 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.total_revenue"
[0m20:37:31.101657 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m20:37:31.102266 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: BEGIN
[0m20:37:31.102771 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:37:31.115932 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m20:37:31.116472 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m20:37:31.116992 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    SUM(amount) AS total_revenue,
    payment_date
FROM "data_warehouse"."dbt_dev_intermediate"."fact_payment"
GROUP BY payment_date
  );
  
[0m20:37:31.150209 [debug] [Thread-1 (]: SQL status: SELECT 14365 in 0.033 seconds
[0m20:37:31.153535 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m20:37:31.154194 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp" rename to "total_revenue"
[0m20:37:31.155121 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:37:31.157393 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m20:37:31.157942 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m20:37:31.158383 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m20:37:31.162650 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m20:37:31.165230 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup"
[0m20:37:31.166715 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m20:37:31.167543 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup" cascade
[0m20:37:31.168725 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m20:37:31.170758 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: Close
[0m20:37:31.171716 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4b935bd-75d2-4579-b671-49631e3dd8f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d31ed2e0>]}
[0m20:37:31.172730 [info ] [Thread-1 (]: 21 of 21 OK created sql table model dbt_dev_mart.total_revenue ................. [[32mSELECT 14365[0m in 0.08s]
[0m20:37:31.174158 [debug] [Thread-1 (]: Finished running node model.data_warehouse.total_revenue
[0m20:37:31.175821 [debug] [MainThread]: Using postgres connection "master"
[0m20:37:31.176393 [debug] [MainThread]: On master: BEGIN
[0m20:37:31.177019 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:37:31.191748 [debug] [MainThread]: SQL status: BEGIN in 0.015 seconds
[0m20:37:31.192380 [debug] [MainThread]: On master: COMMIT
[0m20:37:31.194135 [debug] [MainThread]: Using postgres connection "master"
[0m20:37:31.195598 [debug] [MainThread]: On master: COMMIT
[0m20:37:31.196807 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:37:31.197482 [debug] [MainThread]: On master: Close
[0m20:37:31.198728 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:37:31.199631 [debug] [MainThread]: Connection 'model.data_warehouse.total_revenue' was properly closed.
[0m20:37:31.200703 [info ] [MainThread]: 
[0m20:37:31.201542 [info ] [MainThread]: Finished running 20 table models, 1 view model in 0 hours 0 minutes and 2.02 seconds (2.02s).
[0m20:37:31.206147 [debug] [MainThread]: Command end result
[0m20:37:31.252455 [info ] [MainThread]: 
[0m20:37:31.253135 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:37:31.253717 [info ] [MainThread]: 
[0m20:37:31.254202 [info ] [MainThread]: Done. PASS=21 WARN=0 ERROR=0 SKIP=0 TOTAL=21
[0m20:37:31.255522 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 2.7506409, "process_user_time": 3.46339, "process_kernel_time": 0.179123, "process_mem_max_rss": "107944", "process_in_blocks": "56", "process_out_blocks": "2464"}
[0m20:37:31.256315 [debug] [MainThread]: Command `dbt run` succeeded at 20:37:31.256167 after 2.75 seconds
[0m20:37:31.256865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d3e5c260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d4796db0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d58d2dd7530>]}
[0m20:37:31.257427 [debug] [MainThread]: Flushing usage events
[0m20:56:41.388229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91bb6ace60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b98b2120>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b9d8d8b0>]}


============================== 20:56:41.391301 | dbd4da47-2849-40c8-9b61-ab0eed51c4c5 ==============================
[0m20:56:41.391301 [info ] [MainThread]: Running with dbt=1.8.5
[0m20:56:41.392378 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse/logs', 'profiles_dir': '/home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m20:56:41.596985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91ba4ba6f0>]}
[0m20:56:41.661431 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b9f1d670>]}
[0m20:56:41.662403 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m20:56:41.675685 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m20:56:41.814731 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m20:56:41.815642 [debug] [MainThread]: Partial parsing: updated file: data_warehouse://models/mart/best_selling.sql
[0m20:56:42.098009 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b8578230>]}
[0m20:56:42.224086 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b85647a0>]}
[0m20:56:42.224956 [info ] [MainThread]: Found 23 models, 4 data tests, 9 sources, 417 macros
[0m20:56:42.225842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b924bbf0>]}
[0m20:56:42.228693 [info ] [MainThread]: 
[0m20:56:42.229487 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:56:42.235710 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m20:56:42.283388 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m20:56:42.283935 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m20:56:42.284382 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:56:42.297608 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.013 seconds
[0m20:56:42.299148 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m20:56:42.302523 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m20:56:42.303175 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m20:56:42.303651 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:56:42.317122 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.013 seconds
[0m20:56:42.318669 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m20:56:42.321036 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m20:56:42.321575 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m20:56:42.322765 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:56:42.334218 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.011 seconds
[0m20:56:42.335683 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m20:56:42.339359 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m20:56:42.339970 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m20:56:42.340422 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:56:42.351985 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.012 seconds
[0m20:56:42.353474 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m20:56:42.356558 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse, now list_data_warehouse_dbt_dev_raw)
[0m20:56:42.364190 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m20:56:42.364698 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m20:56:42.365159 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:56:42.375780 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m20:56:42.376251 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m20:56:42.376789 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m20:56:42.380036 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m20:56:42.381906 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m20:56:42.382603 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m20:56:42.383350 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_raw, now list_data_warehouse_dbt_dev_intermediate)
[0m20:56:42.388025 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediate"
[0m20:56:42.388472 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: BEGIN
[0m20:56:42.388877 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:56:42.399805 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m20:56:42.400289 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediate"
[0m20:56:42.400715 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediate"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediate'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediate'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediate'
  
[0m20:56:42.403986 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m20:56:42.405631 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: ROLLBACK
[0m20:56:42.406332 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: Close
[0m20:56:42.407093 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_intermediate, now list_data_warehouse_dbt_dev_mart)
[0m20:56:42.411730 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m20:56:42.412200 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: BEGIN
[0m20:56:42.412616 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:56:42.423103 [debug] [ThreadPool]: SQL status: BEGIN in 0.010 seconds
[0m20:56:42.423593 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m20:56:42.424026 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_mart"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m20:56:42.427448 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.003 seconds
[0m20:56:42.428966 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: ROLLBACK
[0m20:56:42.429580 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: Close
[0m20:56:42.430328 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_mart, now list_data_warehouse_dbt_dev)
[0m20:56:42.433134 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m20:56:42.433607 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m20:56:42.433996 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:56:42.444732 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m20:56:42.445458 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m20:56:42.445949 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m20:56:42.449291 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m20:56:42.450775 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m20:56:42.451420 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m20:56:42.457827 [debug] [MainThread]: Using postgres connection "master"
[0m20:56:42.458291 [debug] [MainThread]: On master: BEGIN
[0m20:56:42.458682 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:56:42.469587 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m20:56:42.470074 [debug] [MainThread]: Using postgres connection "master"
[0m20:56:42.470777 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:56:42.492810 [debug] [MainThread]: SQL status: SELECT 38 in 0.021 seconds
[0m20:56:42.495226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b83fc710>]}
[0m20:56:42.495768 [debug] [MainThread]: On master: ROLLBACK
[0m20:56:42.496372 [debug] [MainThread]: Using postgres connection "master"
[0m20:56:42.496870 [debug] [MainThread]: On master: BEGIN
[0m20:56:42.497531 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m20:56:42.497982 [debug] [MainThread]: On master: COMMIT
[0m20:56:42.498368 [debug] [MainThread]: Using postgres connection "master"
[0m20:56:42.498754 [debug] [MainThread]: On master: COMMIT
[0m20:56:42.499267 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:56:42.499698 [debug] [MainThread]: On master: Close
[0m20:56:42.500439 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:56:42.501300 [info ] [MainThread]: 
[0m20:56:42.504441 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m20:56:42.505183 [info ] [Thread-1 (]: 1 of 22 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m20:56:42.505796 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now model.data_warehouse.actor)
[0m20:56:42.506658 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m20:56:42.518382 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m20:56:42.519217 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m20:56:42.570663 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.actor"
[0m20:56:42.571492 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m20:56:42.572018 [debug] [Thread-1 (]: On model.data_warehouse.actor: BEGIN
[0m20:56:42.572463 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:56:42.583566 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m20:56:42.584151 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m20:56:42.584663 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."actor"
  );
  
[0m20:56:42.586802 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m20:56:42.593678 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m20:56:42.594196 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m20:56:42.595086 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:42.598573 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m20:56:42.599068 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m20:56:42.599841 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:42.626034 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m20:56:42.626582 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m20:56:42.627044 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m20:56:42.629029 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:56:42.637111 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m20:56:42.643401 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m20:56:42.643974 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m20:56:42.646487 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:56:42.649329 [debug] [Thread-1 (]: On model.data_warehouse.actor: Close
[0m20:56:42.652117 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b9df6090>]}
[0m20:56:42.653284 [info ] [Thread-1 (]: 1 of 22 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.14s]
[0m20:56:42.654133 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m20:56:42.654702 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m20:56:42.655587 [info ] [Thread-1 (]: 2 of 22 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m20:56:42.656300 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m20:56:42.656892 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m20:56:42.660117 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m20:56:42.661004 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m20:56:42.665221 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.address"
[0m20:56:42.666270 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m20:56:42.667291 [debug] [Thread-1 (]: On model.data_warehouse.address: BEGIN
[0m20:56:42.668217 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:56:42.681714 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m20:56:42.682310 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m20:56:42.682769 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."address"
  );
  
[0m20:56:42.685199 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m20:56:42.689127 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m20:56:42.690717 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m20:56:42.692256 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:42.695537 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m20:56:42.696057 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m20:56:42.696986 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:42.699374 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m20:56:42.699862 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m20:56:42.700285 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m20:56:42.702470 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:56:42.705175 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."address__dbt_backup"
[0m20:56:42.706145 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m20:56:42.706620 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m20:56:42.709152 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:56:42.711616 [debug] [Thread-1 (]: On model.data_warehouse.address: Close
[0m20:56:42.712527 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b79ee390>]}
[0m20:56:42.713527 [info ] [Thread-1 (]: 2 of 22 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.06s]
[0m20:56:42.714420 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m20:56:42.715225 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m20:56:42.715850 [info ] [Thread-1 (]: 3 of 22 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m20:56:42.716692 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m20:56:42.717197 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m20:56:42.720808 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m20:56:42.721706 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m20:56:42.726612 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.customer"
[0m20:56:42.727784 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m20:56:42.728848 [debug] [Thread-1 (]: On model.data_warehouse.customer: BEGIN
[0m20:56:42.729820 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:56:42.744737 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m20:56:42.745604 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m20:56:42.746177 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."customer"
  );
  
[0m20:56:42.748736 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.002 seconds
[0m20:56:42.752329 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m20:56:42.752851 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m20:56:42.753737 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:42.759584 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m20:56:42.760398 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m20:56:42.761710 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:42.765177 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m20:56:42.766165 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m20:56:42.766960 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m20:56:42.769133 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:56:42.772267 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m20:56:42.773310 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m20:56:42.773836 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m20:56:42.776243 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:56:42.777899 [debug] [Thread-1 (]: On model.data_warehouse.customer: Close
[0m20:56:42.778730 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b8920800>]}
[0m20:56:42.779574 [info ] [Thread-1 (]: 3 of 22 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.06s]
[0m20:56:42.780499 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m20:56:42.781120 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m20:56:42.781796 [info ] [Thread-1 (]: 4 of 22 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m20:56:42.782592 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m20:56:42.783109 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m20:56:42.786498 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m20:56:42.787920 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m20:56:42.798508 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film"
[0m20:56:42.799529 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m20:56:42.800370 [debug] [Thread-1 (]: On model.data_warehouse.film: BEGIN
[0m20:56:42.800864 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:56:42.815597 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m20:56:42.816125 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m20:56:42.816601 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."film"
  );
  
[0m20:56:42.824893 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.008 seconds
[0m20:56:42.828508 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m20:56:42.829221 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m20:56:42.830728 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:56:42.834198 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m20:56:42.834759 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m20:56:42.835639 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:42.838430 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m20:56:42.839049 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m20:56:42.839676 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m20:56:42.843184 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m20:56:42.846134 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film__dbt_backup"
[0m20:56:42.847715 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m20:56:42.848502 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m20:56:42.851447 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:56:42.853116 [debug] [Thread-1 (]: On model.data_warehouse.film: Close
[0m20:56:42.853975 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b786e4b0>]}
[0m20:56:42.854821 [info ] [Thread-1 (]: 4 of 22 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.07s]
[0m20:56:42.855800 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m20:56:42.856544 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m20:56:42.857229 [info ] [Thread-1 (]: 5 of 22 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m20:56:42.858021 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m20:56:42.858605 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m20:56:42.862648 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m20:56:42.863581 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m20:56:42.869350 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film_actor"
[0m20:56:42.870272 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m20:56:42.870913 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: BEGIN
[0m20:56:42.871806 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:56:42.885163 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m20:56:42.885727 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m20:56:42.886172 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."film_actor"
  );
  
[0m20:56:42.892383 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.006 seconds
[0m20:56:42.895782 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m20:56:42.896427 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m20:56:42.897330 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:42.900441 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m20:56:42.900962 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m20:56:42.901837 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:42.904222 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m20:56:42.904832 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m20:56:42.905392 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m20:56:42.908545 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m20:56:42.911069 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m20:56:42.912314 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m20:56:42.912824 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m20:56:42.915494 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:56:42.917124 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: Close
[0m20:56:42.918003 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b7919160>]}
[0m20:56:42.919370 [info ] [Thread-1 (]: 5 of 22 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.06s]
[0m20:56:42.920796 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m20:56:42.921445 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m20:56:42.922169 [info ] [Thread-1 (]: 6 of 22 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m20:56:42.922951 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m20:56:42.923566 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m20:56:42.927030 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m20:56:42.927933 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m20:56:42.933889 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.inventory"
[0m20:56:42.935788 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m20:56:42.936999 [debug] [Thread-1 (]: On model.data_warehouse.inventory: BEGIN
[0m20:56:42.938155 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:56:42.957143 [debug] [Thread-1 (]: SQL status: BEGIN in 0.019 seconds
[0m20:56:42.958245 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m20:56:42.958760 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."inventory"
  );
  
[0m20:56:42.963098 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.004 seconds
[0m20:56:42.967520 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m20:56:42.968072 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m20:56:42.968886 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:42.972232 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m20:56:42.972765 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m20:56:42.973627 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:42.976386 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m20:56:42.976980 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m20:56:42.977437 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m20:56:42.980179 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:56:42.982733 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m20:56:42.983687 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m20:56:42.984162 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m20:56:42.986494 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:56:42.988148 [debug] [Thread-1 (]: On model.data_warehouse.inventory: Close
[0m20:56:42.989026 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b79d50a0>]}
[0m20:56:42.990437 [info ] [Thread-1 (]: 6 of 22 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.07s]
[0m20:56:42.991842 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m20:56:42.992403 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m20:56:42.993082 [info ] [Thread-1 (]: 7 of 22 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m20:56:42.993881 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m20:56:42.994465 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m20:56:42.997230 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m20:56:42.998740 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m20:56:43.007602 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_first_dbt_model"
[0m20:56:43.008669 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m20:56:43.009154 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: BEGIN
[0m20:56:43.009596 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:56:43.020795 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m20:56:43.021400 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m20:56:43.024225 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */

  
    

  create  table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m20:56:43.026795 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.001 seconds
[0m20:56:43.029936 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m20:56:43.030440 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m20:56:43.031321 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:43.034251 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m20:56:43.034749 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m20:56:43.035537 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:43.040456 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m20:56:43.041434 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m20:56:43.042203 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m20:56:43.044653 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:56:43.047920 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m20:56:43.049422 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m20:56:43.049966 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
drop table if exists "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m20:56:43.052446 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:56:43.055020 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: Close
[0m20:56:43.056146 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b852a300>]}
[0m20:56:43.057391 [info ] [Thread-1 (]: 7 of 22 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.06s]
[0m20:56:43.058594 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m20:56:43.059265 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m20:56:43.060014 [info ] [Thread-1 (]: 8 of 22 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m20:56:43.060863 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m20:56:43.061468 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m20:56:43.064668 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m20:56:43.065587 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m20:56:43.069630 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.payment"
[0m20:56:43.070706 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m20:56:43.071522 [debug] [Thread-1 (]: On model.data_warehouse.payment: BEGIN
[0m20:56:43.072094 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:56:43.084460 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m20:56:43.085044 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m20:56:43.085507 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."payment"
  );
  
[0m20:56:43.098539 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.013 seconds
[0m20:56:43.101751 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m20:56:43.102245 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m20:56:43.103192 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:43.108163 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m20:56:43.108695 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m20:56:43.109488 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:43.111916 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m20:56:43.112417 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m20:56:43.112884 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m20:56:43.118206 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m20:56:43.122214 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m20:56:43.123241 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m20:56:43.123735 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m20:56:43.126451 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:56:43.128116 [debug] [Thread-1 (]: On model.data_warehouse.payment: Close
[0m20:56:43.128986 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b784cec0>]}
[0m20:56:43.130385 [info ] [Thread-1 (]: 8 of 22 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.07s]
[0m20:56:43.131855 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m20:56:43.132408 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m20:56:43.132986 [info ] [Thread-1 (]: 9 of 22 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m20:56:43.133885 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m20:56:43.134692 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m20:56:43.138356 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m20:56:43.139480 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m20:56:43.146132 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.rental"
[0m20:56:43.147426 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m20:56:43.148425 [debug] [Thread-1 (]: On model.data_warehouse.rental: BEGIN
[0m20:56:43.150141 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:56:43.165239 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m20:56:43.166106 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m20:56:43.166890 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."rental"
  );
  
[0m20:56:43.178892 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.011 seconds
[0m20:56:43.182251 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m20:56:43.182774 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m20:56:43.183639 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:43.186579 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m20:56:43.187296 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m20:56:43.188591 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:43.191327 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m20:56:43.192019 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m20:56:43.192584 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m20:56:43.195763 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m20:56:43.198397 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m20:56:43.199318 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m20:56:43.199880 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m20:56:43.202667 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:56:43.204265 [debug] [Thread-1 (]: On model.data_warehouse.rental: Close
[0m20:56:43.205132 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b78296d0>]}
[0m20:56:43.206516 [info ] [Thread-1 (]: 9 of 22 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.07s]
[0m20:56:43.208018 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m20:56:43.208589 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m20:56:43.209160 [info ] [Thread-1 (]: 10 of 22 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m20:56:43.209919 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m20:56:43.210484 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m20:56:43.215002 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m20:56:43.215939 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m20:56:43.219992 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.staff"
[0m20:56:43.220879 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m20:56:43.221705 [debug] [Thread-1 (]: On model.data_warehouse.staff: BEGIN
[0m20:56:43.222209 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:56:43.232970 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m20:56:43.233592 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m20:56:43.234109 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."staff"
  );
  
[0m20:56:43.239337 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.005 seconds
[0m20:56:43.242660 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m20:56:43.243269 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m20:56:43.244579 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:43.249768 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m20:56:43.250360 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m20:56:43.251377 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:43.255419 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m20:56:43.256722 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m20:56:43.257769 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m20:56:43.260027 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m20:56:43.264434 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m20:56:43.265663 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m20:56:43.266133 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m20:56:43.268678 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:56:43.270281 [debug] [Thread-1 (]: On model.data_warehouse.staff: Close
[0m20:56:43.271227 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b782bd70>]}
[0m20:56:43.272807 [info ] [Thread-1 (]: 10 of 22 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.06s]
[0m20:56:43.275449 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m20:56:43.276099 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m20:56:43.276855 [info ] [Thread-1 (]: 11 of 22 START sql table model dbt_dev_intermediate.dim_actor .................. [RUN]
[0m20:56:43.277534 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m20:56:43.278056 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m20:56:43.281927 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m20:56:43.282863 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m20:56:43.294498 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_actor"
[0m20:56:43.295378 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m20:56:43.295980 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: BEGIN
[0m20:56:43.296492 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:56:43.308794 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m20:56:43.309322 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m20:56:43.309903 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."actor"
  );
  
[0m20:56:43.311798 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.001 seconds
[0m20:56:43.362785 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m20:56:43.363566 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_actor" rename to "dim_actor__dbt_backup"
[0m20:56:43.364472 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:43.367530 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m20:56:43.368128 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m20:56:43.369001 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:43.371150 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m20:56:43.371708 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m20:56:43.372218 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m20:56:43.374070 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m20:56:43.376526 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_backup"
[0m20:56:43.377491 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m20:56:43.378015 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_backup" cascade
[0m20:56:43.380290 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:56:43.381927 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: Close
[0m20:56:43.382713 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b789a180>]}
[0m20:56:43.383504 [info ] [Thread-1 (]: 11 of 22 OK created sql table model dbt_dev_intermediate.dim_actor ............. [[32mSELECT 200[0m in 0.11s]
[0m20:56:43.384403 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m20:56:43.385024 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m20:56:43.385636 [info ] [Thread-1 (]: 12 of 22 START sql table model dbt_dev_intermediate.dim_address ................ [RUN]
[0m20:56:43.386411 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m20:56:43.386989 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m20:56:43.390787 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m20:56:43.391732 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m20:56:43.397147 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_address"
[0m20:56:43.398840 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m20:56:43.399628 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: BEGIN
[0m20:56:43.400063 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:56:43.412711 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m20:56:43.413251 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m20:56:43.413875 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."address"
  );
  
[0m20:56:43.416081 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m20:56:43.419125 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m20:56:43.419626 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_address" rename to "dim_address__dbt_backup"
[0m20:56:43.420536 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:43.426224 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m20:56:43.426752 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_tmp" rename to "dim_address"
[0m20:56:43.427602 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:43.429971 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m20:56:43.430475 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m20:56:43.430931 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m20:56:43.432912 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:56:43.435405 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_backup"
[0m20:56:43.436351 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m20:56:43.436835 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_backup" cascade
[0m20:56:43.439352 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:56:43.441175 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: Close
[0m20:56:43.441980 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b931b380>]}
[0m20:56:43.442828 [info ] [Thread-1 (]: 12 of 22 OK created sql table model dbt_dev_intermediate.dim_address ........... [[32mSELECT 603[0m in 0.06s]
[0m20:56:43.443831 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m20:56:43.444420 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m20:56:43.445085 [info ] [Thread-1 (]: 13 of 22 START sql table model dbt_dev_intermediate.dim_customer ............... [RUN]
[0m20:56:43.445773 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m20:56:43.446272 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m20:56:43.449776 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m20:56:43.450729 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m20:56:43.457529 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_customer"
[0m20:56:43.458825 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m20:56:43.459615 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: BEGIN
[0m20:56:43.460138 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:56:43.474603 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m20:56:43.475360 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m20:56:43.476119 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."customer"
  );
  
[0m20:56:43.479770 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.003 seconds
[0m20:56:43.484857 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m20:56:43.485647 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_customer" rename to "dim_customer__dbt_backup"
[0m20:56:43.486808 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:43.491660 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m20:56:43.492328 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m20:56:43.493383 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:43.495572 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m20:56:43.496344 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m20:56:43.496930 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m20:56:43.499155 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:56:43.501931 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_backup"
[0m20:56:43.502926 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m20:56:43.503452 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_backup" cascade
[0m20:56:43.505802 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:56:43.507455 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: Close
[0m20:56:43.508212 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b79ecf50>]}
[0m20:56:43.509037 [info ] [Thread-1 (]: 13 of 22 OK created sql table model dbt_dev_intermediate.dim_customer .......... [[32mSELECT 599[0m in 0.06s]
[0m20:56:43.509906 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m20:56:43.510599 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m20:56:43.511213 [info ] [Thread-1 (]: 14 of 22 START sql table model dbt_dev_intermediate.dim_film ................... [RUN]
[0m20:56:43.511966 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m20:56:43.512574 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m20:56:43.516045 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m20:56:43.516963 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m20:56:43.523664 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film"
[0m20:56:43.524749 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m20:56:43.525532 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: BEGIN
[0m20:56:43.526193 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:56:43.537005 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m20:56:43.537635 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m20:56:43.538823 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."film"
  );
  
[0m20:56:43.546272 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.005 seconds
[0m20:56:43.549582 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m20:56:43.550083 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film" rename to "dim_film__dbt_backup"
[0m20:56:43.550906 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:43.554401 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m20:56:43.555065 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_tmp" rename to "dim_film"
[0m20:56:43.555894 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:43.558059 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m20:56:43.558542 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m20:56:43.558995 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m20:56:43.562153 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m20:56:43.564842 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_backup"
[0m20:56:43.566070 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m20:56:43.566659 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_backup" cascade
[0m20:56:43.569485 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:56:43.571149 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: Close
[0m20:56:43.572005 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b78651f0>]}
[0m20:56:43.572857 [info ] [Thread-1 (]: 14 of 22 OK created sql table model dbt_dev_intermediate.dim_film .............. [[32mSELECT 1000[0m in 0.06s]
[0m20:56:43.573798 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m20:56:43.574407 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m20:56:43.575037 [info ] [Thread-1 (]: 15 of 22 START sql table model dbt_dev_intermediate.dim_film_actor ............. [RUN]
[0m20:56:43.575761 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m20:56:43.576606 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m20:56:43.580771 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m20:56:43.581817 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m20:56:43.592075 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film_actor"
[0m20:56:43.593326 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m20:56:43.594622 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: BEGIN
[0m20:56:43.595593 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:56:43.609618 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m20:56:43.610231 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m20:56:43.610892 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m20:56:43.615732 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.004 seconds
[0m20:56:43.618941 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m20:56:43.619543 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor" rename to "dim_film_actor__dbt_backup"
[0m20:56:43.620468 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:43.623807 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m20:56:43.624368 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m20:56:43.625259 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:43.627392 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m20:56:43.627969 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m20:56:43.628567 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m20:56:43.631665 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m20:56:43.634286 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_backup"
[0m20:56:43.635266 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m20:56:43.635781 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_backup" cascade
[0m20:56:43.638149 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:56:43.639827 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: Close
[0m20:56:43.640640 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b79ce180>]}
[0m20:56:43.641452 [info ] [Thread-1 (]: 15 of 22 OK created sql table model dbt_dev_intermediate.dim_film_actor ........ [[32mSELECT 5462[0m in 0.06s]
[0m20:56:43.642334 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m20:56:43.642999 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m20:56:43.643657 [info ] [Thread-1 (]: 16 of 22 START sql table model dbt_dev_intermediate.dim_inventory .............. [RUN]
[0m20:56:43.644443 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.dim_inventory)
[0m20:56:43.645345 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m20:56:43.652942 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m20:56:43.654165 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m20:56:43.660814 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_inventory"
[0m20:56:43.661628 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m20:56:43.662096 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: BEGIN
[0m20:56:43.662523 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:56:43.675902 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m20:56:43.676700 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m20:56:43.677201 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."inventory"
  );
  
[0m20:56:43.681989 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.004 seconds
[0m20:56:43.685994 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m20:56:43.686896 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_inventory" rename to "dim_inventory__dbt_backup"
[0m20:56:43.688280 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:56:43.693911 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m20:56:43.694418 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m20:56:43.695803 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:56:43.697964 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m20:56:43.698486 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m20:56:43.698947 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m20:56:43.702001 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:56:43.704716 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_backup"
[0m20:56:43.705820 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m20:56:43.706312 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_backup" cascade
[0m20:56:43.708698 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:56:43.710456 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: Close
[0m20:56:43.711322 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b7828a10>]}
[0m20:56:43.712748 [info ] [Thread-1 (]: 16 of 22 OK created sql table model dbt_dev_intermediate.dim_inventory ......... [[32mSELECT 4581[0m in 0.07s]
[0m20:56:43.714149 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m20:56:43.714802 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m20:56:43.715379 [info ] [Thread-1 (]: 17 of 22 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m20:56:43.716160 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m20:56:43.716839 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m20:56:43.720358 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m20:56:43.721139 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m20:56:43.747372 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_second_dbt_model"
[0m20:56:43.748159 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m20:56:43.748634 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: BEGIN
[0m20:56:43.749077 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:56:43.761360 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m20:56:43.762090 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m20:56:43.762825 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */

  create view "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "data_warehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m20:56:43.764677 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.001 seconds
[0m20:56:43.768017 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m20:56:43.768599 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m20:56:43.769677 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:43.771797 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m20:56:43.772381 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m20:56:43.772894 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m20:56:43.775007 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:56:43.777596 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m20:56:43.782761 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m20:56:43.783310 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
drop view if exists "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m20:56:43.784129 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m20:56:43.785798 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: Close
[0m20:56:43.786618 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b786dbe0>]}
[0m20:56:43.787547 [info ] [Thread-1 (]: 17 of 22 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.07s]
[0m20:56:43.788483 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m20:56:43.789153 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m20:56:43.789926 [info ] [Thread-1 (]: 18 of 22 START sql table model dbt_dev_intermediate.fact_payment ............... [RUN]
[0m20:56:43.790773 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now model.data_warehouse.fact_payment)
[0m20:56:43.791334 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m20:56:43.795807 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m20:56:43.796903 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m20:56:43.801121 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.fact_payment"
[0m20:56:43.802272 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m20:56:43.803365 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: BEGIN
[0m20:56:43.804189 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:56:43.818858 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m20:56:43.819408 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m20:56:43.819978 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."payment"
  );
  
[0m20:56:43.831794 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.011 seconds
[0m20:56:43.837138 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m20:56:43.837717 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediate"."fact_payment" rename to "fact_payment__dbt_backup"
[0m20:56:43.838723 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:43.842047 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m20:56:43.842592 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m20:56:43.843431 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:43.845926 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m20:56:43.846470 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m20:56:43.846973 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m20:56:43.851925 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m20:56:43.854627 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_backup"
[0m20:56:43.855637 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m20:56:43.856138 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_backup" cascade
[0m20:56:43.858499 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:56:43.860141 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: Close
[0m20:56:43.861062 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b78763c0>]}
[0m20:56:43.862504 [info ] [Thread-1 (]: 18 of 22 OK created sql table model dbt_dev_intermediate.fact_payment .......... [[32mSELECT 14596[0m in 0.07s]
[0m20:56:43.864033 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m20:56:43.864649 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m20:56:43.865596 [info ] [Thread-1 (]: 19 of 22 START sql table model dbt_dev_intermediate.dim_rental ................. [RUN]
[0m20:56:43.866277 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.dim_rental)
[0m20:56:43.866932 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m20:56:43.870872 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m20:56:43.872122 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m20:56:43.877857 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_rental"
[0m20:56:43.878750 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m20:56:43.879404 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: BEGIN
[0m20:56:43.879999 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:56:43.893542 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m20:56:43.894178 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m20:56:43.895068 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."rental"
  );
  
[0m20:56:43.908075 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.012 seconds
[0m20:56:43.911435 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m20:56:43.911951 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_rental" rename to "dim_rental__dbt_backup"
[0m20:56:43.913105 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:43.916211 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m20:56:43.916730 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m20:56:43.917568 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:43.919842 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m20:56:43.920402 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m20:56:43.920997 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m20:56:43.928327 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m20:56:43.930977 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_backup"
[0m20:56:43.931953 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m20:56:43.932411 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_backup" cascade
[0m20:56:43.935200 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:56:43.936933 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: Close
[0m20:56:43.937707 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b8939580>]}
[0m20:56:43.938611 [info ] [Thread-1 (]: 19 of 22 OK created sql table model dbt_dev_intermediate.dim_rental ............ [[32mSELECT 16044[0m in 0.07s]
[0m20:56:43.939475 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m20:56:43.940250 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m20:56:43.941411 [info ] [Thread-1 (]: 20 of 22 START sql table model dbt_dev_intermediate.dim_staff .................. [RUN]
[0m20:56:43.942396 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m20:56:43.943299 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m20:56:43.947533 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m20:56:43.948475 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m20:56:43.954068 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_staff"
[0m20:56:43.957066 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m20:56:43.957989 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: BEGIN
[0m20:56:43.958723 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:56:43.970185 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m20:56:43.970824 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m20:56:43.971476 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."staff"
  );
  
[0m20:56:43.978072 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.005 seconds
[0m20:56:43.981622 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m20:56:43.982434 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_staff" rename to "dim_staff__dbt_backup"
[0m20:56:43.983648 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:43.988780 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m20:56:43.989511 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m20:56:43.990663 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:56:43.993042 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m20:56:43.993640 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m20:56:43.994250 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m20:56:43.996093 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m20:56:44.001085 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_backup"
[0m20:56:44.002061 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m20:56:44.002526 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_backup" cascade
[0m20:56:44.004832 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:56:44.006592 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: Close
[0m20:56:44.007338 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b78493a0>]}
[0m20:56:44.008144 [info ] [Thread-1 (]: 20 of 22 OK created sql table model dbt_dev_intermediate.dim_staff ............. [[32mSELECT 2[0m in 0.07s]
[0m20:56:44.009042 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m20:56:44.009684 [debug] [Thread-1 (]: Began running node model.data_warehouse.total_revenue
[0m20:56:44.010268 [info ] [Thread-1 (]: 21 of 22 START sql table model dbt_dev_mart.total_revenue ...................... [RUN]
[0m20:56:44.011041 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_staff, now model.data_warehouse.total_revenue)
[0m20:56:44.011621 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.total_revenue
[0m20:56:44.015289 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.total_revenue"
[0m20:56:44.016155 [debug] [Thread-1 (]: Began executing node model.data_warehouse.total_revenue
[0m20:56:44.020389 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.total_revenue"
[0m20:56:44.021276 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m20:56:44.021912 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: BEGIN
[0m20:56:44.022543 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:56:44.034892 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m20:56:44.035459 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m20:56:44.036006 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    SUM(amount) AS total_revenue,
    payment_date
FROM "data_warehouse"."dbt_dev_intermediate"."fact_payment"
GROUP BY payment_date
  );
  
[0m20:56:44.068516 [debug] [Thread-1 (]: SQL status: SELECT 14365 in 0.032 seconds
[0m20:56:44.071947 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m20:56:44.072465 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue" rename to "total_revenue__dbt_backup"
[0m20:56:44.073400 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:44.076593 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m20:56:44.077091 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp" rename to "total_revenue"
[0m20:56:44.078105 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:56:44.080311 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m20:56:44.080859 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m20:56:44.081339 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m20:56:44.085882 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m20:56:44.088507 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup"
[0m20:56:44.089858 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m20:56:44.090403 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup" cascade
[0m20:56:44.093684 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m20:56:44.096129 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: Close
[0m20:56:44.096950 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b784d910>]}
[0m20:56:44.098082 [info ] [Thread-1 (]: 21 of 22 OK created sql table model dbt_dev_mart.total_revenue ................. [[32mSELECT 14365[0m in 0.09s]
[0m20:56:44.099210 [debug] [Thread-1 (]: Finished running node model.data_warehouse.total_revenue
[0m20:56:44.100171 [debug] [Thread-1 (]: Began running node model.data_warehouse.best_selling
[0m20:56:44.101171 [info ] [Thread-1 (]: 22 of 22 START sql table model dbt_dev_mart.best_selling ....................... [RUN]
[0m20:56:44.101999 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.total_revenue, now model.data_warehouse.best_selling)
[0m20:56:44.102510 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.best_selling
[0m20:56:44.107082 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.best_selling"
[0m20:56:44.107935 [debug] [Thread-1 (]: Began executing node model.data_warehouse.best_selling
[0m20:56:44.114574 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.best_selling"
[0m20:56:44.115396 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling"
[0m20:56:44.115968 [debug] [Thread-1 (]: On model.data_warehouse.best_selling: BEGIN
[0m20:56:44.116472 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:56:44.130053 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m20:56:44.130603 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling"
[0m20:56:44.131089 [debug] [Thread-1 (]: On model.data_warehouse.best_selling: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."best_selling__dbt_tmp"
  
  
    as
  
  (
    

SELECT df.title, COUNT(fp.payment_id) AS total_sales
FROM "data_warehouse"."dbt_dev_intermediate"."dim_film" df
JOIN "data_warehouse"."dbt_dev_intermediate"."dim_inventory" di ON df.film_id = di.film_id
JOIN "data_warehouse"."dbt_dev_intermediate"."dim_rental" dr ON fp.rental_id = dr.rental_id
JOIN "data_warehouse"."dbt_dev_intermediate"."fact_payment" fp ON dr.rental_id = fp.rental_id
GROUP BY df.title
ORDER BY total_sales DESC
  );
  
[0m20:56:44.132272 [debug] [Thread-1 (]: Postgres adapter: Postgres error: missing FROM-clause entry for table "fp"
LINE 17: ...ehouse"."dbt_dev_intermediate"."dim_rental" dr ON fp.rental_...
                                                              ^

[0m20:56:44.132819 [debug] [Thread-1 (]: On model.data_warehouse.best_selling: ROLLBACK
[0m20:56:44.133640 [debug] [Thread-1 (]: On model.data_warehouse.best_selling: Close
[0m20:56:44.143197 [debug] [Thread-1 (]: Database Error in model best_selling (models/mart/best_selling.sql)
  missing FROM-clause entry for table "fp"
  LINE 17: ...ehouse"."dbt_dev_intermediate"."dim_rental" dr ON fp.rental_...
                                                                ^
  compiled Code at target/run/data_warehouse/models/mart/best_selling.sql
[0m20:56:44.143824 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbd4da47-2849-40c8-9b61-ab0eed51c4c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b7838200>]}
[0m20:56:44.144537 [error] [Thread-1 (]: 22 of 22 ERROR creating sql table model dbt_dev_mart.best_selling .............. [[31mERROR[0m in 0.04s]
[0m20:56:44.145670 [debug] [Thread-1 (]: Finished running node model.data_warehouse.best_selling
[0m20:56:44.147837 [debug] [MainThread]: Using postgres connection "master"
[0m20:56:44.148344 [debug] [MainThread]: On master: BEGIN
[0m20:56:44.148856 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:56:44.163226 [debug] [MainThread]: SQL status: BEGIN in 0.014 seconds
[0m20:56:44.163986 [debug] [MainThread]: On master: COMMIT
[0m20:56:44.164620 [debug] [MainThread]: Using postgres connection "master"
[0m20:56:44.165011 [debug] [MainThread]: On master: COMMIT
[0m20:56:44.165614 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:56:44.166089 [debug] [MainThread]: On master: Close
[0m20:56:44.166729 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:56:44.167164 [debug] [MainThread]: Connection 'model.data_warehouse.best_selling' was properly closed.
[0m20:56:44.167729 [info ] [MainThread]: 
[0m20:56:44.168269 [info ] [MainThread]: Finished running 21 table models, 1 view model in 0 hours 0 minutes and 1.94 seconds (1.94s).
[0m20:56:44.176095 [debug] [MainThread]: Command end result
[0m20:56:44.227237 [info ] [MainThread]: 
[0m20:56:44.227888 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m20:56:44.228416 [info ] [MainThread]: 
[0m20:56:44.229189 [error] [MainThread]:   Database Error in model best_selling (models/mart/best_selling.sql)
  missing FROM-clause entry for table "fp"
  LINE 17: ...ehouse"."dbt_dev_intermediate"."dim_rental" dr ON fp.rental_...
                                                                ^
  compiled Code at target/run/data_warehouse/models/mart/best_selling.sql
[0m20:56:44.229752 [info ] [MainThread]: 
[0m20:56:44.230282 [info ] [MainThread]: Done. PASS=21 WARN=0 ERROR=1 SKIP=0 TOTAL=22
[0m20:56:44.231304 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 2.8962448, "process_user_time": 3.659979, "process_kernel_time": 0.195998, "process_mem_max_rss": "110916", "process_in_blocks": "464", "process_out_blocks": "3400", "command_success": false}
[0m20:56:44.232004 [debug] [MainThread]: Command `dbt run` failed at 20:56:44.231880 after 2.90 seconds
[0m20:56:44.232485 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b94a2c30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b9574d40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91b98e05c0>]}
[0m20:56:46.910684 [debug] [MainThread]: Flushing usage events
[0m20:57:57.862237 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f040a6480>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f029363c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f026711c0>]}


============================== 20:57:57.865319 | 35cd2536-ab65-45b9-b5f2-91baed269d15 ==============================
[0m20:57:57.865319 [info ] [MainThread]: Running with dbt=1.8.5
[0m20:57:57.866165 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse/logs', 'profiles_dir': '/home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m20:57:58.070082 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f029363c0>]}
[0m20:57:58.134878 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f036f5af0>]}
[0m20:57:58.135827 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m20:57:58.147027 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m20:57:58.283266 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m20:57:58.284045 [debug] [MainThread]: Partial parsing: updated file: data_warehouse://models/mart/best_selling.sql
[0m20:57:58.565397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f01bffe30>]}
[0m20:57:58.677861 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f017586e0>]}
[0m20:57:58.678895 [info ] [MainThread]: Found 23 models, 4 data tests, 9 sources, 417 macros
[0m20:57:58.679802 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f01713980>]}
[0m20:57:58.684254 [info ] [MainThread]: 
[0m20:57:58.685572 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:57:58.696407 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m20:57:58.748067 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m20:57:58.748716 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m20:57:58.749119 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:57:58.764180 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.015 seconds
[0m20:57:58.765712 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m20:57:58.769752 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m20:57:58.770378 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m20:57:58.770901 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:57:58.782343 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.011 seconds
[0m20:57:58.783919 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m20:57:58.786374 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m20:57:58.787027 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m20:57:58.787461 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:57:58.798995 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.011 seconds
[0m20:57:58.800463 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m20:57:58.802706 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m20:57:58.803315 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m20:57:58.803852 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:57:58.819520 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.016 seconds
[0m20:57:58.822266 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m20:57:58.827624 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse, now list_data_warehouse_dbt_dev)
[0m20:57:58.836157 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m20:57:58.836666 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m20:57:58.837093 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:57:58.847690 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m20:57:58.848238 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m20:57:58.848987 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m20:57:58.852891 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m20:57:58.854450 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m20:57:58.855126 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m20:57:58.855896 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_intermediate)
[0m20:57:58.859023 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediate"
[0m20:57:58.859508 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: BEGIN
[0m20:57:58.859937 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:57:58.870783 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m20:57:58.871285 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediate"
[0m20:57:58.871890 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediate"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediate'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediate'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediate'
  
[0m20:57:58.875089 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m20:57:58.876708 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: ROLLBACK
[0m20:57:58.877376 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: Close
[0m20:57:58.878252 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_intermediate, now list_data_warehouse_dbt_dev_mart)
[0m20:57:58.882975 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m20:57:58.883405 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: BEGIN
[0m20:57:58.883830 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:57:58.894619 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m20:57:58.895083 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m20:57:58.895500 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_mart"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m20:57:58.898685 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.003 seconds
[0m20:57:58.900284 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: ROLLBACK
[0m20:57:58.900967 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: Close
[0m20:57:58.901753 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_mart, now list_data_warehouse_dbt_dev_raw)
[0m20:57:58.904346 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m20:57:58.904846 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m20:57:58.905253 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:57:58.916191 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m20:57:58.916701 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m20:57:58.917210 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m20:57:58.920545 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m20:57:58.922220 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m20:57:58.922897 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m20:57:58.931346 [debug] [MainThread]: Using postgres connection "master"
[0m20:57:58.931816 [debug] [MainThread]: On master: BEGIN
[0m20:57:58.932194 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:57:58.942672 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m20:57:58.943180 [debug] [MainThread]: Using postgres connection "master"
[0m20:57:58.943833 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:57:58.962385 [debug] [MainThread]: SQL status: SELECT 38 in 0.018 seconds
[0m20:57:58.964879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f0251e3c0>]}
[0m20:57:58.965422 [debug] [MainThread]: On master: ROLLBACK
[0m20:57:58.966039 [debug] [MainThread]: Using postgres connection "master"
[0m20:57:58.966448 [debug] [MainThread]: On master: BEGIN
[0m20:57:58.967112 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m20:57:58.967522 [debug] [MainThread]: On master: COMMIT
[0m20:57:58.967932 [debug] [MainThread]: Using postgres connection "master"
[0m20:57:58.968300 [debug] [MainThread]: On master: COMMIT
[0m20:57:58.968817 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:57:58.969223 [debug] [MainThread]: On master: Close
[0m20:57:58.969977 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:57:58.970870 [info ] [MainThread]: 
[0m20:57:58.974015 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m20:57:58.974675 [info ] [Thread-1 (]: 1 of 22 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m20:57:58.975330 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_raw, now model.data_warehouse.actor)
[0m20:57:58.976371 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m20:57:58.989570 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m20:57:58.990856 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m20:57:59.040339 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.actor"
[0m20:57:59.041262 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m20:57:59.041910 [debug] [Thread-1 (]: On model.data_warehouse.actor: BEGIN
[0m20:57:59.042389 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:57:59.053661 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m20:57:59.054228 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m20:57:59.054728 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."actor"
  );
  
[0m20:57:59.056823 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m20:57:59.063538 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m20:57:59.064127 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m20:57:59.065016 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:57:59.068183 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m20:57:59.068730 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m20:57:59.069599 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:57:59.093930 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m20:57:59.094565 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m20:57:59.095297 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m20:57:59.097182 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m20:57:59.105683 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m20:57:59.111853 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m20:57:59.112486 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m20:57:59.115096 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:57:59.117692 [debug] [Thread-1 (]: On model.data_warehouse.actor: Close
[0m20:57:59.119480 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f02fc1d00>]}
[0m20:57:59.120340 [info ] [Thread-1 (]: 1 of 22 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.14s]
[0m20:57:59.121291 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m20:57:59.121896 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m20:57:59.122463 [info ] [Thread-1 (]: 2 of 22 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m20:57:59.123243 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m20:57:59.123818 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m20:57:59.127184 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m20:57:59.128143 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m20:57:59.133107 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.address"
[0m20:57:59.134332 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m20:57:59.134922 [debug] [Thread-1 (]: On model.data_warehouse.address: BEGIN
[0m20:57:59.135375 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:57:59.148764 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m20:57:59.149278 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m20:57:59.149881 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."address"
  );
  
[0m20:57:59.152743 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m20:57:59.155910 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m20:57:59.156497 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m20:57:59.158741 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:57:59.163411 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m20:57:59.163936 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m20:57:59.164760 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:57:59.166921 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m20:57:59.167405 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m20:57:59.167908 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m20:57:59.169951 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:57:59.172584 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."address__dbt_backup"
[0m20:57:59.173605 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m20:57:59.174308 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m20:57:59.177141 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:57:59.179370 [debug] [Thread-1 (]: On model.data_warehouse.address: Close
[0m20:57:59.180161 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f00bb20c0>]}
[0m20:57:59.180980 [info ] [Thread-1 (]: 2 of 22 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.06s]
[0m20:57:59.181863 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m20:57:59.182587 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m20:57:59.183204 [info ] [Thread-1 (]: 3 of 22 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m20:57:59.184090 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m20:57:59.184622 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m20:57:59.188382 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m20:57:59.189130 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m20:57:59.195363 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.customer"
[0m20:57:59.196718 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m20:57:59.197728 [debug] [Thread-1 (]: On model.data_warehouse.customer: BEGIN
[0m20:57:59.198778 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:57:59.213791 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m20:57:59.214310 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m20:57:59.214880 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."customer"
  );
  
[0m20:57:59.217461 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.002 seconds
[0m20:57:59.220917 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m20:57:59.221420 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m20:57:59.222407 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:57:59.227814 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m20:57:59.228341 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m20:57:59.229236 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:57:59.231387 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m20:57:59.231875 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m20:57:59.232486 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m20:57:59.234930 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:57:59.237932 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m20:57:59.238941 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m20:57:59.239408 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m20:57:59.242067 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:57:59.243730 [debug] [Thread-1 (]: On model.data_warehouse.customer: Close
[0m20:57:59.244608 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f00b840e0>]}
[0m20:57:59.246026 [info ] [Thread-1 (]: 3 of 22 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.06s]
[0m20:57:59.247372 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m20:57:59.248032 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m20:57:59.248859 [info ] [Thread-1 (]: 4 of 22 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m20:57:59.249748 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m20:57:59.250251 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m20:57:59.253819 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m20:57:59.254843 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m20:57:59.260920 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film"
[0m20:57:59.261864 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m20:57:59.262951 [debug] [Thread-1 (]: On model.data_warehouse.film: BEGIN
[0m20:57:59.263791 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:57:59.277401 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m20:57:59.278272 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m20:57:59.279412 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."film"
  );
  
[0m20:57:59.285764 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.006 seconds
[0m20:57:59.288930 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m20:57:59.289412 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m20:57:59.291923 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:57:59.295929 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m20:57:59.296429 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m20:57:59.297479 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:57:59.300311 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m20:57:59.300866 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m20:57:59.301476 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m20:57:59.305223 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m20:57:59.308905 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film__dbt_backup"
[0m20:57:59.310330 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m20:57:59.310854 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m20:57:59.313719 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:57:59.316160 [debug] [Thread-1 (]: On model.data_warehouse.film: Close
[0m20:57:59.317112 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f00a363f0>]}
[0m20:57:59.317897 [info ] [Thread-1 (]: 4 of 22 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.07s]
[0m20:57:59.318977 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m20:57:59.319893 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m20:57:59.320834 [info ] [Thread-1 (]: 5 of 22 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m20:57:59.321629 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m20:57:59.322204 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m20:57:59.326587 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m20:57:59.327459 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m20:57:59.334140 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film_actor"
[0m20:57:59.335060 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m20:57:59.335695 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: BEGIN
[0m20:57:59.336213 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:57:59.350019 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m20:57:59.350531 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m20:57:59.350981 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."film_actor"
  );
  
[0m20:57:59.355603 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.004 seconds
[0m20:57:59.360883 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m20:57:59.361434 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m20:57:59.362601 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:57:59.365583 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m20:57:59.366057 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m20:57:59.366876 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:57:59.369209 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m20:57:59.369712 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m20:57:59.370205 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m20:57:59.373144 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:57:59.376161 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m20:57:59.377132 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m20:57:59.377601 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m20:57:59.380100 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:57:59.381712 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: Close
[0m20:57:59.382515 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f00f49340>]}
[0m20:57:59.383332 [info ] [Thread-1 (]: 5 of 22 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.06s]
[0m20:57:59.384232 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m20:57:59.384871 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m20:57:59.385541 [info ] [Thread-1 (]: 6 of 22 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m20:57:59.386302 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m20:57:59.386937 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m20:57:59.390364 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m20:57:59.391393 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m20:57:59.396716 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.inventory"
[0m20:57:59.398261 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m20:57:59.399222 [debug] [Thread-1 (]: On model.data_warehouse.inventory: BEGIN
[0m20:57:59.400220 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:57:59.414927 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m20:57:59.415630 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m20:57:59.416098 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."inventory"
  );
  
[0m20:57:59.420464 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.004 seconds
[0m20:57:59.428145 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m20:57:59.428768 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m20:57:59.429797 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:57:59.433080 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m20:57:59.433574 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m20:57:59.434403 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:57:59.436758 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m20:57:59.437242 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m20:57:59.437706 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m20:57:59.440878 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m20:57:59.443494 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m20:57:59.444419 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m20:57:59.444942 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m20:57:59.447445 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:57:59.449088 [debug] [Thread-1 (]: On model.data_warehouse.inventory: Close
[0m20:57:59.449972 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f00fb48f0>]}
[0m20:57:59.451405 [info ] [Thread-1 (]: 6 of 22 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.06s]
[0m20:57:59.452805 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m20:57:59.453352 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m20:57:59.453923 [info ] [Thread-1 (]: 7 of 22 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m20:57:59.454716 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m20:57:59.455543 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m20:57:59.458744 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m20:57:59.460222 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m20:57:59.467888 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_first_dbt_model"
[0m20:57:59.468807 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m20:57:59.469312 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: BEGIN
[0m20:57:59.469756 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:57:59.483159 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m20:57:59.483838 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m20:57:59.484293 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */

  
    

  create  table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m20:57:59.486137 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.001 seconds
[0m20:57:59.489269 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m20:57:59.489885 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m20:57:59.491118 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:57:59.495205 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m20:57:59.495736 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m20:57:59.496609 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:57:59.499380 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m20:57:59.500219 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m20:57:59.500997 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m20:57:59.502831 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m20:57:59.505377 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m20:57:59.506363 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m20:57:59.507160 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
drop table if exists "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m20:57:59.510516 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m20:57:59.512388 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: Close
[0m20:57:59.513292 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f00f40b90>]}
[0m20:57:59.514700 [info ] [Thread-1 (]: 7 of 22 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.06s]
[0m20:57:59.516069 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m20:57:59.516672 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m20:57:59.517437 [info ] [Thread-1 (]: 8 of 22 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m20:57:59.518273 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m20:57:59.518914 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m20:57:59.522522 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m20:57:59.523261 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m20:57:59.529473 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.payment"
[0m20:57:59.530357 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m20:57:59.530955 [debug] [Thread-1 (]: On model.data_warehouse.payment: BEGIN
[0m20:57:59.531404 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:57:59.544487 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m20:57:59.545451 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m20:57:59.546172 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."payment"
  );
  
[0m20:57:59.556198 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.009 seconds
[0m20:57:59.562120 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m20:57:59.562656 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m20:57:59.563464 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:57:59.566438 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m20:57:59.566924 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m20:57:59.567716 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:57:59.570122 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m20:57:59.570647 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m20:57:59.571438 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m20:57:59.576960 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m20:57:59.580635 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m20:57:59.581632 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m20:57:59.582093 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m20:57:59.584531 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:57:59.586151 [debug] [Thread-1 (]: On model.data_warehouse.payment: Close
[0m20:57:59.587010 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f00a2d940>]}
[0m20:57:59.588400 [info ] [Thread-1 (]: 8 of 22 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.07s]
[0m20:57:59.589876 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m20:57:59.590523 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m20:57:59.591458 [info ] [Thread-1 (]: 9 of 22 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m20:57:59.592125 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m20:57:59.592665 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m20:57:59.597226 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m20:57:59.598474 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m20:57:59.606376 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.rental"
[0m20:57:59.609064 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m20:57:59.610290 [debug] [Thread-1 (]: On model.data_warehouse.rental: BEGIN
[0m20:57:59.611135 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:57:59.625929 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m20:57:59.626925 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m20:57:59.627605 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."rental"
  );
  
[0m20:57:59.638106 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.010 seconds
[0m20:57:59.641563 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m20:57:59.642091 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m20:57:59.642900 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:57:59.646070 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m20:57:59.646611 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m20:57:59.647380 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:57:59.649740 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m20:57:59.650214 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m20:57:59.650650 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m20:57:59.656952 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m20:57:59.659598 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m20:57:59.660502 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m20:57:59.660951 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m20:57:59.663497 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:57:59.665114 [debug] [Thread-1 (]: On model.data_warehouse.rental: Close
[0m20:57:59.665957 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f00a1ab70>]}
[0m20:57:59.667334 [info ] [Thread-1 (]: 9 of 22 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.07s]
[0m20:57:59.668840 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m20:57:59.669491 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m20:57:59.670310 [info ] [Thread-1 (]: 10 of 22 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m20:57:59.670977 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m20:57:59.671460 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m20:57:59.674964 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m20:57:59.676004 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m20:57:59.681923 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.staff"
[0m20:57:59.682771 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m20:57:59.683322 [debug] [Thread-1 (]: On model.data_warehouse.staff: BEGIN
[0m20:57:59.683814 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:57:59.695993 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m20:57:59.696594 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m20:57:59.697087 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."staff"
  );
  
[0m20:57:59.701978 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.004 seconds
[0m20:57:59.705225 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m20:57:59.705779 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m20:57:59.706866 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:57:59.712518 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m20:57:59.713167 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m20:57:59.714028 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:57:59.716548 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m20:57:59.717113 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m20:57:59.717830 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m20:57:59.720365 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:57:59.723085 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m20:57:59.724476 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m20:57:59.725359 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m20:57:59.728178 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:57:59.729930 [debug] [Thread-1 (]: On model.data_warehouse.staff: Close
[0m20:57:59.730758 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f00bfffe0>]}
[0m20:57:59.731593 [info ] [Thread-1 (]: 10 of 22 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.06s]
[0m20:57:59.732454 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m20:57:59.733086 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m20:57:59.733722 [info ] [Thread-1 (]: 11 of 22 START sql table model dbt_dev_intermediate.dim_actor .................. [RUN]
[0m20:57:59.734536 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m20:57:59.735047 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m20:57:59.738302 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m20:57:59.739111 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m20:57:59.745621 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_actor"
[0m20:57:59.746757 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m20:57:59.748181 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: BEGIN
[0m20:57:59.748899 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:57:59.761644 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m20:57:59.762956 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m20:57:59.763732 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."actor"
  );
  
[0m20:57:59.766063 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m20:57:59.819960 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m20:57:59.820493 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_actor" rename to "dim_actor__dbt_backup"
[0m20:57:59.821458 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:57:59.826046 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m20:57:59.826949 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m20:57:59.828099 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:57:59.831604 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m20:57:59.832376 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m20:57:59.833077 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m20:57:59.834993 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m20:57:59.837478 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_backup"
[0m20:57:59.838387 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m20:57:59.838845 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_backup" cascade
[0m20:57:59.840924 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:57:59.842527 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: Close
[0m20:57:59.843269 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f026fd700>]}
[0m20:57:59.844050 [info ] [Thread-1 (]: 11 of 22 OK created sql table model dbt_dev_intermediate.dim_actor ............. [[32mSELECT 200[0m in 0.11s]
[0m20:57:59.845032 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m20:57:59.845684 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m20:57:59.846470 [info ] [Thread-1 (]: 12 of 22 START sql table model dbt_dev_intermediate.dim_address ................ [RUN]
[0m20:57:59.847153 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m20:57:59.847835 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m20:57:59.852828 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m20:57:59.854546 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m20:57:59.863216 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_address"
[0m20:57:59.864226 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m20:57:59.864816 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: BEGIN
[0m20:57:59.865569 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:57:59.878102 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m20:57:59.878706 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m20:57:59.879292 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."address"
  );
  
[0m20:57:59.881927 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m20:57:59.884991 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m20:57:59.885480 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_address" rename to "dim_address__dbt_backup"
[0m20:57:59.886287 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:57:59.889377 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m20:57:59.889963 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_tmp" rename to "dim_address"
[0m20:57:59.890888 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:57:59.893361 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m20:57:59.893872 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m20:57:59.894299 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m20:57:59.896099 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m20:57:59.898525 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_backup"
[0m20:57:59.899439 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m20:57:59.899905 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_backup" cascade
[0m20:57:59.902708 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:57:59.904307 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: Close
[0m20:57:59.905056 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f00ffa5d0>]}
[0m20:57:59.905857 [info ] [Thread-1 (]: 12 of 22 OK created sql table model dbt_dev_intermediate.dim_address ........... [[32mSELECT 603[0m in 0.06s]
[0m20:57:59.906986 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m20:57:59.907938 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m20:57:59.908785 [info ] [Thread-1 (]: 13 of 22 START sql table model dbt_dev_intermediate.dim_customer ............... [RUN]
[0m20:57:59.909538 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m20:57:59.910096 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m20:57:59.913641 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m20:57:59.914595 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m20:57:59.919980 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_customer"
[0m20:57:59.921008 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m20:57:59.922019 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: BEGIN
[0m20:57:59.922818 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:57:59.937849 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m20:57:59.938672 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m20:57:59.939589 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."customer"
  );
  
[0m20:57:59.944339 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.004 seconds
[0m20:57:59.949628 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m20:57:59.950139 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_customer" rename to "dim_customer__dbt_backup"
[0m20:57:59.951019 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:57:59.955445 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m20:57:59.956006 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m20:57:59.957040 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:57:59.959211 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m20:57:59.959707 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m20:57:59.960135 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m20:57:59.962171 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:57:59.964871 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_backup"
[0m20:57:59.965892 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m20:57:59.966362 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_backup" cascade
[0m20:57:59.968677 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:57:59.970514 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: Close
[0m20:57:59.971422 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f00b0be00>]}
[0m20:57:59.972835 [info ] [Thread-1 (]: 13 of 22 OK created sql table model dbt_dev_intermediate.dim_customer .......... [[32mSELECT 599[0m in 0.06s]
[0m20:57:59.974292 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m20:57:59.974862 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m20:57:59.975422 [info ] [Thread-1 (]: 14 of 22 START sql table model dbt_dev_intermediate.dim_film ................... [RUN]
[0m20:57:59.976206 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m20:57:59.976899 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m20:57:59.981325 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m20:57:59.982462 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m20:57:59.987331 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film"
[0m20:57:59.988212 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m20:57:59.989091 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: BEGIN
[0m20:57:59.989548 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:00.004206 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m20:58:00.004759 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m20:58:00.005256 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."film"
  );
  
[0m20:58:00.013798 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.008 seconds
[0m20:58:00.017133 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m20:58:00.017656 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film" rename to "dim_film__dbt_backup"
[0m20:58:00.018515 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:00.021647 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m20:58:00.022136 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_tmp" rename to "dim_film"
[0m20:58:00.023117 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:00.027114 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m20:58:00.027971 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m20:58:00.028718 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m20:58:00.032868 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m20:58:00.035690 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_backup"
[0m20:58:00.036916 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m20:58:00.037450 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_backup" cascade
[0m20:58:00.040108 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:58:00.041929 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: Close
[0m20:58:00.042817 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f00b90680>]}
[0m20:58:00.044235 [info ] [Thread-1 (]: 14 of 22 OK created sql table model dbt_dev_intermediate.dim_film .............. [[32mSELECT 1000[0m in 0.07s]
[0m20:58:00.045793 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m20:58:00.046414 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m20:58:00.050057 [info ] [Thread-1 (]: 15 of 22 START sql table model dbt_dev_intermediate.dim_film_actor ............. [RUN]
[0m20:58:00.050861 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m20:58:00.051862 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m20:58:00.056899 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m20:58:00.058433 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m20:58:00.064349 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film_actor"
[0m20:58:00.065100 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m20:58:00.065597 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: BEGIN
[0m20:58:00.066044 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:00.078399 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m20:58:00.078984 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m20:58:00.079424 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m20:58:00.084005 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.004 seconds
[0m20:58:00.087212 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m20:58:00.087727 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor" rename to "dim_film_actor__dbt_backup"
[0m20:58:00.088538 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:00.093893 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m20:58:00.094418 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m20:58:00.095233 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:00.097351 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m20:58:00.097851 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m20:58:00.098271 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m20:58:00.101071 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:58:00.103814 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_backup"
[0m20:58:00.104760 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m20:58:00.105211 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_backup" cascade
[0m20:58:00.107798 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:58:00.109454 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: Close
[0m20:58:00.110406 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f00b91790>]}
[0m20:58:00.111266 [info ] [Thread-1 (]: 15 of 22 OK created sql table model dbt_dev_intermediate.dim_film_actor ........ [[32mSELECT 5462[0m in 0.06s]
[0m20:58:00.112147 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m20:58:00.112801 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m20:58:00.113628 [info ] [Thread-1 (]: 16 of 22 START sql table model dbt_dev_intermediate.dim_inventory .............. [RUN]
[0m20:58:00.114294 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.dim_inventory)
[0m20:58:00.114950 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m20:58:00.120370 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m20:58:00.121226 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m20:58:00.127348 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_inventory"
[0m20:58:00.128656 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m20:58:00.130071 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: BEGIN
[0m20:58:00.130749 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:00.145036 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m20:58:00.146114 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m20:58:00.147080 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."inventory"
  );
  
[0m20:58:00.151669 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.004 seconds
[0m20:58:00.154926 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m20:58:00.155432 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_inventory" rename to "dim_inventory__dbt_backup"
[0m20:58:00.156339 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:00.161156 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m20:58:00.161703 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m20:58:00.162523 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:00.164709 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m20:58:00.165237 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m20:58:00.165688 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m20:58:00.168643 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:58:00.171404 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_backup"
[0m20:58:00.172344 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m20:58:00.172812 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_backup" cascade
[0m20:58:00.175546 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:58:00.177167 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: Close
[0m20:58:00.178048 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f00feba70>]}
[0m20:58:00.179465 [info ] [Thread-1 (]: 16 of 22 OK created sql table model dbt_dev_intermediate.dim_inventory ......... [[32mSELECT 4581[0m in 0.06s]
[0m20:58:00.180856 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m20:58:00.181567 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m20:58:00.182238 [info ] [Thread-1 (]: 17 of 22 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m20:58:00.182972 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m20:58:00.183448 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m20:58:00.186662 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m20:58:00.187410 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m20:58:00.214679 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_second_dbt_model"
[0m20:58:00.215452 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m20:58:00.215949 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: BEGIN
[0m20:58:00.216372 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:00.228755 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m20:58:00.229461 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m20:58:00.230112 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */

  create view "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "data_warehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m20:58:00.232633 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.002 seconds
[0m20:58:00.236740 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m20:58:00.237333 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m20:58:00.238298 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:00.241182 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m20:58:00.241991 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m20:58:00.242446 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m20:58:00.243934 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m20:58:00.246776 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m20:58:00.250648 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m20:58:00.251183 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
drop view if exists "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m20:58:00.252317 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m20:58:00.253912 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: Close
[0m20:58:00.254703 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f00fb53a0>]}
[0m20:58:00.255482 [info ] [Thread-1 (]: 17 of 22 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.07s]
[0m20:58:00.256378 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m20:58:00.257017 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m20:58:00.257758 [info ] [Thread-1 (]: 18 of 22 START sql table model dbt_dev_intermediate.fact_payment ............... [RUN]
[0m20:58:00.258454 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now model.data_warehouse.fact_payment)
[0m20:58:00.259054 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m20:58:00.262423 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m20:58:00.263741 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m20:58:00.270120 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.fact_payment"
[0m20:58:00.270985 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m20:58:00.271469 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: BEGIN
[0m20:58:00.271911 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:00.285518 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m20:58:00.286110 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m20:58:00.286628 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."payment"
  );
  
[0m20:58:00.298317 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.011 seconds
[0m20:58:00.303540 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m20:58:00.304135 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediate"."fact_payment" rename to "fact_payment__dbt_backup"
[0m20:58:00.305066 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:00.308575 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m20:58:00.309143 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m20:58:00.310007 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:00.312191 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m20:58:00.312746 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m20:58:00.313504 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m20:58:00.318996 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m20:58:00.321726 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_backup"
[0m20:58:00.322727 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m20:58:00.323247 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_backup" cascade
[0m20:58:00.325557 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:58:00.327182 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: Close
[0m20:58:00.327944 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f0251cf20>]}
[0m20:58:00.328837 [info ] [Thread-1 (]: 18 of 22 OK created sql table model dbt_dev_intermediate.fact_payment .......... [[32mSELECT 14596[0m in 0.07s]
[0m20:58:00.329844 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m20:58:00.330708 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m20:58:00.331675 [info ] [Thread-1 (]: 19 of 22 START sql table model dbt_dev_intermediate.dim_rental ................. [RUN]
[0m20:58:00.332811 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.dim_rental)
[0m20:58:00.333763 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m20:58:00.339693 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m20:58:00.341744 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m20:58:00.347740 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_rental"
[0m20:58:00.348595 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m20:58:00.349085 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: BEGIN
[0m20:58:00.349506 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:00.361454 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m20:58:00.361995 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m20:58:00.362945 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."rental"
  );
  
[0m20:58:00.374320 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.011 seconds
[0m20:58:00.377525 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m20:58:00.378039 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_rental" rename to "dim_rental__dbt_backup"
[0m20:58:00.378947 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:00.382146 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m20:58:00.382702 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m20:58:00.383581 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:00.385864 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m20:58:00.386621 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m20:58:00.387121 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m20:58:00.393721 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m20:58:00.397321 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_backup"
[0m20:58:00.398404 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m20:58:00.399053 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_backup" cascade
[0m20:58:00.401504 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:58:00.403389 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: Close
[0m20:58:00.404154 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f01b03200>]}
[0m20:58:00.404958 [info ] [Thread-1 (]: 19 of 22 OK created sql table model dbt_dev_intermediate.dim_rental ............ [[32mSELECT 16044[0m in 0.07s]
[0m20:58:00.405886 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m20:58:00.406567 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m20:58:00.407485 [info ] [Thread-1 (]: 20 of 22 START sql table model dbt_dev_intermediate.dim_staff .................. [RUN]
[0m20:58:00.408218 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m20:58:00.408914 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m20:58:00.413403 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m20:58:00.414759 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m20:58:00.421609 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_staff"
[0m20:58:00.422376 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m20:58:00.422945 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: BEGIN
[0m20:58:00.425087 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:00.439990 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m20:58:00.442255 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m20:58:00.443386 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."staff"
  );
  
[0m20:58:00.450064 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.006 seconds
[0m20:58:00.453642 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m20:58:00.454251 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_staff" rename to "dim_staff__dbt_backup"
[0m20:58:00.455176 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:00.459005 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m20:58:00.459515 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m20:58:00.460566 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:58:00.462889 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m20:58:00.463395 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m20:58:00.463843 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m20:58:00.465578 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m20:58:00.469819 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_backup"
[0m20:58:00.470763 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m20:58:00.471217 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_backup" cascade
[0m20:58:00.473601 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:58:00.475235 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: Close
[0m20:58:00.475991 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f00a393a0>]}
[0m20:58:00.476781 [info ] [Thread-1 (]: 20 of 22 OK created sql table model dbt_dev_intermediate.dim_staff ............. [[32mSELECT 2[0m in 0.07s]
[0m20:58:00.477871 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m20:58:00.478674 [debug] [Thread-1 (]: Began running node model.data_warehouse.total_revenue
[0m20:58:00.479457 [info ] [Thread-1 (]: 21 of 22 START sql table model dbt_dev_mart.total_revenue ...................... [RUN]
[0m20:58:00.480142 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_staff, now model.data_warehouse.total_revenue)
[0m20:58:00.480673 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.total_revenue
[0m20:58:00.485547 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.total_revenue"
[0m20:58:00.486610 [debug] [Thread-1 (]: Began executing node model.data_warehouse.total_revenue
[0m20:58:00.494299 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.total_revenue"
[0m20:58:00.495770 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m20:58:00.496296 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: BEGIN
[0m20:58:00.496740 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:00.509135 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m20:58:00.510456 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m20:58:00.511134 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    SUM(amount) AS total_revenue,
    payment_date
FROM "data_warehouse"."dbt_dev_intermediate"."fact_payment"
GROUP BY payment_date
  );
  
[0m20:58:00.538813 [debug] [Thread-1 (]: SQL status: SELECT 14365 in 0.027 seconds
[0m20:58:00.542109 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m20:58:00.542780 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue" rename to "total_revenue__dbt_backup"
[0m20:58:00.544027 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:00.549502 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m20:58:00.550399 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp" rename to "total_revenue"
[0m20:58:00.551532 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:00.555006 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m20:58:00.555793 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m20:58:00.556248 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m20:58:00.560703 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m20:58:00.563668 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup"
[0m20:58:00.564727 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m20:58:00.565196 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup" cascade
[0m20:58:00.568027 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:58:00.569632 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: Close
[0m20:58:00.570508 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f01bf90d0>]}
[0m20:58:00.571910 [info ] [Thread-1 (]: 21 of 22 OK created sql table model dbt_dev_mart.total_revenue ................. [[32mSELECT 14365[0m in 0.09s]
[0m20:58:00.573387 [debug] [Thread-1 (]: Finished running node model.data_warehouse.total_revenue
[0m20:58:00.573966 [debug] [Thread-1 (]: Began running node model.data_warehouse.best_selling
[0m20:58:00.574533 [info ] [Thread-1 (]: 22 of 22 START sql table model dbt_dev_mart.best_selling ....................... [RUN]
[0m20:58:00.575257 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.total_revenue, now model.data_warehouse.best_selling)
[0m20:58:00.575770 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.best_selling
[0m20:58:00.579699 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.best_selling"
[0m20:58:00.580581 [debug] [Thread-1 (]: Began executing node model.data_warehouse.best_selling
[0m20:58:00.586705 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.best_selling"
[0m20:58:00.587440 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling"
[0m20:58:00.587928 [debug] [Thread-1 (]: On model.data_warehouse.best_selling: BEGIN
[0m20:58:00.588350 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:00.601878 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m20:58:00.602401 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling"
[0m20:58:00.602899 [debug] [Thread-1 (]: On model.data_warehouse.best_selling: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."best_selling__dbt_tmp"
  
  
    as
  
  (
    

SELECT df.title, COUNT(fp.payment_id) AS total_sales
FROM "data_warehouse"."dbt_dev_intermediate"."dim_film" df
JOIN "data_warehouse"."dbt_dev_intermediate"."dim_inventory" di ON df.film_id = di.film_id
JOIN "data_warehouse"."dbt_dev_intermediate"."dim_rental" dr ON dr.inventory_id = di.inventory_id
JOIN "data_warehouse"."dbt_dev_intermediate"."fact_payment" fp ON fp.rental_id = dr.rental_id
GROUP BY df.title
ORDER BY total_sales DESC;
  );
  
[0m20:58:00.603721 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 20: ORDER BY total_sales DESC;
                                  ^

[0m20:58:00.604205 [debug] [Thread-1 (]: On model.data_warehouse.best_selling: ROLLBACK
[0m20:58:00.604912 [debug] [Thread-1 (]: On model.data_warehouse.best_selling: Close
[0m20:58:00.611822 [debug] [Thread-1 (]: Database Error in model best_selling (models/mart/best_selling.sql)
  syntax error at or near ";"
  LINE 20: ORDER BY total_sales DESC;
                                    ^
  compiled Code at target/run/data_warehouse/models/mart/best_selling.sql
[0m20:58:00.612445 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35cd2536-ab65-45b9-b5f2-91baed269d15', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f00a00f80>]}
[0m20:58:00.613252 [error] [Thread-1 (]: 22 of 22 ERROR creating sql table model dbt_dev_mart.best_selling .............. [[31mERROR[0m in 0.04s]
[0m20:58:00.614076 [debug] [Thread-1 (]: Finished running node model.data_warehouse.best_selling
[0m20:58:00.616211 [debug] [MainThread]: Using postgres connection "master"
[0m20:58:00.616724 [debug] [MainThread]: On master: BEGIN
[0m20:58:00.617148 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:58:00.631291 [debug] [MainThread]: SQL status: BEGIN in 0.014 seconds
[0m20:58:00.631812 [debug] [MainThread]: On master: COMMIT
[0m20:58:00.632253 [debug] [MainThread]: Using postgres connection "master"
[0m20:58:00.632819 [debug] [MainThread]: On master: COMMIT
[0m20:58:00.633444 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:58:00.633921 [debug] [MainThread]: On master: Close
[0m20:58:00.634618 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:58:00.635068 [debug] [MainThread]: Connection 'model.data_warehouse.best_selling' was properly closed.
[0m20:58:00.635674 [info ] [MainThread]: 
[0m20:58:00.636312 [info ] [MainThread]: Finished running 21 table models, 1 view model in 0 hours 0 minutes and 1.95 seconds (1.95s).
[0m20:58:00.643098 [debug] [MainThread]: Command end result
[0m20:58:00.696408 [info ] [MainThread]: 
[0m20:58:00.697086 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m20:58:00.697714 [info ] [MainThread]: 
[0m20:58:00.698472 [error] [MainThread]:   Database Error in model best_selling (models/mart/best_selling.sql)
  syntax error at or near ";"
  LINE 20: ORDER BY total_sales DESC;
                                    ^
  compiled Code at target/run/data_warehouse/models/mart/best_selling.sql
[0m20:58:00.699108 [info ] [MainThread]: 
[0m20:58:00.699862 [info ] [MainThread]: Done. PASS=21 WARN=0 ERROR=1 SKIP=0 TOTAL=22
[0m20:58:00.700933 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 2.8933794, "process_user_time": 3.683094, "process_kernel_time": 0.164316, "process_mem_max_rss": "110844", "process_out_blocks": "3392", "command_success": false, "process_in_blocks": "0"}
[0m20:58:00.701637 [debug] [MainThread]: Command `dbt run` failed at 20:58:00.701489 after 2.89 seconds
[0m20:58:00.702112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f02bac8c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f03c507d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x703f02a9c110>]}
[0m20:58:02.321441 [debug] [MainThread]: Flushing usage events
[0m20:58:13.372201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7567359fce00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7567359fd700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7567351b0b00>]}


============================== 20:58:13.375306 | 7a70f6ac-7910-4248-8e83-c958734d8c80 ==============================
[0m20:58:13.375306 [info ] [MainThread]: Running with dbt=1.8.5
[0m20:58:13.379251 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse', 'debug': 'False', 'version_check': 'True', 'log_path': '/home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m20:58:13.583433 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x756736520170>]}
[0m20:58:13.648197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7567351b3680>]}
[0m20:58:13.649122 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m20:58:13.662022 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m20:58:13.805835 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m20:58:13.806712 [debug] [MainThread]: Partial parsing: updated file: data_warehouse://models/mart/best_selling.sql
[0m20:58:14.090515 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x756734178620>]}
[0m20:58:14.204301 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x756734170980>]}
[0m20:58:14.205267 [info ] [MainThread]: Found 23 models, 4 data tests, 9 sources, 417 macros
[0m20:58:14.206130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x756734c06660>]}
[0m20:58:14.211034 [info ] [MainThread]: 
[0m20:58:14.212224 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:58:14.220787 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m20:58:14.268615 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m20:58:14.269188 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m20:58:14.269911 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:58:14.283259 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.013 seconds
[0m20:58:14.284866 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m20:58:14.288948 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m20:58:14.289523 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m20:58:14.289990 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:58:14.301084 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.011 seconds
[0m20:58:14.302579 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m20:58:14.306391 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m20:58:14.307063 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m20:58:14.307472 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:58:14.318361 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.011 seconds
[0m20:58:14.319900 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m20:58:14.323595 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m20:58:14.324266 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m20:58:14.324724 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:58:14.335814 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.011 seconds
[0m20:58:14.337273 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m20:58:14.340295 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse, now list_data_warehouse_dbt_dev_intermediate)
[0m20:58:14.347969 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediate"
[0m20:58:14.348444 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: BEGIN
[0m20:58:14.348840 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:58:14.359606 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m20:58:14.360110 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediate"
[0m20:58:14.360600 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediate"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediate'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediate'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediate'
  
[0m20:58:14.363880 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m20:58:14.365543 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: ROLLBACK
[0m20:58:14.366235 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: Close
[0m20:58:14.367050 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_intermediate, now list_data_warehouse_dbt_dev)
[0m20:58:14.371976 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m20:58:14.372448 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m20:58:14.372916 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:58:14.383786 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m20:58:14.384289 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m20:58:14.384887 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m20:58:14.388079 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m20:58:14.389716 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m20:58:14.390399 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m20:58:14.391179 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_mart)
[0m20:58:14.394137 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m20:58:14.394621 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: BEGIN
[0m20:58:14.395031 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:58:14.406280 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m20:58:14.406797 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m20:58:14.407386 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_mart"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m20:58:14.410647 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.003 seconds
[0m20:58:14.412160 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: ROLLBACK
[0m20:58:14.412760 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: Close
[0m20:58:14.413641 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_mart, now list_data_warehouse_dbt_dev_raw)
[0m20:58:14.417265 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m20:58:14.417730 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m20:58:14.418126 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:58:14.428962 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m20:58:14.429434 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m20:58:14.429851 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m20:58:14.433129 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m20:58:14.434710 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m20:58:14.435367 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m20:58:14.442813 [debug] [MainThread]: Using postgres connection "master"
[0m20:58:14.443280 [debug] [MainThread]: On master: BEGIN
[0m20:58:14.443774 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:58:14.454532 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m20:58:14.455026 [debug] [MainThread]: Using postgres connection "master"
[0m20:58:14.455492 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:58:14.474106 [debug] [MainThread]: SQL status: SELECT 38 in 0.018 seconds
[0m20:58:14.476519 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x756733544bc0>]}
[0m20:58:14.477056 [debug] [MainThread]: On master: ROLLBACK
[0m20:58:14.477633 [debug] [MainThread]: Using postgres connection "master"
[0m20:58:14.478053 [debug] [MainThread]: On master: BEGIN
[0m20:58:14.478686 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m20:58:14.479116 [debug] [MainThread]: On master: COMMIT
[0m20:58:14.479508 [debug] [MainThread]: Using postgres connection "master"
[0m20:58:14.479911 [debug] [MainThread]: On master: COMMIT
[0m20:58:14.480448 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:58:14.480921 [debug] [MainThread]: On master: Close
[0m20:58:14.481684 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:58:14.482530 [info ] [MainThread]: 
[0m20:58:14.485737 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m20:58:14.486395 [info ] [Thread-1 (]: 1 of 22 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m20:58:14.487145 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_raw, now model.data_warehouse.actor)
[0m20:58:14.487909 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m20:58:14.498662 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m20:58:14.499504 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m20:58:14.550310 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.actor"
[0m20:58:14.551324 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m20:58:14.551891 [debug] [Thread-1 (]: On model.data_warehouse.actor: BEGIN
[0m20:58:14.552322 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:14.562909 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m20:58:14.563449 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m20:58:14.563906 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."actor"
  );
  
[0m20:58:14.565953 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m20:58:14.572670 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m20:58:14.573191 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m20:58:14.574062 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:14.577333 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m20:58:14.577833 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m20:58:14.578703 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:14.601006 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m20:58:14.601597 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m20:58:14.602041 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m20:58:14.603905 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m20:58:14.612282 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m20:58:14.618501 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m20:58:14.619078 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m20:58:14.621264 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:58:14.623843 [debug] [Thread-1 (]: On model.data_warehouse.actor: Close
[0m20:58:14.626842 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7567359fe060>]}
[0m20:58:14.628042 [info ] [Thread-1 (]: 1 of 22 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.14s]
[0m20:58:14.628942 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m20:58:14.629535 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m20:58:14.630153 [info ] [Thread-1 (]: 2 of 22 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m20:58:14.630841 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m20:58:14.631317 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m20:58:14.634800 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m20:58:14.635965 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m20:58:14.641347 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.address"
[0m20:58:14.642637 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m20:58:14.643716 [debug] [Thread-1 (]: On model.data_warehouse.address: BEGIN
[0m20:58:14.644545 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:14.658612 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m20:58:14.659679 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m20:58:14.660504 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."address"
  );
  
[0m20:58:14.663359 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m20:58:14.666762 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m20:58:14.667325 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m20:58:14.668271 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:14.673367 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m20:58:14.674618 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m20:58:14.675592 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:14.677747 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m20:58:14.678280 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m20:58:14.678788 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m20:58:14.680910 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:58:14.683494 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."address__dbt_backup"
[0m20:58:14.684483 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m20:58:14.685123 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m20:58:14.687359 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:58:14.689155 [debug] [Thread-1 (]: On model.data_warehouse.address: Close
[0m20:58:14.689947 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7567335f5a00>]}
[0m20:58:14.690820 [info ] [Thread-1 (]: 2 of 22 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.06s]
[0m20:58:14.691797 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m20:58:14.692511 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m20:58:14.693412 [info ] [Thread-1 (]: 3 of 22 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m20:58:14.694142 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m20:58:14.694858 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m20:58:14.698449 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m20:58:14.699306 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m20:58:14.703418 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.customer"
[0m20:58:14.704317 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m20:58:14.705116 [debug] [Thread-1 (]: On model.data_warehouse.customer: BEGIN
[0m20:58:14.705717 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:14.717607 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m20:58:14.718360 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m20:58:14.718964 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."customer"
  );
  
[0m20:58:14.723301 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.003 seconds
[0m20:58:14.728538 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m20:58:14.729077 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m20:58:14.730040 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:14.733116 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m20:58:14.733615 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m20:58:14.734417 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:14.736568 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m20:58:14.737196 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m20:58:14.737850 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m20:58:14.741308 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:58:14.743906 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m20:58:14.744887 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m20:58:14.745346 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m20:58:14.747928 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:58:14.749599 [debug] [Thread-1 (]: On model.data_warehouse.customer: Close
[0m20:58:14.750355 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7567335f5a00>]}
[0m20:58:14.751171 [info ] [Thread-1 (]: 3 of 22 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.06s]
[0m20:58:14.752076 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m20:58:14.752704 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m20:58:14.753588 [info ] [Thread-1 (]: 4 of 22 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m20:58:14.754446 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m20:58:14.755035 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m20:58:14.758761 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m20:58:14.759609 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m20:58:14.768240 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film"
[0m20:58:14.769047 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m20:58:14.769517 [debug] [Thread-1 (]: On model.data_warehouse.film: BEGIN
[0m20:58:14.770186 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:14.783623 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m20:58:14.784525 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m20:58:14.785284 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."film"
  );
  
[0m20:58:14.794190 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.008 seconds
[0m20:58:14.797412 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m20:58:14.797914 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m20:58:14.798821 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:14.802038 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m20:58:14.802641 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m20:58:14.803465 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:14.807838 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m20:58:14.808452 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m20:58:14.809493 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m20:58:14.812892 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m20:58:14.815471 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film__dbt_backup"
[0m20:58:14.816497 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m20:58:14.816988 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m20:58:14.819512 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:58:14.821372 [debug] [Thread-1 (]: On model.data_warehouse.film: Close
[0m20:58:14.822303 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x756733473da0>]}
[0m20:58:14.823724 [info ] [Thread-1 (]: 4 of 22 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.07s]
[0m20:58:14.825138 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m20:58:14.825714 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m20:58:14.826480 [info ] [Thread-1 (]: 5 of 22 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m20:58:14.827132 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m20:58:14.827664 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m20:58:14.831637 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m20:58:14.832909 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m20:58:14.841235 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film_actor"
[0m20:58:14.842037 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m20:58:14.842518 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: BEGIN
[0m20:58:14.843219 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:14.853838 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m20:58:14.854970 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m20:58:14.857366 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."film_actor"
  );
  
[0m20:58:14.863196 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.005 seconds
[0m20:58:14.867142 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m20:58:14.868007 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m20:58:14.869364 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:14.876304 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m20:58:14.877130 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m20:58:14.878135 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:14.880785 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m20:58:14.881635 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m20:58:14.882351 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m20:58:14.885742 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m20:58:14.888526 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m20:58:14.889487 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m20:58:14.889965 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m20:58:14.892333 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:58:14.893927 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: Close
[0m20:58:14.894792 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x756733528230>]}
[0m20:58:14.896194 [info ] [Thread-1 (]: 5 of 22 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.07s]
[0m20:58:14.897694 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m20:58:14.898263 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m20:58:14.899003 [info ] [Thread-1 (]: 6 of 22 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m20:58:14.899691 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m20:58:14.900501 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m20:58:14.903786 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m20:58:14.904679 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m20:58:14.910288 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.inventory"
[0m20:58:14.911725 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m20:58:14.912977 [debug] [Thread-1 (]: On model.data_warehouse.inventory: BEGIN
[0m20:58:14.913514 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:14.926154 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m20:58:14.926971 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m20:58:14.927450 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."inventory"
  );
  
[0m20:58:14.931710 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.004 seconds
[0m20:58:14.935953 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m20:58:14.936484 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m20:58:14.937660 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:14.942675 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m20:58:14.943182 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m20:58:14.943990 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:14.946387 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m20:58:14.946914 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m20:58:14.947345 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m20:58:14.950091 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:58:14.952606 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m20:58:14.953638 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m20:58:14.954500 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m20:58:14.957100 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:58:14.958793 [debug] [Thread-1 (]: On model.data_warehouse.inventory: Close
[0m20:58:14.959648 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x756734017f80>]}
[0m20:58:14.961033 [info ] [Thread-1 (]: 6 of 22 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.06s]
[0m20:58:14.962569 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m20:58:14.963144 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m20:58:14.963913 [info ] [Thread-1 (]: 7 of 22 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m20:58:14.964659 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m20:58:14.965274 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m20:58:14.969489 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m20:58:14.970510 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m20:58:14.977427 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_first_dbt_model"
[0m20:58:14.978630 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m20:58:14.979523 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: BEGIN
[0m20:58:14.980045 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:14.992861 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m20:58:14.993384 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m20:58:14.993932 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */

  
    

  create  table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m20:58:14.995724 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.001 seconds
[0m20:58:14.999011 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m20:58:14.999530 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m20:58:15.000412 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:15.003971 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m20:58:15.005929 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m20:58:15.007764 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:58:15.010153 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m20:58:15.010661 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m20:58:15.011097 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m20:58:15.012712 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m20:58:15.015206 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m20:58:15.016122 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m20:58:15.016597 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
drop table if exists "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m20:58:15.019292 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:58:15.021121 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: Close
[0m20:58:15.021923 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75673352d670>]}
[0m20:58:15.022728 [info ] [Thread-1 (]: 7 of 22 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.06s]
[0m20:58:15.023655 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m20:58:15.024266 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m20:58:15.025086 [info ] [Thread-1 (]: 8 of 22 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m20:58:15.025839 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m20:58:15.026621 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m20:58:15.029840 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m20:58:15.030677 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m20:58:15.034699 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.payment"
[0m20:58:15.035665 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m20:58:15.036170 [debug] [Thread-1 (]: On model.data_warehouse.payment: BEGIN
[0m20:58:15.036606 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:15.050044 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m20:58:15.050602 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m20:58:15.051215 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."payment"
  );
  
[0m20:58:15.063332 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.012 seconds
[0m20:58:15.066705 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m20:58:15.067262 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m20:58:15.068411 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:58:15.074817 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m20:58:15.075444 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m20:58:15.076485 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:15.079416 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m20:58:15.080168 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m20:58:15.080957 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m20:58:15.086119 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m20:58:15.089995 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m20:58:15.090991 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m20:58:15.091454 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m20:58:15.094058 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:58:15.095744 [debug] [Thread-1 (]: On model.data_warehouse.payment: Close
[0m20:58:15.096490 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7567335d49e0>]}
[0m20:58:15.097303 [info ] [Thread-1 (]: 8 of 22 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.07s]
[0m20:58:15.098228 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m20:58:15.098858 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m20:58:15.099690 [info ] [Thread-1 (]: 9 of 22 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m20:58:15.100352 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m20:58:15.100904 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m20:58:15.104376 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m20:58:15.105330 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m20:58:15.111988 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.rental"
[0m20:58:15.112768 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m20:58:15.113375 [debug] [Thread-1 (]: On model.data_warehouse.rental: BEGIN
[0m20:58:15.113894 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:15.126740 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m20:58:15.127425 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m20:58:15.128375 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."rental"
  );
  
[0m20:58:15.141028 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.012 seconds
[0m20:58:15.144270 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m20:58:15.144827 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m20:58:15.145773 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:15.148862 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m20:58:15.149401 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m20:58:15.150293 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:15.152672 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m20:58:15.153212 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m20:58:15.153854 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m20:58:15.160229 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m20:58:15.163032 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m20:58:15.164038 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m20:58:15.164593 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m20:58:15.166827 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:58:15.168973 [debug] [Thread-1 (]: On model.data_warehouse.rental: Close
[0m20:58:15.169868 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75673345bd70>]}
[0m20:58:15.170951 [info ] [Thread-1 (]: 9 of 22 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.07s]
[0m20:58:15.172273 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m20:58:15.172980 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m20:58:15.173948 [info ] [Thread-1 (]: 10 of 22 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m20:58:15.174733 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m20:58:15.175511 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m20:58:15.179314 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m20:58:15.180675 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m20:58:15.188783 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.staff"
[0m20:58:15.190600 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m20:58:15.192013 [debug] [Thread-1 (]: On model.data_warehouse.staff: BEGIN
[0m20:58:15.193195 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:15.206105 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m20:58:15.207017 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m20:58:15.208037 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."staff"
  );
  
[0m20:58:15.213001 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.004 seconds
[0m20:58:15.216198 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m20:58:15.216710 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m20:58:15.217572 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:15.221105 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m20:58:15.221685 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m20:58:15.222567 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:15.224880 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m20:58:15.225463 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m20:58:15.225988 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m20:58:15.228162 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:58:15.231142 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m20:58:15.232299 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m20:58:15.232845 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m20:58:15.235465 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:58:15.237110 [debug] [Thread-1 (]: On model.data_warehouse.staff: Close
[0m20:58:15.237856 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x756733458500>]}
[0m20:58:15.238730 [info ] [Thread-1 (]: 10 of 22 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.06s]
[0m20:58:15.239772 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m20:58:15.240512 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m20:58:15.241216 [info ] [Thread-1 (]: 11 of 22 START sql table model dbt_dev_intermediate.dim_actor .................. [RUN]
[0m20:58:15.242020 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m20:58:15.242627 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m20:58:15.246339 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m20:58:15.247452 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m20:58:15.256044 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_actor"
[0m20:58:15.257697 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m20:58:15.258465 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: BEGIN
[0m20:58:15.259395 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:15.269964 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m20:58:15.271005 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m20:58:15.273451 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."actor"
  );
  
[0m20:58:15.276654 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m20:58:15.328683 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m20:58:15.329224 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_actor" rename to "dim_actor__dbt_backup"
[0m20:58:15.330141 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:15.333243 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m20:58:15.333764 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m20:58:15.334613 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:15.336726 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m20:58:15.337206 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m20:58:15.337663 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m20:58:15.339661 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m20:58:15.342142 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_backup"
[0m20:58:15.343072 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m20:58:15.343534 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_backup" cascade
[0m20:58:15.345803 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:58:15.347634 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: Close
[0m20:58:15.348383 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7567334a42c0>]}
[0m20:58:15.349178 [info ] [Thread-1 (]: 11 of 22 OK created sql table model dbt_dev_intermediate.dim_actor ............. [[32mSELECT 200[0m in 0.11s]
[0m20:58:15.350093 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m20:58:15.350695 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m20:58:15.351336 [info ] [Thread-1 (]: 12 of 22 START sql table model dbt_dev_intermediate.dim_address ................ [RUN]
[0m20:58:15.351996 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m20:58:15.352473 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m20:58:15.355682 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m20:58:15.356967 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m20:58:15.361692 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_address"
[0m20:58:15.362866 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m20:58:15.363657 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: BEGIN
[0m20:58:15.364268 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:15.377847 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m20:58:15.378574 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m20:58:15.379058 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."address"
  );
  
[0m20:58:15.381817 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m20:58:15.385789 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m20:58:15.386316 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_address" rename to "dim_address__dbt_backup"
[0m20:58:15.387664 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:15.393113 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m20:58:15.393646 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_tmp" rename to "dim_address"
[0m20:58:15.394449 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:15.396903 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m20:58:15.397407 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m20:58:15.397912 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m20:58:15.448121 [debug] [Thread-1 (]: SQL status: COMMIT in 0.050 seconds
[0m20:58:15.450817 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_backup"
[0m20:58:15.451770 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m20:58:15.452236 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_backup" cascade
[0m20:58:15.454470 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:58:15.456111 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: Close
[0m20:58:15.456983 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7567335db0b0>]}
[0m20:58:15.458386 [info ] [Thread-1 (]: 12 of 22 OK created sql table model dbt_dev_intermediate.dim_address ........... [[32mSELECT 603[0m in 0.10s]
[0m20:58:15.459788 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m20:58:15.460447 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m20:58:15.461129 [info ] [Thread-1 (]: 13 of 22 START sql table model dbt_dev_intermediate.dim_customer ............... [RUN]
[0m20:58:15.461808 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m20:58:15.462446 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m20:58:15.465943 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m20:58:15.466973 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m20:58:15.476543 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_customer"
[0m20:58:15.477456 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m20:58:15.478012 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: BEGIN
[0m20:58:15.478518 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:15.493052 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m20:58:15.493674 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m20:58:15.494265 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."customer"
  );
  
[0m20:58:15.496984 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.002 seconds
[0m20:58:15.500549 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m20:58:15.501145 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_customer" rename to "dim_customer__dbt_backup"
[0m20:58:15.502079 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:15.507000 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m20:58:15.507626 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m20:58:15.508605 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:15.510802 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m20:58:15.511327 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m20:58:15.511829 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m20:58:15.514125 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:58:15.517045 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_backup"
[0m20:58:15.518068 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m20:58:15.518615 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_backup" cascade
[0m20:58:15.521171 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:58:15.522989 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: Close
[0m20:58:15.523846 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7567355f0e00>]}
[0m20:58:15.525056 [info ] [Thread-1 (]: 13 of 22 OK created sql table model dbt_dev_intermediate.dim_customer .......... [[32mSELECT 599[0m in 0.06s]
[0m20:58:15.526407 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m20:58:15.527064 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m20:58:15.527746 [info ] [Thread-1 (]: 14 of 22 START sql table model dbt_dev_intermediate.dim_film ................... [RUN]
[0m20:58:15.528465 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m20:58:15.529082 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m20:58:15.532134 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m20:58:15.533298 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m20:58:15.543297 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film"
[0m20:58:15.544357 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m20:58:15.544867 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: BEGIN
[0m20:58:15.545294 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:15.557932 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m20:58:15.558575 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m20:58:15.559160 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."film"
  );
  
[0m20:58:15.565210 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.005 seconds
[0m20:58:15.568432 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m20:58:15.569008 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film" rename to "dim_film__dbt_backup"
[0m20:58:15.569925 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:15.573366 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m20:58:15.573975 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_tmp" rename to "dim_film"
[0m20:58:15.574867 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:15.577041 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m20:58:15.577598 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m20:58:15.578080 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m20:58:15.581917 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m20:58:15.585225 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_backup"
[0m20:58:15.586274 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m20:58:15.586846 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_backup" cascade
[0m20:58:15.589973 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m20:58:15.592356 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: Close
[0m20:58:15.593432 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75673414b9e0>]}
[0m20:58:15.594602 [info ] [Thread-1 (]: 14 of 22 OK created sql table model dbt_dev_intermediate.dim_film .............. [[32mSELECT 1000[0m in 0.07s]
[0m20:58:15.595771 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m20:58:15.596456 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m20:58:15.597260 [info ] [Thread-1 (]: 15 of 22 START sql table model dbt_dev_intermediate.dim_film_actor ............. [RUN]
[0m20:58:15.597909 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m20:58:15.598436 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m20:58:15.602645 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m20:58:15.603978 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m20:58:15.611025 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film_actor"
[0m20:58:15.611886 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m20:58:15.612440 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: BEGIN
[0m20:58:15.612884 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:15.624769 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m20:58:15.625299 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m20:58:15.625766 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m20:58:15.630689 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.004 seconds
[0m20:58:15.633835 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m20:58:15.634327 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor" rename to "dim_film_actor__dbt_backup"
[0m20:58:15.635208 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:15.638515 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m20:58:15.639054 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m20:58:15.639915 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:15.642031 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m20:58:15.642519 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m20:58:15.642968 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m20:58:15.645902 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:58:15.648528 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_backup"
[0m20:58:15.649456 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m20:58:15.649922 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_backup" cascade
[0m20:58:15.652122 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:58:15.653744 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: Close
[0m20:58:15.654618 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7567334a27b0>]}
[0m20:58:15.656018 [info ] [Thread-1 (]: 15 of 22 OK created sql table model dbt_dev_intermediate.dim_film_actor ........ [[32mSELECT 5462[0m in 0.06s]
[0m20:58:15.657409 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m20:58:15.658008 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m20:58:15.658702 [info ] [Thread-1 (]: 16 of 22 START sql table model dbt_dev_intermediate.dim_inventory .............. [RUN]
[0m20:58:15.659345 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.dim_inventory)
[0m20:58:15.660062 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m20:58:15.665458 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m20:58:15.666401 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m20:58:15.672311 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_inventory"
[0m20:58:15.673608 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m20:58:15.674360 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: BEGIN
[0m20:58:15.675079 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:15.686162 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m20:58:15.686891 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m20:58:15.688171 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."inventory"
  );
  
[0m20:58:15.694473 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.004 seconds
[0m20:58:15.699690 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m20:58:15.700480 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_inventory" rename to "dim_inventory__dbt_backup"
[0m20:58:15.701696 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:15.705780 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m20:58:15.706302 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m20:58:15.707149 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:15.709298 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m20:58:15.709808 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m20:58:15.710259 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m20:58:15.712861 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:58:15.715646 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_backup"
[0m20:58:15.716609 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m20:58:15.717094 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_backup" cascade
[0m20:58:15.719404 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:58:15.721082 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: Close
[0m20:58:15.721961 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x756733511070>]}
[0m20:58:15.723367 [info ] [Thread-1 (]: 16 of 22 OK created sql table model dbt_dev_intermediate.dim_inventory ......... [[32mSELECT 4581[0m in 0.06s]
[0m20:58:15.724783 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m20:58:15.725341 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m20:58:15.725938 [info ] [Thread-1 (]: 17 of 22 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m20:58:15.726648 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m20:58:15.727137 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m20:58:15.730057 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m20:58:15.731138 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m20:58:15.761431 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_second_dbt_model"
[0m20:58:15.762296 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m20:58:15.762902 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: BEGIN
[0m20:58:15.763338 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:15.774691 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m20:58:15.775285 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m20:58:15.775809 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */

  create view "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "data_warehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m20:58:15.777633 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.001 seconds
[0m20:58:15.781287 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m20:58:15.781914 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m20:58:15.782873 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:15.784768 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m20:58:15.785311 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m20:58:15.785817 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m20:58:15.787711 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m20:58:15.791227 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m20:58:15.795275 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m20:58:15.795885 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
drop view if exists "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m20:58:15.796672 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m20:58:15.799217 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: Close
[0m20:58:15.800318 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75673354f6b0>]}
[0m20:58:15.801546 [info ] [Thread-1 (]: 17 of 22 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.07s]
[0m20:58:15.802759 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m20:58:15.803442 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m20:58:15.804300 [info ] [Thread-1 (]: 18 of 22 START sql table model dbt_dev_intermediate.fact_payment ............... [RUN]
[0m20:58:15.805001 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now model.data_warehouse.fact_payment)
[0m20:58:15.805756 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m20:58:15.811010 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m20:58:15.812327 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m20:58:15.822743 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.fact_payment"
[0m20:58:15.824366 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m20:58:15.825605 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: BEGIN
[0m20:58:15.826709 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:15.842964 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m20:58:15.843704 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m20:58:15.844166 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."payment"
  );
  
[0m20:58:15.854795 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.010 seconds
[0m20:58:15.860064 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m20:58:15.860630 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediate"."fact_payment" rename to "fact_payment__dbt_backup"
[0m20:58:15.861567 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:15.864744 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m20:58:15.865257 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m20:58:15.866133 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:15.868306 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m20:58:15.868821 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m20:58:15.869264 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m20:58:15.873849 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m20:58:15.876813 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_backup"
[0m20:58:15.877780 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m20:58:15.878267 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_backup" cascade
[0m20:58:15.880716 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:58:15.882317 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: Close
[0m20:58:15.883059 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x756734e571a0>]}
[0m20:58:15.883860 [info ] [Thread-1 (]: 18 of 22 OK created sql table model dbt_dev_intermediate.fact_payment .......... [[32mSELECT 14596[0m in 0.08s]
[0m20:58:15.884800 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m20:58:15.885471 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m20:58:15.886486 [info ] [Thread-1 (]: 19 of 22 START sql table model dbt_dev_intermediate.dim_rental ................. [RUN]
[0m20:58:15.887243 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.dim_rental)
[0m20:58:15.887911 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m20:58:15.892893 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m20:58:15.894182 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m20:58:15.898936 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_rental"
[0m20:58:15.900027 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m20:58:15.900903 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: BEGIN
[0m20:58:15.901397 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:15.915437 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m20:58:15.916030 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m20:58:15.916829 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."rental"
  );
  
[0m20:58:15.930471 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.013 seconds
[0m20:58:15.933695 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m20:58:15.934194 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_rental" rename to "dim_rental__dbt_backup"
[0m20:58:15.934998 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:15.938534 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m20:58:15.939082 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m20:58:15.939864 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:15.942241 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m20:58:15.942761 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m20:58:15.943218 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m20:58:15.949594 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m20:58:15.952449 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_backup"
[0m20:58:15.953423 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m20:58:15.953906 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_backup" cascade
[0m20:58:15.956205 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:58:15.957828 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: Close
[0m20:58:15.958696 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7567339aa540>]}
[0m20:58:15.960102 [info ] [Thread-1 (]: 19 of 22 OK created sql table model dbt_dev_intermediate.dim_rental ............ [[32mSELECT 16044[0m in 0.07s]
[0m20:58:15.961662 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m20:58:15.962243 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m20:58:15.963003 [info ] [Thread-1 (]: 20 of 22 START sql table model dbt_dev_intermediate.dim_staff .................. [RUN]
[0m20:58:15.963717 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m20:58:15.964203 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m20:58:15.967591 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m20:58:15.968760 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m20:58:15.975906 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_staff"
[0m20:58:15.977078 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m20:58:15.977639 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: BEGIN
[0m20:58:15.978073 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:15.991791 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m20:58:15.992380 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m20:58:15.992905 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."staff"
  );
  
[0m20:58:15.997831 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.004 seconds
[0m20:58:16.001126 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m20:58:16.001868 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_staff" rename to "dim_staff__dbt_backup"
[0m20:58:16.002745 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:16.009884 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m20:58:16.010689 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m20:58:16.011592 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:16.014096 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m20:58:16.014628 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m20:58:16.015138 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m20:58:16.017989 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:58:16.023061 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_backup"
[0m20:58:16.024085 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m20:58:16.024619 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_backup" cascade
[0m20:58:16.027343 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:58:16.029011 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: Close
[0m20:58:16.029906 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75673346ef60>]}
[0m20:58:16.031290 [info ] [Thread-1 (]: 20 of 22 OK created sql table model dbt_dev_intermediate.dim_staff ............. [[32mSELECT 2[0m in 0.07s]
[0m20:58:16.032747 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m20:58:16.033299 [debug] [Thread-1 (]: Began running node model.data_warehouse.total_revenue
[0m20:58:16.033972 [info ] [Thread-1 (]: 21 of 22 START sql table model dbt_dev_mart.total_revenue ...................... [RUN]
[0m20:58:16.034607 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_staff, now model.data_warehouse.total_revenue)
[0m20:58:16.035145 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.total_revenue
[0m20:58:16.038370 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.total_revenue"
[0m20:58:16.039621 [debug] [Thread-1 (]: Began executing node model.data_warehouse.total_revenue
[0m20:58:16.044599 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.total_revenue"
[0m20:58:16.045900 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m20:58:16.047329 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: BEGIN
[0m20:58:16.048004 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:16.061226 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m20:58:16.061766 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m20:58:16.062289 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    SUM(amount) AS total_revenue,
    payment_date
FROM "data_warehouse"."dbt_dev_intermediate"."fact_payment"
GROUP BY payment_date
  );
  
[0m20:58:16.093612 [debug] [Thread-1 (]: SQL status: SELECT 14365 in 0.031 seconds
[0m20:58:16.096698 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m20:58:16.097209 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue" rename to "total_revenue__dbt_backup"
[0m20:58:16.098030 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:16.101701 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m20:58:16.102242 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp" rename to "total_revenue"
[0m20:58:16.103091 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:16.105412 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m20:58:16.105953 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m20:58:16.106416 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m20:58:16.110008 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m20:58:16.112880 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup"
[0m20:58:16.113970 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m20:58:16.114459 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup" cascade
[0m20:58:16.117034 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m20:58:16.118742 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: Close
[0m20:58:16.119517 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x756733457740>]}
[0m20:58:16.120351 [info ] [Thread-1 (]: 21 of 22 OK created sql table model dbt_dev_mart.total_revenue ................. [[32mSELECT 14365[0m in 0.09s]
[0m20:58:16.121277 [debug] [Thread-1 (]: Finished running node model.data_warehouse.total_revenue
[0m20:58:16.121902 [debug] [Thread-1 (]: Began running node model.data_warehouse.best_selling
[0m20:58:16.122660 [info ] [Thread-1 (]: 22 of 22 START sql table model dbt_dev_mart.best_selling ....................... [RUN]
[0m20:58:16.123308 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.total_revenue, now model.data_warehouse.best_selling)
[0m20:58:16.123815 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.best_selling
[0m20:58:16.128323 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.best_selling"
[0m20:58:16.129623 [debug] [Thread-1 (]: Began executing node model.data_warehouse.best_selling
[0m20:58:16.135194 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.best_selling"
[0m20:58:16.136078 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling"
[0m20:58:16.136899 [debug] [Thread-1 (]: On model.data_warehouse.best_selling: BEGIN
[0m20:58:16.139128 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:58:16.151078 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m20:58:16.151638 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling"
[0m20:58:16.152109 [debug] [Thread-1 (]: On model.data_warehouse.best_selling: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."best_selling__dbt_tmp"
  
  
    as
  
  (
    

SELECT df.title, COUNT(fp.payment_id) AS total_sales
FROM "data_warehouse"."dbt_dev_intermediate"."dim_film" df
JOIN "data_warehouse"."dbt_dev_intermediate"."dim_inventory" di ON df.film_id = di.film_id
JOIN "data_warehouse"."dbt_dev_intermediate"."dim_rental" dr ON dr.inventory_id = di.inventory_id
JOIN "data_warehouse"."dbt_dev_intermediate"."fact_payment" fp ON fp.rental_id = dr.rental_id
GROUP BY df.title
ORDER BY total_sales DESC
  );
  
[0m20:58:16.552040 [debug] [Thread-1 (]: SQL status: SELECT 958 in 0.399 seconds
[0m20:58:16.555276 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling"
[0m20:58:16.555833 [debug] [Thread-1 (]: On model.data_warehouse.best_selling: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling"} */
alter table "data_warehouse"."dbt_dev_mart"."best_selling__dbt_tmp" rename to "best_selling"
[0m20:58:16.556726 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:58:16.558687 [debug] [Thread-1 (]: On model.data_warehouse.best_selling: COMMIT
[0m20:58:16.559220 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling"
[0m20:58:16.559705 [debug] [Thread-1 (]: On model.data_warehouse.best_selling: COMMIT
[0m20:58:16.562153 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:58:16.564793 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."best_selling__dbt_backup"
[0m20:58:16.565791 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling"
[0m20:58:16.566300 [debug] [Thread-1 (]: On model.data_warehouse.best_selling: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."best_selling__dbt_backup" cascade
[0m20:58:16.567108 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m20:58:16.568688 [debug] [Thread-1 (]: On model.data_warehouse.best_selling: Close
[0m20:58:16.569432 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a70f6ac-7910-4248-8e83-c958734d8c80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7567335b2a80>]}
[0m20:58:16.570538 [info ] [Thread-1 (]: 22 of 22 OK created sql table model dbt_dev_mart.best_selling .................. [[32mSELECT 958[0m in 0.45s]
[0m20:58:16.571685 [debug] [Thread-1 (]: Finished running node model.data_warehouse.best_selling
[0m20:58:16.573658 [debug] [MainThread]: Using postgres connection "master"
[0m20:58:16.574685 [debug] [MainThread]: On master: BEGIN
[0m20:58:16.575547 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:58:16.587267 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m20:58:16.588120 [debug] [MainThread]: On master: COMMIT
[0m20:58:16.588870 [debug] [MainThread]: Using postgres connection "master"
[0m20:58:16.589630 [debug] [MainThread]: On master: COMMIT
[0m20:58:16.590647 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:58:16.591404 [debug] [MainThread]: On master: Close
[0m20:58:16.592811 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:58:16.593514 [debug] [MainThread]: Connection 'model.data_warehouse.best_selling' was properly closed.
[0m20:58:16.594180 [info ] [MainThread]: 
[0m20:58:16.594851 [info ] [MainThread]: Finished running 21 table models, 1 view model in 0 hours 0 minutes and 2.38 seconds (2.38s).
[0m20:58:16.599062 [debug] [MainThread]: Command end result
[0m20:58:16.647745 [info ] [MainThread]: 
[0m20:58:16.648392 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:58:16.648938 [info ] [MainThread]: 
[0m20:58:16.649487 [info ] [MainThread]: Done. PASS=22 WARN=0 ERROR=0 SKIP=0 TOTAL=22
[0m20:58:16.650531 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 3.3317726, "process_user_time": 3.764577, "process_kernel_time": 0.154736, "process_mem_max_rss": "111040", "process_out_blocks": "3392", "process_in_blocks": "0"}
[0m20:58:16.651225 [debug] [MainThread]: Command `dbt run` succeeded at 20:58:16.651104 after 3.33 seconds
[0m20:58:16.651945 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x756735dfe840>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x75673353eb70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x756738d978f0>]}
[0m20:58:17.986717 [debug] [MainThread]: Flushing usage events
[0m21:14:28.315720 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403dcc715b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403dbd88fe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403da4e75c0>]}


============================== 21:14:28.318811 | c8212198-31c3-4eb8-8a78-45ee35949a2c ==============================
[0m21:14:28.318811 [info ] [MainThread]: Running with dbt=1.8.5
[0m21:14:28.319684 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse', 'log_path': '/home/fikri/Documents/ftde-digitalskola/project 2/data_warehouse/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:14:28.523901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d99e6d20>]}
[0m21:14:28.588256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d9fd3c20>]}
[0m21:14:28.589180 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m21:14:28.599592 [debug] [MainThread]: checksum: 643640a45b16e0d012867be4ac17daaa0c3ce97300faec3ce9a6de300b5e1c09, vars: {}, profile: , target: , version: 1.8.5
[0m21:14:28.739060 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m21:14:28.739804 [debug] [MainThread]: Partial parsing: updated file: data_warehouse://models/mart/best_selling.sql
[0m21:14:28.740319 [debug] [MainThread]: Partial parsing: updated file: data_warehouse://models/mart/most_actor.sql
[0m21:14:29.031481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d9392fc0>]}
[0m21:14:29.156675 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d9390dd0>]}
[0m21:14:29.157290 [info ] [MainThread]: Found 23 models, 4 data tests, 9 sources, 417 macros
[0m21:14:29.157892 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d8d6d820>]}
[0m21:14:29.161254 [info ] [MainThread]: 
[0m21:14:29.162042 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:14:29.168516 [debug] [ThreadPool]: Acquiring new postgres connection 'list_data_warehouse'
[0m21:14:29.213407 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m21:14:29.213967 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:14:29.214633 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:14:29.227357 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.013 seconds
[0m21:14:29.228902 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m21:14:29.231951 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m21:14:29.232494 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:14:29.232918 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:14:29.244932 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.012 seconds
[0m21:14:29.246860 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m21:14:29.250607 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m21:14:29.251242 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:14:29.251832 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:14:29.263225 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.011 seconds
[0m21:14:29.264726 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m21:14:29.267012 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse"
[0m21:14:29.267624 [debug] [ThreadPool]: On list_data_warehouse: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m21:14:29.268047 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:14:29.279289 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.011 seconds
[0m21:14:29.280875 [debug] [ThreadPool]: On list_data_warehouse: Close
[0m21:14:29.285351 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse, now list_data_warehouse_dbt_dev)
[0m21:14:29.293086 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m21:14:29.293569 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: BEGIN
[0m21:14:29.293942 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:14:29.304665 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m21:14:29.305164 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev"
[0m21:14:29.305648 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev'
  
[0m21:14:29.308957 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m21:14:29.310499 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: ROLLBACK
[0m21:14:29.311183 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev: Close
[0m21:14:29.311977 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev, now list_data_warehouse_dbt_dev_intermediate)
[0m21:14:29.314791 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediate"
[0m21:14:29.315277 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: BEGIN
[0m21:14:29.315811 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:14:29.326640 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m21:14:29.327148 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_intermediate"
[0m21:14:29.327635 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_intermediate"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_intermediate'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_intermediate'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_intermediate'
  
[0m21:14:29.330877 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m21:14:29.332559 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: ROLLBACK
[0m21:14:29.333248 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_intermediate: Close
[0m21:14:29.334018 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_intermediate, now list_data_warehouse_dbt_dev_mart)
[0m21:14:29.337645 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m21:14:29.338108 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: BEGIN
[0m21:14:29.338513 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:14:29.349366 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m21:14:29.349898 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_mart"
[0m21:14:29.350375 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_mart"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_mart'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_mart'
  
[0m21:14:29.353625 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m21:14:29.355130 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: ROLLBACK
[0m21:14:29.355796 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_mart: Close
[0m21:14:29.356617 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_mart, now list_data_warehouse_dbt_dev_raw)
[0m21:14:29.359264 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m21:14:29.359752 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: BEGIN
[0m21:14:29.360320 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:14:29.371088 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m21:14:29.371607 [debug] [ThreadPool]: Using postgres connection "list_data_warehouse_dbt_dev_raw"
[0m21:14:29.372086 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "list_data_warehouse_dbt_dev_raw"} */
select
      'data_warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dbt_dev_raw'
    union all
    select
      'data_warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'dbt_dev_raw'
  
[0m21:14:29.375306 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m21:14:29.376921 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: ROLLBACK
[0m21:14:29.377566 [debug] [ThreadPool]: On list_data_warehouse_dbt_dev_raw: Close
[0m21:14:29.384868 [debug] [MainThread]: Using postgres connection "master"
[0m21:14:29.385356 [debug] [MainThread]: On master: BEGIN
[0m21:14:29.386048 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:14:29.396802 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m21:14:29.397313 [debug] [MainThread]: Using postgres connection "master"
[0m21:14:29.397996 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:14:29.417028 [debug] [MainThread]: SQL status: SELECT 38 in 0.018 seconds
[0m21:14:29.419521 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d818ba40>]}
[0m21:14:29.420082 [debug] [MainThread]: On master: ROLLBACK
[0m21:14:29.420774 [debug] [MainThread]: Using postgres connection "master"
[0m21:14:29.421231 [debug] [MainThread]: On master: BEGIN
[0m21:14:29.422016 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m21:14:29.422500 [debug] [MainThread]: On master: COMMIT
[0m21:14:29.422962 [debug] [MainThread]: Using postgres connection "master"
[0m21:14:29.423377 [debug] [MainThread]: On master: COMMIT
[0m21:14:29.424075 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:14:29.424536 [debug] [MainThread]: On master: Close
[0m21:14:29.425230 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:14:29.425862 [info ] [MainThread]: 
[0m21:14:29.428682 [debug] [Thread-1 (]: Began running node model.data_warehouse.actor
[0m21:14:29.429468 [info ] [Thread-1 (]: 1 of 23 START sql table model dbt_dev_raw.actor ................................ [RUN]
[0m21:14:29.430167 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_data_warehouse_dbt_dev_raw, now model.data_warehouse.actor)
[0m21:14:29.430665 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.actor
[0m21:14:29.443963 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.actor"
[0m21:14:29.444730 [debug] [Thread-1 (]: Began executing node model.data_warehouse.actor
[0m21:14:29.496693 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.actor"
[0m21:14:29.497735 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m21:14:29.498301 [debug] [Thread-1 (]: On model.data_warehouse.actor: BEGIN
[0m21:14:29.498803 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:14:29.509784 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m21:14:29.510379 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m21:14:29.510897 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."actor"
  );
  
[0m21:14:29.513201 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m21:14:29.520034 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m21:14:29.520617 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor" rename to "actor__dbt_backup"
[0m21:14:29.521519 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:29.524709 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m21:14:29.525261 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
alter table "data_warehouse"."dbt_dev_raw"."actor__dbt_tmp" rename to "actor"
[0m21:14:29.526142 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:29.549018 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m21:14:29.549633 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m21:14:29.550125 [debug] [Thread-1 (]: On model.data_warehouse.actor: COMMIT
[0m21:14:29.552142 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m21:14:29.560349 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."actor__dbt_backup"
[0m21:14:29.566654 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.actor"
[0m21:14:29.567268 [debug] [Thread-1 (]: On model.data_warehouse.actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."actor__dbt_backup" cascade
[0m21:14:29.569899 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m21:14:29.573209 [debug] [Thread-1 (]: On model.data_warehouse.actor: Close
[0m21:14:29.575076 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d7f16810>]}
[0m21:14:29.575940 [info ] [Thread-1 (]: 1 of 23 OK created sql table model dbt_dev_raw.actor ........................... [[32mSELECT 200[0m in 0.14s]
[0m21:14:29.576931 [debug] [Thread-1 (]: Finished running node model.data_warehouse.actor
[0m21:14:29.577604 [debug] [Thread-1 (]: Began running node model.data_warehouse.address
[0m21:14:29.578208 [info ] [Thread-1 (]: 2 of 23 START sql table model dbt_dev_raw.address .............................. [RUN]
[0m21:14:29.579040 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.actor, now model.data_warehouse.address)
[0m21:14:29.579602 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.address
[0m21:14:29.583547 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.address"
[0m21:14:29.584603 [debug] [Thread-1 (]: Began executing node model.data_warehouse.address
[0m21:14:29.590895 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.address"
[0m21:14:29.591801 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m21:14:29.592335 [debug] [Thread-1 (]: On model.data_warehouse.address: BEGIN
[0m21:14:29.593373 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:14:29.607365 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m21:14:29.608069 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m21:14:29.608993 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."address"
  );
  
[0m21:14:29.611809 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m21:14:29.616961 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m21:14:29.617867 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address" rename to "address__dbt_backup"
[0m21:14:29.620482 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:14:29.625536 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m21:14:29.626130 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
alter table "data_warehouse"."dbt_dev_raw"."address__dbt_tmp" rename to "address"
[0m21:14:29.626970 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:29.629119 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m21:14:29.629635 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m21:14:29.630068 [debug] [Thread-1 (]: On model.data_warehouse.address: COMMIT
[0m21:14:29.632185 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m21:14:29.635450 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."address__dbt_backup"
[0m21:14:29.636504 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.address"
[0m21:14:29.637040 [debug] [Thread-1 (]: On model.data_warehouse.address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.address"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."address__dbt_backup" cascade
[0m21:14:29.639408 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m21:14:29.641056 [debug] [Thread-1 (]: On model.data_warehouse.address: Close
[0m21:14:29.641840 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d80fb2f0>]}
[0m21:14:29.642709 [info ] [Thread-1 (]: 2 of 23 OK created sql table model dbt_dev_raw.address ......................... [[32mSELECT 603[0m in 0.06s]
[0m21:14:29.643598 [debug] [Thread-1 (]: Finished running node model.data_warehouse.address
[0m21:14:29.644211 [debug] [Thread-1 (]: Began running node model.data_warehouse.customer
[0m21:14:29.644824 [info ] [Thread-1 (]: 3 of 23 START sql table model dbt_dev_raw.customer ............................. [RUN]
[0m21:14:29.645657 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.address, now model.data_warehouse.customer)
[0m21:14:29.646175 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.customer
[0m21:14:29.649642 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.customer"
[0m21:14:29.650506 [debug] [Thread-1 (]: Began executing node model.data_warehouse.customer
[0m21:14:29.654985 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.customer"
[0m21:14:29.655957 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m21:14:29.656567 [debug] [Thread-1 (]: On model.data_warehouse.customer: BEGIN
[0m21:14:29.657063 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:14:29.671405 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m21:14:29.672410 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m21:14:29.673496 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."customer"
  );
  
[0m21:14:29.676679 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.002 seconds
[0m21:14:29.680568 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m21:14:29.681159 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer" rename to "customer__dbt_backup"
[0m21:14:29.682024 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:29.687088 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m21:14:29.688037 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
alter table "data_warehouse"."dbt_dev_raw"."customer__dbt_tmp" rename to "customer"
[0m21:14:29.689154 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:29.691334 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m21:14:29.691830 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m21:14:29.692265 [debug] [Thread-1 (]: On model.data_warehouse.customer: COMMIT
[0m21:14:29.694474 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m21:14:29.697016 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."customer__dbt_backup"
[0m21:14:29.697976 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.customer"
[0m21:14:29.698443 [debug] [Thread-1 (]: On model.data_warehouse.customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.customer"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."customer__dbt_backup" cascade
[0m21:14:29.701035 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m21:14:29.702798 [debug] [Thread-1 (]: On model.data_warehouse.customer: Close
[0m21:14:29.703600 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d8c76b70>]}
[0m21:14:29.704411 [info ] [Thread-1 (]: 3 of 23 OK created sql table model dbt_dev_raw.customer ........................ [[32mSELECT 599[0m in 0.06s]
[0m21:14:29.705284 [debug] [Thread-1 (]: Finished running node model.data_warehouse.customer
[0m21:14:29.705903 [debug] [Thread-1 (]: Began running node model.data_warehouse.film
[0m21:14:29.706589 [info ] [Thread-1 (]: 4 of 23 START sql table model dbt_dev_raw.film ................................. [RUN]
[0m21:14:29.707444 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.customer, now model.data_warehouse.film)
[0m21:14:29.708034 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film
[0m21:14:29.713314 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film"
[0m21:14:29.714599 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film
[0m21:14:29.723687 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film"
[0m21:14:29.724872 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m21:14:29.725844 [debug] [Thread-1 (]: On model.data_warehouse.film: BEGIN
[0m21:14:29.726777 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:14:29.742812 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m21:14:29.743669 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m21:14:29.744501 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."film"
  );
  
[0m21:14:29.751245 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.006 seconds
[0m21:14:29.756948 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m21:14:29.757490 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film" rename to "film__dbt_backup"
[0m21:14:29.758372 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:29.763051 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m21:14:29.763819 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
alter table "data_warehouse"."dbt_dev_raw"."film__dbt_tmp" rename to "film"
[0m21:14:29.764924 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:29.767130 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m21:14:29.767677 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m21:14:29.768142 [debug] [Thread-1 (]: On model.data_warehouse.film: COMMIT
[0m21:14:29.771154 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m21:14:29.773800 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film__dbt_backup"
[0m21:14:29.774860 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film"
[0m21:14:29.775326 [debug] [Thread-1 (]: On model.data_warehouse.film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film__dbt_backup" cascade
[0m21:14:29.778298 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m21:14:29.779882 [debug] [Thread-1 (]: On model.data_warehouse.film: Close
[0m21:14:29.780777 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d7f75880>]}
[0m21:14:29.782176 [info ] [Thread-1 (]: 4 of 23 OK created sql table model dbt_dev_raw.film ............................ [[32mSELECT 1000[0m in 0.07s]
[0m21:14:29.783680 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film
[0m21:14:29.784252 [debug] [Thread-1 (]: Began running node model.data_warehouse.film_actor
[0m21:14:29.784941 [info ] [Thread-1 (]: 5 of 23 START sql table model dbt_dev_raw.film_actor ........................... [RUN]
[0m21:14:29.785777 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film, now model.data_warehouse.film_actor)
[0m21:14:29.786264 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.film_actor
[0m21:14:29.789875 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.film_actor"
[0m21:14:29.791167 [debug] [Thread-1 (]: Began executing node model.data_warehouse.film_actor
[0m21:14:29.799036 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.film_actor"
[0m21:14:29.799942 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m21:14:29.800422 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: BEGIN
[0m21:14:29.800902 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:14:29.816672 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m21:14:29.817764 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m21:14:29.819052 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."film_actor"
  );
  
[0m21:14:29.828805 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.008 seconds
[0m21:14:29.832393 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m21:14:29.833145 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor" rename to "film_actor__dbt_backup"
[0m21:14:29.834251 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:29.837833 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m21:14:29.838683 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
alter table "data_warehouse"."dbt_dev_raw"."film_actor__dbt_tmp" rename to "film_actor"
[0m21:14:29.839684 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:29.842471 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m21:14:29.843051 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m21:14:29.843645 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: COMMIT
[0m21:14:29.846575 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m21:14:29.849092 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup"
[0m21:14:29.850083 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.film_actor"
[0m21:14:29.850618 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."film_actor__dbt_backup" cascade
[0m21:14:29.853086 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m21:14:29.854738 [debug] [Thread-1 (]: On model.data_warehouse.film_actor: Close
[0m21:14:29.855483 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403da483950>]}
[0m21:14:29.856319 [info ] [Thread-1 (]: 5 of 23 OK created sql table model dbt_dev_raw.film_actor ...................... [[32mSELECT 5462[0m in 0.07s]
[0m21:14:29.857231 [debug] [Thread-1 (]: Finished running node model.data_warehouse.film_actor
[0m21:14:29.857861 [debug] [Thread-1 (]: Began running node model.data_warehouse.inventory
[0m21:14:29.858588 [info ] [Thread-1 (]: 6 of 23 START sql table model dbt_dev_raw.inventory ............................ [RUN]
[0m21:14:29.859437 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.film_actor, now model.data_warehouse.inventory)
[0m21:14:29.860045 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.inventory
[0m21:14:29.863766 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.inventory"
[0m21:14:29.864719 [debug] [Thread-1 (]: Began executing node model.data_warehouse.inventory
[0m21:14:29.871341 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.inventory"
[0m21:14:29.872431 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m21:14:29.873079 [debug] [Thread-1 (]: On model.data_warehouse.inventory: BEGIN
[0m21:14:29.873592 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:14:29.887602 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m21:14:29.888826 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m21:14:29.889824 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."inventory"
  );
  
[0m21:14:29.894452 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.004 seconds
[0m21:14:29.898820 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m21:14:29.899336 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory" rename to "inventory__dbt_backup"
[0m21:14:29.900213 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:29.905946 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m21:14:29.906463 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
alter table "data_warehouse"."dbt_dev_raw"."inventory__dbt_tmp" rename to "inventory"
[0m21:14:29.907296 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:29.909677 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m21:14:29.910169 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m21:14:29.910620 [debug] [Thread-1 (]: On model.data_warehouse.inventory: COMMIT
[0m21:14:29.913392 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m21:14:29.916111 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup"
[0m21:14:29.917044 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.inventory"
[0m21:14:29.917603 [debug] [Thread-1 (]: On model.data_warehouse.inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.inventory"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."inventory__dbt_backup" cascade
[0m21:14:29.920502 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m21:14:29.922328 [debug] [Thread-1 (]: On model.data_warehouse.inventory: Close
[0m21:14:29.923123 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d93becc0>]}
[0m21:14:29.923980 [info ] [Thread-1 (]: 6 of 23 OK created sql table model dbt_dev_raw.inventory ....................... [[32mSELECT 4581[0m in 0.06s]
[0m21:14:29.924962 [debug] [Thread-1 (]: Finished running node model.data_warehouse.inventory
[0m21:14:29.925705 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_first_dbt_model
[0m21:14:29.926892 [info ] [Thread-1 (]: 7 of 23 START sql table model dbt_dev.my_first_dbt_model ....................... [RUN]
[0m21:14:29.927845 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.inventory, now model.data_warehouse.my_first_dbt_model)
[0m21:14:29.928791 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_first_dbt_model
[0m21:14:29.933098 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_first_dbt_model"
[0m21:14:29.934337 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_first_dbt_model
[0m21:14:29.942460 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_first_dbt_model"
[0m21:14:29.943405 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m21:14:29.943983 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: BEGIN
[0m21:14:29.944499 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:14:29.956995 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m21:14:29.957602 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m21:14:29.958130 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */

  
    

  create  table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m21:14:29.960011 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.001 seconds
[0m21:14:29.963170 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m21:14:29.963774 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m21:14:29.964770 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:29.967797 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m21:14:29.968533 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m21:14:29.969445 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:29.971851 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m21:14:29.972359 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m21:14:29.972802 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: COMMIT
[0m21:14:29.974520 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m21:14:29.977001 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup"
[0m21:14:29.977929 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_first_dbt_model"
[0m21:14:29.978390 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_first_dbt_model"} */
drop table if exists "data_warehouse"."dbt_dev"."my_first_dbt_model__dbt_backup" cascade
[0m21:14:29.980948 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m21:14:29.982987 [debug] [Thread-1 (]: On model.data_warehouse.my_first_dbt_model: Close
[0m21:14:29.983764 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d8caf110>]}
[0m21:14:29.984651 [info ] [Thread-1 (]: 7 of 23 OK created sql table model dbt_dev.my_first_dbt_model .................. [[32mSELECT 2[0m in 0.06s]
[0m21:14:29.985704 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_first_dbt_model
[0m21:14:29.986430 [debug] [Thread-1 (]: Began running node model.data_warehouse.payment
[0m21:14:29.987367 [info ] [Thread-1 (]: 8 of 23 START sql table model dbt_dev_raw.payment .............................. [RUN]
[0m21:14:29.988236 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_first_dbt_model, now model.data_warehouse.payment)
[0m21:14:29.988878 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.payment
[0m21:14:29.993348 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.payment"
[0m21:14:29.994570 [debug] [Thread-1 (]: Began executing node model.data_warehouse.payment
[0m21:14:29.999991 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.payment"
[0m21:14:30.000779 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m21:14:30.002810 [debug] [Thread-1 (]: On model.data_warehouse.payment: BEGIN
[0m21:14:30.004411 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:14:30.016167 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m21:14:30.016728 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m21:14:30.017192 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."payment"
  );
  
[0m21:14:30.031288 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.013 seconds
[0m21:14:30.036447 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m21:14:30.037388 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment" rename to "payment__dbt_backup"
[0m21:14:30.038687 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:30.043298 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m21:14:30.043898 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
alter table "data_warehouse"."dbt_dev_raw"."payment__dbt_tmp" rename to "payment"
[0m21:14:30.044794 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:30.047622 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m21:14:30.048132 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m21:14:30.048594 [debug] [Thread-1 (]: On model.data_warehouse.payment: COMMIT
[0m21:14:30.053436 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m21:14:30.057085 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."payment__dbt_backup"
[0m21:14:30.058061 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.payment"
[0m21:14:30.058565 [debug] [Thread-1 (]: On model.data_warehouse.payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.payment"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."payment__dbt_backup" cascade
[0m21:14:30.061625 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m21:14:30.063230 [debug] [Thread-1 (]: On model.data_warehouse.payment: Close
[0m21:14:30.063972 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d7f67860>]}
[0m21:14:30.064760 [info ] [Thread-1 (]: 8 of 23 OK created sql table model dbt_dev_raw.payment ......................... [[32mSELECT 14596[0m in 0.08s]
[0m21:14:30.065697 [debug] [Thread-1 (]: Finished running node model.data_warehouse.payment
[0m21:14:30.066330 [debug] [Thread-1 (]: Began running node model.data_warehouse.rental
[0m21:14:30.067311 [info ] [Thread-1 (]: 9 of 23 START sql table model dbt_dev_raw.rental ............................... [RUN]
[0m21:14:30.068114 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.payment, now model.data_warehouse.rental)
[0m21:14:30.068879 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.rental
[0m21:14:30.072784 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.rental"
[0m21:14:30.073880 [debug] [Thread-1 (]: Began executing node model.data_warehouse.rental
[0m21:14:30.080086 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.rental"
[0m21:14:30.081820 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m21:14:30.082653 [debug] [Thread-1 (]: On model.data_warehouse.rental: BEGIN
[0m21:14:30.083246 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:14:30.097048 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m21:14:30.097599 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m21:14:30.098129 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."rental"
  );
  
[0m21:14:30.110340 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.012 seconds
[0m21:14:30.114053 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m21:14:30.114578 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental" rename to "rental__dbt_backup"
[0m21:14:30.116050 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:30.120145 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m21:14:30.120835 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
alter table "data_warehouse"."dbt_dev_raw"."rental__dbt_tmp" rename to "rental"
[0m21:14:30.122118 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:30.125067 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m21:14:30.125561 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m21:14:30.126001 [debug] [Thread-1 (]: On model.data_warehouse.rental: COMMIT
[0m21:14:30.127656 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m21:14:30.130166 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."rental__dbt_backup"
[0m21:14:30.131105 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.rental"
[0m21:14:30.131576 [debug] [Thread-1 (]: On model.data_warehouse.rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.rental"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."rental__dbt_backup" cascade
[0m21:14:30.134226 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m21:14:30.136395 [debug] [Thread-1 (]: On model.data_warehouse.rental: Close
[0m21:14:30.137330 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d7f6f260>]}
[0m21:14:30.138774 [info ] [Thread-1 (]: 9 of 23 OK created sql table model dbt_dev_raw.rental .......................... [[32mSELECT 16044[0m in 0.07s]
[0m21:14:30.140270 [debug] [Thread-1 (]: Finished running node model.data_warehouse.rental
[0m21:14:30.140884 [debug] [Thread-1 (]: Began running node model.data_warehouse.staff
[0m21:14:30.141681 [info ] [Thread-1 (]: 10 of 23 START sql table model dbt_dev_raw.staff ............................... [RUN]
[0m21:14:30.142701 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.rental, now model.data_warehouse.staff)
[0m21:14:30.143494 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.staff
[0m21:14:30.148227 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.staff"
[0m21:14:30.149329 [debug] [Thread-1 (]: Began executing node model.data_warehouse.staff
[0m21:14:30.159103 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.staff"
[0m21:14:30.160164 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m21:14:30.160744 [debug] [Thread-1 (]: On model.data_warehouse.staff: BEGIN
[0m21:14:30.161491 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:14:30.174236 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m21:14:30.174962 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m21:14:30.175515 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."public"."staff"
  );
  
[0m21:14:30.180664 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.005 seconds
[0m21:14:30.184026 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m21:14:30.184864 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff" rename to "staff__dbt_backup"
[0m21:14:30.185941 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:30.189210 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m21:14:30.189771 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
alter table "data_warehouse"."dbt_dev_raw"."staff__dbt_tmp" rename to "staff"
[0m21:14:30.190650 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:30.192940 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m21:14:30.193514 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m21:14:30.194018 [debug] [Thread-1 (]: On model.data_warehouse.staff: COMMIT
[0m21:14:30.196028 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m21:14:30.198849 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_raw"."staff__dbt_backup"
[0m21:14:30.199939 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.staff"
[0m21:14:30.200491 [debug] [Thread-1 (]: On model.data_warehouse.staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.staff"} */
drop table if exists "data_warehouse"."dbt_dev_raw"."staff__dbt_backup" cascade
[0m21:14:30.202982 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m21:14:30.204652 [debug] [Thread-1 (]: On model.data_warehouse.staff: Close
[0m21:14:30.205392 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d7f551c0>]}
[0m21:14:30.206228 [info ] [Thread-1 (]: 10 of 23 OK created sql table model dbt_dev_raw.staff .......................... [[32mSELECT 2[0m in 0.06s]
[0m21:14:30.207088 [debug] [Thread-1 (]: Finished running node model.data_warehouse.staff
[0m21:14:30.207707 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_actor
[0m21:14:30.208496 [info ] [Thread-1 (]: 11 of 23 START sql table model dbt_dev_intermediate.dim_actor .................. [RUN]
[0m21:14:30.209197 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.staff, now model.data_warehouse.dim_actor)
[0m21:14:30.209858 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_actor
[0m21:14:30.213639 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_actor"
[0m21:14:30.214924 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_actor
[0m21:14:30.224341 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_actor"
[0m21:14:30.225229 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m21:14:30.225894 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: BEGIN
[0m21:14:30.226401 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:14:30.239365 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m21:14:30.239996 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m21:14:30.240644 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."actor"
  );
  
[0m21:14:30.243215 [debug] [Thread-1 (]: SQL status: SELECT 200 in 0.002 seconds
[0m21:14:30.294725 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m21:14:30.295315 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_actor" rename to "dim_actor__dbt_backup"
[0m21:14:30.296259 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:30.299490 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m21:14:30.300054 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_tmp" rename to "dim_actor"
[0m21:14:30.300953 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:30.303140 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m21:14:30.303678 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m21:14:30.304160 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: COMMIT
[0m21:14:30.306134 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m21:14:30.308723 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_backup"
[0m21:14:30.309705 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_actor"
[0m21:14:30.310210 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_actor__dbt_backup" cascade
[0m21:14:30.312296 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m21:14:30.313928 [debug] [Thread-1 (]: On model.data_warehouse.dim_actor: Close
[0m21:14:30.314758 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d7fa4620>]}
[0m21:14:30.315576 [info ] [Thread-1 (]: 11 of 23 OK created sql table model dbt_dev_intermediate.dim_actor ............. [[32mSELECT 200[0m in 0.11s]
[0m21:14:30.316430 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_actor
[0m21:14:30.317061 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_address
[0m21:14:30.317763 [info ] [Thread-1 (]: 12 of 23 START sql table model dbt_dev_intermediate.dim_address ................ [RUN]
[0m21:14:30.318423 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_actor, now model.data_warehouse.dim_address)
[0m21:14:30.319014 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_address
[0m21:14:30.322171 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_address"
[0m21:14:30.323289 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_address
[0m21:14:30.329722 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_address"
[0m21:14:30.330618 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m21:14:30.331258 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: BEGIN
[0m21:14:30.331879 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:14:30.345655 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m21:14:30.346305 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m21:14:30.347017 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."address"
  );
  
[0m21:14:30.350162 [debug] [Thread-1 (]: SQL status: SELECT 603 in 0.002 seconds
[0m21:14:30.356123 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m21:14:30.356728 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_address" rename to "dim_address__dbt_backup"
[0m21:14:30.357782 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:14:30.361116 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m21:14:30.361698 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_tmp" rename to "dim_address"
[0m21:14:30.362673 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:30.365251 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m21:14:30.365809 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m21:14:30.366296 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: COMMIT
[0m21:14:30.368344 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m21:14:30.372158 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_backup"
[0m21:14:30.373455 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_address"
[0m21:14:30.374009 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_address"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_address__dbt_backup" cascade
[0m21:14:30.376488 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m21:14:30.378185 [debug] [Thread-1 (]: On model.data_warehouse.dim_address: Close
[0m21:14:30.379060 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d8b14f20>]}
[0m21:14:30.380441 [info ] [Thread-1 (]: 12 of 23 OK created sql table model dbt_dev_intermediate.dim_address ........... [[32mSELECT 603[0m in 0.06s]
[0m21:14:30.381899 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_address
[0m21:14:30.382574 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_customer
[0m21:14:30.383220 [info ] [Thread-1 (]: 13 of 23 START sql table model dbt_dev_intermediate.dim_customer ............... [RUN]
[0m21:14:30.383866 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_address, now model.data_warehouse.dim_customer)
[0m21:14:30.384435 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_customer
[0m21:14:30.387973 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_customer"
[0m21:14:30.389062 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_customer
[0m21:14:30.394713 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_customer"
[0m21:14:30.395603 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m21:14:30.396168 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: BEGIN
[0m21:14:30.396689 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:14:30.410632 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m21:14:30.411277 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m21:14:30.411909 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."customer"
  );
  
[0m21:14:30.414358 [debug] [Thread-1 (]: SQL status: SELECT 599 in 0.002 seconds
[0m21:14:30.417625 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m21:14:30.418341 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_customer" rename to "dim_customer__dbt_backup"
[0m21:14:30.421023 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:30.425944 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m21:14:30.426583 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m21:14:30.427414 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:30.429771 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m21:14:30.430325 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m21:14:30.430838 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: COMMIT
[0m21:14:30.432804 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m21:14:30.435717 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_backup"
[0m21:14:30.436738 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_customer"
[0m21:14:30.437310 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_customer"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_customer__dbt_backup" cascade
[0m21:14:30.440372 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m21:14:30.442109 [debug] [Thread-1 (]: On model.data_warehouse.dim_customer: Close
[0m21:14:30.442860 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d8d6c0e0>]}
[0m21:14:30.443736 [info ] [Thread-1 (]: 13 of 23 OK created sql table model dbt_dev_intermediate.dim_customer .......... [[32mSELECT 599[0m in 0.06s]
[0m21:14:30.444636 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_customer
[0m21:14:30.445358 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film
[0m21:14:30.446051 [info ] [Thread-1 (]: 14 of 23 START sql table model dbt_dev_intermediate.dim_film ................... [RUN]
[0m21:14:30.446856 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_customer, now model.data_warehouse.dim_film)
[0m21:14:30.447720 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film
[0m21:14:30.451906 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film"
[0m21:14:30.453124 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film
[0m21:14:30.459979 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film"
[0m21:14:30.460780 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m21:14:30.461378 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: BEGIN
[0m21:14:30.461894 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:14:30.477847 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m21:14:30.478481 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m21:14:30.479037 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."film"
  );
  
[0m21:14:30.484873 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.005 seconds
[0m21:14:30.490172 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m21:14:30.490721 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film" rename to "dim_film__dbt_backup"
[0m21:14:30.491616 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:30.494708 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m21:14:30.495208 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_tmp" rename to "dim_film"
[0m21:14:30.495998 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:30.498214 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m21:14:30.498742 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m21:14:30.499194 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: COMMIT
[0m21:14:30.502096 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m21:14:30.504828 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_backup"
[0m21:14:30.505770 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film"
[0m21:14:30.506233 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_film__dbt_backup" cascade
[0m21:14:30.509546 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m21:14:30.511211 [debug] [Thread-1 (]: On model.data_warehouse.dim_film: Close
[0m21:14:30.511965 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d8025460>]}
[0m21:14:30.512768 [info ] [Thread-1 (]: 14 of 23 OK created sql table model dbt_dev_intermediate.dim_film .............. [[32mSELECT 1000[0m in 0.07s]
[0m21:14:30.513753 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film
[0m21:14:30.514505 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_film_actor
[0m21:14:30.515189 [info ] [Thread-1 (]: 15 of 23 START sql table model dbt_dev_intermediate.dim_film_actor ............. [RUN]
[0m21:14:30.515921 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film, now model.data_warehouse.dim_film_actor)
[0m21:14:30.516488 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_film_actor
[0m21:14:30.520976 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_film_actor"
[0m21:14:30.522191 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_film_actor
[0m21:14:30.527637 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_film_actor"
[0m21:14:30.528563 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m21:14:30.529206 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: BEGIN
[0m21:14:30.529850 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:14:30.543679 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m21:14:30.544257 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m21:14:30.544772 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."film_actor"
  );
  
[0m21:14:30.549837 [debug] [Thread-1 (]: SQL status: SELECT 5462 in 0.004 seconds
[0m21:14:30.557057 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m21:14:30.557926 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor" rename to "dim_film_actor__dbt_backup"
[0m21:14:30.558995 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:30.562297 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m21:14:30.562820 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_tmp" rename to "dim_film_actor"
[0m21:14:30.563718 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:30.566068 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m21:14:30.566635 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m21:14:30.567134 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: COMMIT
[0m21:14:30.569858 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m21:14:30.572426 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_backup"
[0m21:14:30.573367 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_film_actor"
[0m21:14:30.573850 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_film_actor"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_film_actor__dbt_backup" cascade
[0m21:14:30.576269 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m21:14:30.577902 [debug] [Thread-1 (]: On model.data_warehouse.dim_film_actor: Close
[0m21:14:30.578862 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d81980e0>]}
[0m21:14:30.580301 [info ] [Thread-1 (]: 15 of 23 OK created sql table model dbt_dev_intermediate.dim_film_actor ........ [[32mSELECT 5462[0m in 0.06s]
[0m21:14:30.581803 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_film_actor
[0m21:14:30.582358 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_inventory
[0m21:14:30.582942 [info ] [Thread-1 (]: 16 of 23 START sql table model dbt_dev_intermediate.dim_inventory .............. [RUN]
[0m21:14:30.583720 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_film_actor, now model.data_warehouse.dim_inventory)
[0m21:14:30.584220 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_inventory
[0m21:14:30.589909 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_inventory"
[0m21:14:30.591022 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_inventory
[0m21:14:30.596384 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_inventory"
[0m21:14:30.597161 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m21:14:30.597826 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: BEGIN
[0m21:14:30.598267 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:14:30.611119 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m21:14:30.611683 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m21:14:30.612167 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."inventory"
  );
  
[0m21:14:30.616612 [debug] [Thread-1 (]: SQL status: SELECT 4581 in 0.004 seconds
[0m21:14:30.622418 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m21:14:30.623026 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_inventory" rename to "dim_inventory__dbt_backup"
[0m21:14:30.623862 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:30.626916 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m21:14:30.627427 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_tmp" rename to "dim_inventory"
[0m21:14:30.628221 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:30.630405 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m21:14:30.630924 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m21:14:30.631648 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: COMMIT
[0m21:14:30.634119 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m21:14:30.636785 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_backup"
[0m21:14:30.638005 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_inventory"
[0m21:14:30.638574 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_inventory"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_inventory__dbt_backup" cascade
[0m21:14:30.640919 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m21:14:30.642525 [debug] [Thread-1 (]: On model.data_warehouse.dim_inventory: Close
[0m21:14:30.643403 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d7f0fe30>]}
[0m21:14:30.644812 [info ] [Thread-1 (]: 16 of 23 OK created sql table model dbt_dev_intermediate.dim_inventory ......... [[32mSELECT 4581[0m in 0.06s]
[0m21:14:30.646223 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_inventory
[0m21:14:30.646873 [debug] [Thread-1 (]: Began running node model.data_warehouse.my_second_dbt_model
[0m21:14:30.647579 [info ] [Thread-1 (]: 17 of 23 START sql view model dbt_dev.my_second_dbt_model ...................... [RUN]
[0m21:14:30.648392 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_inventory, now model.data_warehouse.my_second_dbt_model)
[0m21:14:30.648999 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.my_second_dbt_model
[0m21:14:30.652808 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.my_second_dbt_model"
[0m21:14:30.653773 [debug] [Thread-1 (]: Began executing node model.data_warehouse.my_second_dbt_model
[0m21:14:30.688235 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.my_second_dbt_model"
[0m21:14:30.689452 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m21:14:30.690312 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: BEGIN
[0m21:14:30.690909 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:14:30.701761 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m21:14:30.702644 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m21:14:30.703122 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */

  create view "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "data_warehouse"."dbt_dev"."my_first_dbt_model"
where id = 1
  );
[0m21:14:30.704962 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.001 seconds
[0m21:14:30.708151 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m21:14:30.708663 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
alter table "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m21:14:30.709489 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:30.711267 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m21:14:30.711758 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m21:14:30.712187 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: COMMIT
[0m21:14:30.714057 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m21:14:30.716477 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup"
[0m21:14:30.720077 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.my_second_dbt_model"
[0m21:14:30.720607 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.my_second_dbt_model"} */
drop view if exists "data_warehouse"."dbt_dev"."my_second_dbt_model__dbt_backup" cascade
[0m21:14:30.721342 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m21:14:30.723074 [debug] [Thread-1 (]: On model.data_warehouse.my_second_dbt_model: Close
[0m21:14:30.723861 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d93bf410>]}
[0m21:14:30.724640 [info ] [Thread-1 (]: 17 of 23 OK created sql view model dbt_dev.my_second_dbt_model ................. [[32mCREATE VIEW[0m in 0.08s]
[0m21:14:30.725538 [debug] [Thread-1 (]: Finished running node model.data_warehouse.my_second_dbt_model
[0m21:14:30.726199 [debug] [Thread-1 (]: Began running node model.data_warehouse.fact_payment
[0m21:14:30.726995 [info ] [Thread-1 (]: 18 of 23 START sql table model dbt_dev_intermediate.fact_payment ............... [RUN]
[0m21:14:30.727771 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.my_second_dbt_model, now model.data_warehouse.fact_payment)
[0m21:14:30.728605 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.fact_payment
[0m21:14:30.733065 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.fact_payment"
[0m21:14:30.734474 [debug] [Thread-1 (]: Began executing node model.data_warehouse.fact_payment
[0m21:14:30.741253 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.fact_payment"
[0m21:14:30.742102 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m21:14:30.742661 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: BEGIN
[0m21:14:30.743100 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:14:30.755208 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m21:14:30.756061 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m21:14:30.756652 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."payment"
  );
  
[0m21:14:30.768823 [debug] [Thread-1 (]: SQL status: SELECT 14596 in 0.011 seconds
[0m21:14:30.774206 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m21:14:30.774746 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediate"."fact_payment" rename to "fact_payment__dbt_backup"
[0m21:14:30.775646 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:30.779220 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m21:14:30.779742 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
alter table "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_tmp" rename to "fact_payment"
[0m21:14:30.780610 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:30.783901 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m21:14:30.784578 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m21:14:30.785151 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: COMMIT
[0m21:14:30.790095 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m21:14:30.792656 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_backup"
[0m21:14:30.793670 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.fact_payment"
[0m21:14:30.794193 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.fact_payment"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."fact_payment__dbt_backup" cascade
[0m21:14:30.797173 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m21:14:30.798837 [debug] [Thread-1 (]: On model.data_warehouse.fact_payment: Close
[0m21:14:30.799597 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d8d56f30>]}
[0m21:14:30.800418 [info ] [Thread-1 (]: 18 of 23 OK created sql table model dbt_dev_intermediate.fact_payment .......... [[32mSELECT 14596[0m in 0.07s]
[0m21:14:30.801351 [debug] [Thread-1 (]: Finished running node model.data_warehouse.fact_payment
[0m21:14:30.801979 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_rental
[0m21:14:30.802640 [info ] [Thread-1 (]: 19 of 23 START sql table model dbt_dev_intermediate.dim_rental ................. [RUN]
[0m21:14:30.803403 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.fact_payment, now model.data_warehouse.dim_rental)
[0m21:14:30.803945 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_rental
[0m21:14:30.807369 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_rental"
[0m21:14:30.808354 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_rental
[0m21:14:30.814965 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_rental"
[0m21:14:30.815888 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m21:14:30.816683 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: BEGIN
[0m21:14:30.817165 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:14:30.831581 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m21:14:30.832117 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m21:14:30.832609 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."rental"
  );
  
[0m21:14:30.845416 [debug] [Thread-1 (]: SQL status: SELECT 16044 in 0.012 seconds
[0m21:14:30.848673 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m21:14:30.849188 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_rental" rename to "dim_rental__dbt_backup"
[0m21:14:30.850491 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:30.854172 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m21:14:30.854708 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_tmp" rename to "dim_rental"
[0m21:14:30.855545 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:30.858318 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m21:14:30.859067 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m21:14:30.859712 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: COMMIT
[0m21:14:30.865711 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m21:14:30.868485 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_backup"
[0m21:14:30.869790 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_rental"
[0m21:14:30.870909 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_rental"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_rental__dbt_backup" cascade
[0m21:14:30.874068 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m21:14:30.875727 [debug] [Thread-1 (]: On model.data_warehouse.dim_rental: Close
[0m21:14:30.876624 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d8d25d00>]}
[0m21:14:30.878030 [info ] [Thread-1 (]: 19 of 23 OK created sql table model dbt_dev_intermediate.dim_rental ............ [[32mSELECT 16044[0m in 0.07s]
[0m21:14:30.879653 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_rental
[0m21:14:30.880325 [debug] [Thread-1 (]: Began running node model.data_warehouse.dim_staff
[0m21:14:30.881154 [info ] [Thread-1 (]: 20 of 23 START sql table model dbt_dev_intermediate.dim_staff .................. [RUN]
[0m21:14:30.881948 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_rental, now model.data_warehouse.dim_staff)
[0m21:14:30.882442 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.dim_staff
[0m21:14:30.887038 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.dim_staff"
[0m21:14:30.888029 [debug] [Thread-1 (]: Began executing node model.data_warehouse.dim_staff
[0m21:14:30.892731 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.dim_staff"
[0m21:14:30.893485 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m21:14:30.893982 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: BEGIN
[0m21:14:30.894417 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:14:30.907455 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m21:14:30.907993 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m21:14:30.908441 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */

  
    

  create  table "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_tmp"
  
  
    as
  
  (
    
SELECT
    *
FROM "data_warehouse"."dbt_dev_raw"."staff"
  );
  
[0m21:14:30.913369 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.004 seconds
[0m21:14:30.916664 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m21:14:30.917165 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_staff" rename to "dim_staff__dbt_backup"
[0m21:14:30.918290 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:30.923577 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m21:14:30.924109 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
alter table "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_tmp" rename to "dim_staff"
[0m21:14:30.924916 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:30.927128 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m21:14:30.927637 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m21:14:30.928086 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: COMMIT
[0m21:14:30.929866 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m21:14:30.934466 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_backup"
[0m21:14:30.935767 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.dim_staff"
[0m21:14:30.936296 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.dim_staff"} */
drop table if exists "data_warehouse"."dbt_dev_intermediate"."dim_staff__dbt_backup" cascade
[0m21:14:30.938859 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m21:14:30.940477 [debug] [Thread-1 (]: On model.data_warehouse.dim_staff: Close
[0m21:14:30.941349 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d7f46a80>]}
[0m21:14:30.942759 [info ] [Thread-1 (]: 20 of 23 OK created sql table model dbt_dev_intermediate.dim_staff ............. [[32mSELECT 2[0m in 0.06s]
[0m21:14:30.944149 [debug] [Thread-1 (]: Finished running node model.data_warehouse.dim_staff
[0m21:14:30.944705 [debug] [Thread-1 (]: Began running node model.data_warehouse.most_actor
[0m21:14:30.945271 [info ] [Thread-1 (]: 21 of 23 START sql table model dbt_dev_mart.most_actor ......................... [RUN]
[0m21:14:30.945995 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.dim_staff, now model.data_warehouse.most_actor)
[0m21:14:30.946483 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.most_actor
[0m21:14:30.950399 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.most_actor"
[0m21:14:30.951108 [debug] [Thread-1 (]: Began executing node model.data_warehouse.most_actor
[0m21:14:30.956432 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.most_actor"
[0m21:14:30.957324 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.most_actor"
[0m21:14:30.957926 [debug] [Thread-1 (]: On model.data_warehouse.most_actor: BEGIN
[0m21:14:30.958423 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:14:30.973103 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m21:14:30.974029 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.most_actor"
[0m21:14:30.974696 [debug] [Thread-1 (]: On model.data_warehouse.most_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.most_actor"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."most_actor__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    CONCAT(da.first_name, ' ', da.last_name) AS actor_name,
    COUNT(dfa.film_id) AS count_roles
FROM "data_warehouse"."dbt_dev_intermediate"."dim_actor" da
JOIN "data_warehouse"."dbt_dev_intermediate"."dim_film_actor" dfa ON da.actor_id = dfa.actor_id
GROUP BY actor_name
ORDER BY count_roles DESC
  );
  
[0m21:14:30.983823 [debug] [Thread-1 (]: SQL status: SELECT 199 in 0.008 seconds
[0m21:14:30.989438 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.most_actor"
[0m21:14:30.989981 [debug] [Thread-1 (]: On model.data_warehouse.most_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.most_actor"} */
alter table "data_warehouse"."dbt_dev_mart"."most_actor__dbt_tmp" rename to "most_actor"
[0m21:14:30.990871 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:30.993374 [debug] [Thread-1 (]: On model.data_warehouse.most_actor: COMMIT
[0m21:14:30.993902 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.most_actor"
[0m21:14:30.994652 [debug] [Thread-1 (]: On model.data_warehouse.most_actor: COMMIT
[0m21:14:30.996530 [debug] [Thread-1 (]: SQL status: COMMIT in 0.001 seconds
[0m21:14:30.999109 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."most_actor__dbt_backup"
[0m21:14:31.000183 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.most_actor"
[0m21:14:31.000752 [debug] [Thread-1 (]: On model.data_warehouse.most_actor: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.most_actor"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."most_actor__dbt_backup" cascade
[0m21:14:31.001657 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m21:14:31.003284 [debug] [Thread-1 (]: On model.data_warehouse.most_actor: Close
[0m21:14:31.004169 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d81fee10>]}
[0m21:14:31.005138 [info ] [Thread-1 (]: 21 of 23 OK created sql table model dbt_dev_mart.most_actor .................... [[32mSELECT 199[0m in 0.06s]
[0m21:14:31.006218 [debug] [Thread-1 (]: Finished running node model.data_warehouse.most_actor
[0m21:14:31.007040 [debug] [Thread-1 (]: Began running node model.data_warehouse.total_revenue
[0m21:14:31.007705 [info ] [Thread-1 (]: 22 of 23 START sql table model dbt_dev_mart.total_revenue ...................... [RUN]
[0m21:14:31.008498 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.most_actor, now model.data_warehouse.total_revenue)
[0m21:14:31.009058 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.total_revenue
[0m21:14:31.012333 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.total_revenue"
[0m21:14:31.013296 [debug] [Thread-1 (]: Began executing node model.data_warehouse.total_revenue
[0m21:14:31.022575 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.total_revenue"
[0m21:14:31.023967 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m21:14:31.024875 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: BEGIN
[0m21:14:31.025372 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:14:31.037771 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m21:14:31.038799 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m21:14:31.039445 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    SUM(amount) AS total_revenue,
    payment_date
FROM "data_warehouse"."dbt_dev_intermediate"."fact_payment"
GROUP BY payment_date
  );
  
[0m21:14:31.067299 [debug] [Thread-1 (]: SQL status: SELECT 14365 in 0.027 seconds
[0m21:14:31.070533 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m21:14:31.071102 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue" rename to "total_revenue__dbt_backup"
[0m21:14:31.072010 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:31.075316 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m21:14:31.075976 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
alter table "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_tmp" rename to "total_revenue"
[0m21:14:31.076994 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:31.080584 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m21:14:31.081370 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m21:14:31.082212 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: COMMIT
[0m21:14:31.086976 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m21:14:31.090179 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup"
[0m21:14:31.091222 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.total_revenue"
[0m21:14:31.091756 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.total_revenue"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."total_revenue__dbt_backup" cascade
[0m21:14:31.094861 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m21:14:31.096628 [debug] [Thread-1 (]: On model.data_warehouse.total_revenue: Close
[0m21:14:31.097434 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d800c5c0>]}
[0m21:14:31.098269 [info ] [Thread-1 (]: 22 of 23 OK created sql table model dbt_dev_mart.total_revenue ................. [[32mSELECT 14365[0m in 0.09s]
[0m21:14:31.099176 [debug] [Thread-1 (]: Finished running node model.data_warehouse.total_revenue
[0m21:14:31.099784 [debug] [Thread-1 (]: Began running node model.data_warehouse.best_selling
[0m21:14:31.100405 [info ] [Thread-1 (]: 23 of 23 START sql table model dbt_dev_mart.best_selling ....................... [RUN]
[0m21:14:31.101119 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.data_warehouse.total_revenue, now model.data_warehouse.best_selling)
[0m21:14:31.101654 [debug] [Thread-1 (]: Began compiling node model.data_warehouse.best_selling
[0m21:14:31.106132 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse.best_selling"
[0m21:14:31.107439 [debug] [Thread-1 (]: Began executing node model.data_warehouse.best_selling
[0m21:14:31.114621 [debug] [Thread-1 (]: Writing runtime sql for node "model.data_warehouse.best_selling"
[0m21:14:31.115493 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling"
[0m21:14:31.116008 [debug] [Thread-1 (]: On model.data_warehouse.best_selling: BEGIN
[0m21:14:31.116434 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:14:31.130134 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m21:14:31.130762 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling"
[0m21:14:31.131377 [debug] [Thread-1 (]: On model.data_warehouse.best_selling: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling"} */

  
    

  create  table "data_warehouse"."dbt_dev_mart"."best_selling__dbt_tmp"
  
  
    as
  
  (
    

SELECT 
    df.title, 
    COUNT(fp.payment_id) AS total_sales
FROM "data_warehouse"."dbt_dev_intermediate"."dim_film" df
JOIN "data_warehouse"."dbt_dev_intermediate"."dim_inventory" di ON df.film_id = di.film_id
JOIN "data_warehouse"."dbt_dev_intermediate"."dim_rental" dr ON dr.inventory_id = di.inventory_id
JOIN "data_warehouse"."dbt_dev_intermediate"."fact_payment" fp ON fp.rental_id = dr.rental_id
GROUP BY df.title
ORDER BY total_sales DESC
  );
  
[0m21:14:31.462277 [debug] [Thread-1 (]: SQL status: SELECT 958 in 0.330 seconds
[0m21:14:31.465583 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling"
[0m21:14:31.466146 [debug] [Thread-1 (]: On model.data_warehouse.best_selling: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling"} */
alter table "data_warehouse"."dbt_dev_mart"."best_selling" rename to "best_selling__dbt_backup"
[0m21:14:31.467063 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:31.470032 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling"
[0m21:14:31.470599 [debug] [Thread-1 (]: On model.data_warehouse.best_selling: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling"} */
alter table "data_warehouse"."dbt_dev_mart"."best_selling__dbt_tmp" rename to "best_selling"
[0m21:14:31.471467 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:14:31.473790 [debug] [Thread-1 (]: On model.data_warehouse.best_selling: COMMIT
[0m21:14:31.474335 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling"
[0m21:14:31.474824 [debug] [Thread-1 (]: On model.data_warehouse.best_selling: COMMIT
[0m21:14:31.477244 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m21:14:31.479893 [debug] [Thread-1 (]: Applying DROP to: "data_warehouse"."dbt_dev_mart"."best_selling__dbt_backup"
[0m21:14:31.480982 [debug] [Thread-1 (]: Using postgres connection "model.data_warehouse.best_selling"
[0m21:14:31.481565 [debug] [Thread-1 (]: On model.data_warehouse.best_selling: /* {"app": "dbt", "dbt_version": "1.8.5", "profile_name": "data_warehouse", "target_name": "dev", "node_id": "model.data_warehouse.best_selling"} */
drop table if exists "data_warehouse"."dbt_dev_mart"."best_selling__dbt_backup" cascade
[0m21:14:31.483962 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.002 seconds
[0m21:14:31.485643 [debug] [Thread-1 (]: On model.data_warehouse.best_selling: Close
[0m21:14:31.486393 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c8212198-31c3-4eb8-8a78-45ee35949a2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d8d22270>]}
[0m21:14:35.544194 [info ] [Thread-1 (]: 23 of 23 OK created sql table model dbt_dev_mart.best_selling .................. [[32mSELECT 958[0m in 0.39s]
[0m21:14:35.545282 [debug] [Thread-1 (]: Finished running node model.data_warehouse.best_selling
[0m21:14:35.546836 [debug] [MainThread]: Using postgres connection "master"
[0m21:14:35.547336 [debug] [MainThread]: On master: BEGIN
[0m21:14:35.547825 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:14:35.562354 [debug] [MainThread]: SQL status: BEGIN in 0.014 seconds
[0m21:14:35.562917 [debug] [MainThread]: On master: COMMIT
[0m21:14:35.563317 [debug] [MainThread]: Using postgres connection "master"
[0m21:14:35.563717 [debug] [MainThread]: On master: COMMIT
[0m21:14:35.564265 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:14:35.564829 [debug] [MainThread]: On master: Close
[0m21:14:35.566020 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:14:35.566957 [debug] [MainThread]: Connection 'model.data_warehouse.best_selling' was properly closed.
[0m21:14:35.568805 [info ] [MainThread]: 
[0m21:14:35.570973 [info ] [MainThread]: Finished running 22 table models, 1 view model in 0 hours 0 minutes and 6.41 seconds (6.41s).
[0m21:14:35.576700 [debug] [MainThread]: Command end result
[0m21:14:35.621796 [info ] [MainThread]: 
[0m21:14:35.622526 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:14:35.623116 [info ] [MainThread]: 
[0m21:14:35.623759 [info ] [MainThread]: Done. PASS=23 WARN=0 ERROR=0 SKIP=0 TOTAL=23
[0m21:14:35.624880 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.3623376, "process_user_time": 3.721954, "process_kernel_time": 0.194101, "process_mem_max_rss": "110864", "process_in_blocks": "8", "process_out_blocks": "3432"}
[0m21:14:35.625629 [debug] [MainThread]: Command `dbt run` succeeded at 21:14:35.625462 after 7.36 seconds
[0m21:14:35.626225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403da3642f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d9fd04a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7403d9b2c260>]}
[0m21:14:35.626813 [debug] [MainThread]: Flushing usage events
